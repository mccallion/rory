{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Softmax\" data-toc-modified-id=\"Softmax-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Softmax</a></span></li><li><span><a href=\"#Tensors-are-just-rectangles!\" data-toc-modified-id=\"Tensors-are-just-rectangles!-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Tensors are just rectangles!</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1332,  0.6272,  0.9774, -1.1850,  0.3530,  0.2776,  0.9024,  1.0016,\n",
       "         0.9419, -1.1489])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 imgs, output has 10 activations per img\n",
    "im1 = torch.randn(10)\n",
    "im2 = torch.randn(10)\n",
    "im3 = torch.randn(10)\n",
    "im1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1332,  0.6272,  0.9774, -1.1850,  0.3530,  0.2776,  0.9024,  1.0016,\n",
       "          0.9419, -1.1489],\n",
       "        [-0.3813,  0.3184, -0.7167, -1.1152, -0.2556, -0.1563,  1.2510, -0.8549,\n",
       "         -1.2150,  0.8789],\n",
       "        [ 1.2981,  0.3528,  1.9857, -2.4427,  0.7066,  0.3762, -0.7110,  1.3030,\n",
       "         -0.0151, -0.3545]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ims = torch.stack((im1,im2,im3),0)\n",
    "ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(t):\n",
    "    if len(t.shape) == 1: return torch.exp(t) / torch.exp(t).sum()\n",
    "    else:                 return torch.exp(t) / torch.exp(t).sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0680, 0.1115, 0.1583, 0.0182, 0.0848, 0.0786, 0.1468, 0.1622, 0.1527,\n",
       "        0.0189])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0680, 0.1115, 0.1583, 0.0182, 0.0848, 0.0786, 0.1468, 0.1622, 0.1527,\n",
       "         0.0189],\n",
       "        [0.0614, 0.1235, 0.0439, 0.0295, 0.0696, 0.0769, 0.3140, 0.0382, 0.0267,\n",
       "         0.2164],\n",
       "        [0.1680, 0.0653, 0.3342, 0.0040, 0.0930, 0.0668, 0.0225, 0.1688, 0.0452,\n",
       "         0.0322]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(ims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors are just rectangles!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good news! You have a brilliantly intuitive grasp of tensors, smartypants. I'm just going to draw it out of you with a few simple words and analogies. But remember: you already have the power. You already *know* tensors.\n",
    "\n",
    "Warmup:\n",
    "- A square is a rectangle, but a rectangle is not a square\n",
    "- A square is a two-dimensional shape\n",
    "- A cube is a three-dimensional shape\n",
    "- A cube is a 3-D square\n",
    "- A \"hypercube\" is a 4-D square\n",
    "\n",
    "Alright, now that you're freaking' burning me with your hot brain, let's talk about tensors:\n",
    "- A hypercube is a tensor, but a tensor is not a hypercube\n",
    "- A tensor word for one or more rectangles smooshed together\n",
    "- A rectangle is a tensor\n",
    "- A cube is a tensor\n",
    "- A hyper-cube (a 4-d cube) is a tensor\n",
    "- \"Tensor\" means \"some number of rectangles smooshed together\"\n",
    "- Replace rectangle with \"matrix\" in the above definition and you're a freaking genius!\n",
    "\n",
    "I can tell you're smart because I know you know these things about squares and cubes:\n",
    "\n",
    "\n",
    "Tensors are \"n-dimensional\" \"rectagular\" objects. By n-dimensional, I mean n-e-dimensional (haha get it). Let me show you using an example involving spreadsheets:\n",
    "- n is 1: a list of numbers is a tensor (even if the list has only one number!).\n",
    "- n is 2: a spreadsheet of numbers is a tensor.\n",
    "- n is 3: a workbook with many sheets is a tensor.\n",
    "- n is 4: a folder with workbooks is a tensor.\n",
    "- n is 5: a folder of folders is a tensor.\n",
    "- n it goes on n on!\n",
    "\n",
    "Since it would be a drag to say something like \"n-dimensional matrix\" whenever we mean \"some number of matrices smooshed together\", we just say \"tensor.\" I personally use the mental image of a workbook with many spreadsheets as my visual mental-model of what a tensor is.\n",
    "\n",
    "To finish convincing you that you are already a tensor expert, let's talk about the two most important tensors in computer vision: the *black-and-white image* and the *color image.*\n",
    "\n",
    "b&w image:\n",
    "- length of \"height\" dimension: 200 pixels\n",
    "- length of \"width\" dimension: 100 pixels\n",
    "- length of color dimension: 1 channel (Grey)\n",
    "\n",
    "mental model of a b&w image:\n",
    "- a workbook with one sheet titled \"Grey\"\n",
    "- the Grey sheet has 200 rows and 100 columns\n",
    "- the Grey sheet has no column headers\n",
    "- each cell in the sheet is a pixel\n",
    "- each cell has a number in it from 0 (pure black) to 255 (pure white)\n",
    "\n",
    "color image:\n",
    "- length of \"width\" dimension: 100 pixels\n",
    "- length of \"height\" dimension: 200 pixels\n",
    "- length of color dimension: 3 channels (Red, Blue, Green)\n",
    "\n",
    "mental model of a color image:\n",
    "- a workbook of spreadsheets, just like the B&W image\n",
    "- the workbook has three sheets instead of one: \"Red\", \"Blue\", and \"Green\"\n",
    "- each cell in the Red sheet represent the red value for a single pixel\n",
    "- each cell in the Blue sheet represent the blue value for a single pixel\n",
    "- each cell in the Green sheet represent the green value for a single pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
