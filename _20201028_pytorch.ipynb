{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Creating-and-Copying-Tensors\" data-toc-modified-id=\"Creating-and-Copying-Tensors-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Creating and Copying Tensors</a></span></li><li><span><a href=\"#Tensor-Shapes\" data-toc-modified-id=\"Tensor-Shapes-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Tensor Shapes</a></span></li><li><span><a href=\"#Broadcasting\" data-toc-modified-id=\"Broadcasting-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Broadcasting</a></span></li><li><span><a href=\"#Playground\" data-toc-modified-id=\"Playground-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Playground</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helpers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T(Tensor): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pnl(*args): print(*args, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Copying Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.empty(shape)**\n",
    "\n",
    "Create a tensor of `shape` using random memory; will be filled with garbage, but it's the fastest way to create a tensor. Note that this tensor is NOT a floattensor, but all other tensors created in this section are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.5505e-09, 4.5553e-41, 3.5505e-09, 4.5553e-41],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 1.0800e-05, 1.8788e+31, 1.7220e+22]],\n",
       "\n",
       "        [[1.9152e+23, 1.0432e+21, 2.5639e-09, 1.6691e-07],\n",
       "         [2.0314e+20, 1.3423e-05, 1.3075e+22, 5.3483e+22],\n",
       "         [2.5100e-18, 1.9421e+31, 2.7491e+20, 6.1949e-04]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty((2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(torch.empty(0), torch.Tensor([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.zeros(shape)**\n",
    "\n",
    "Create float tensor of shape with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.rand(shape)**\n",
    "\n",
    "Create float tensor of shape with uniform random vals between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7242, 0.1377],\n",
       "        [0.1792, 0.3165]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor[idx]**  *(aka: slicing on indeces)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2705, 0.3561],\n",
      "        [0.4726, 0.6325]])\n",
      "tensor(0.2705)\n",
      "tensor([0.2705, 0.4726])\n",
      "tensor([0.4726, 0.6325])\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(2,2)\n",
    "\n",
    "pnl(t,\n",
    "    t[0,0],\n",
    "    t[:,0],\n",
    "    t[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor.repeat(repeats,per,dim)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4580, 0.8005],\n",
       "        [0.8964, 0.3002]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(2,2)\n",
    "t.repeat(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4580, 0.8005, 0.4580, 0.8005, 0.4580, 0.8005],\n",
       "        [0.8964, 0.3002, 0.8964, 0.3002, 0.8964, 0.3002],\n",
       "        [0.4580, 0.8005, 0.4580, 0.8005, 0.4580, 0.8005],\n",
       "        [0.8964, 0.3002, 0.8964, 0.3002, 0.8964, 0.3002]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.repeat(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0.4580, 0.8005, 0.4580, 0.8005, 0.4580, 0.8005],\n",
       "           [0.8964, 0.3002, 0.8964, 0.3002, 0.8964, 0.3002],\n",
       "           [0.4580, 0.8005, 0.4580, 0.8005, 0.4580, 0.8005],\n",
       "           [0.8964, 0.3002, 0.8964, 0.3002, 0.8964, 0.3002]]]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.repeat(1,1,1,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.arange(num_of_elements)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(4.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor.view(shape)**\n",
    "\n",
    "Create a view of a tensor. View object shares data (and memory) with underlying tensor; avoids extra data copying for more efficient operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(6).view(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0],\n",
       "           [1],\n",
       "           [2]],\n",
       "\n",
       "          [[3],\n",
       "           [4],\n",
       "           [5]]]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(6).view(1,1,2,3,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.squeeze(tensor)**\n",
    "\n",
    "Remove dims of size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4, 5])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(T(1,2,1,1,3,1,4,5,1)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor.flatten()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor.unflatten(dim, sizes)**\n",
    "\n",
    "Expand dimension `dim` into new dimensions `sizes`.\n",
    "\n",
    "IDK if this still works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor.split()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors have shapes that look like tuples, lists, vectors, etc. Ex: (5,2,3). The tuple represents a list of dimension sizes. The length of the tuple is the total number of dimensions (aka the tensor's rank).\n",
    "\n",
    "To visualize the shape of a tensor, I basically visualize a spreadsheet workbook. I start at the \"trailing\" dimension (the right-most one) â€“ 3 in the example above. This is the number of \"columns\" on one page. The next number is the number of rows. The next number is the number of sheets. And, if there was a number above that one, I'd visualize that as the number of workbooks. (If there was one above that, I'd visualize it as the number of folders; from there it's nested folders all the way down).\n",
    "\n",
    "**Ex: visualizing a tensor of shape (2,2,2,3,4).**\n",
    "\n",
    "From right (trailing dim) to left:\n",
    "- 4 cols\n",
    "- 3 rows\n",
    "- 2 sheets\n",
    "- 2 wbs\n",
    "- 2 folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 3.5506e-09,  4.5553e-41,  3.5506e-09,  4.5553e-41],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "          [[-3.5106e-13,  3.0617e-41,  0.0000e+00,  0.0000e+00],\n",
       "           [-3.6195e-13,  3.0617e-41, -3.6195e-13,  3.0617e-41],\n",
       "           [-3.6195e-13,  3.0617e-41,  0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "         [[[ 4.5553e-41,  3.2320e-12,  4.5552e-41,  1.6158e-09],\n",
       "           [ 4.5553e-41,  1.6158e-09,  4.5553e-41,  1.4013e-45],\n",
       "           [-3.6195e-13,  3.0617e-41, -3.6195e-13,  3.0617e-41]],\n",
       "\n",
       "          [[-3.6195e-13,  3.0617e-41,  1.4013e-45,  0.0000e+00],\n",
       "           [-3.5587e-13,  3.0617e-41,  1.4013e-45,  0.0000e+00],\n",
       "           [ 1.4013e-45,  0.0000e+00,  1.4013e-45,  0.0000e+00]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 0.0000e+00,  0.0000e+00,  1.4013e-45,  0.0000e+00],\n",
       "           [-1.9100e-04,  4.5552e-41,  1.4013e-45,  9.1834e-41],\n",
       "           [ 1.4013e-45,  0.0000e+00,  1.4013e-45,  2.3511e-38]],\n",
       "\n",
       "          [[ 3.5873e-43,  0.0000e+00,  3.5873e-43,  0.0000e+00],\n",
       "           [-3.6196e-13,  3.0617e-41,  2.7185e-43,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "         [[[ 0.0000e+00,  0.0000e+00,  1.8788e+31,  1.7220e+22],\n",
       "           [ 1.8704e+20,  1.7000e+22,  1.0311e-11,  6.7940e+22],\n",
       "           [ 8.3106e+20,  1.0431e-08,  6.5562e-10,  1.0991e-05]],\n",
       "\n",
       "          [[ 2.1065e-07,  1.0490e-08,  3.1369e+27,  7.0800e+31],\n",
       "           [ 3.1095e-18,  1.8590e+34,  7.7767e+31,  7.1536e+22],\n",
       "           [ 3.3803e-18,  1.9421e+31,  2.7491e+20,  6.1949e-04]]]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                                # end of cols (4 per row)\n",
    "T([[[[[ 3.5506e-09,  4.5553e-41,  3.5506e-09,  4.5553e-41],   # end of rows (3 per sheet)\n",
    "      [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00], \n",
    "      [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],  # end of sheet (2 per wb)\n",
    "                                                              \n",
    "     [[-3.5106e-13,  3.0617e-41,  0.0000e+00,  0.0000e+00],\n",
    "      [-3.6195e-13,  3.0617e-41, -3.6195e-13,  3.0617e-41],\n",
    "      [-3.6195e-13,  3.0617e-41,  0.0000e+00,  0.0000e+00]]], # end of wb (2 per folder)\n",
    "                                                              \n",
    "                                                              \n",
    "    [[[ 4.5553e-41,  3.2320e-12,  4.5552e-41,  1.6158e-09],\n",
    "      [ 4.5553e-41,  1.6158e-09,  4.5553e-41,  1.4013e-45],\n",
    "      [-3.6195e-13,  3.0617e-41, -3.6195e-13,  3.0617e-41]], \n",
    "      \n",
    "     [[-3.6195e-13,  3.0617e-41,  1.4013e-45,  0.0000e+00],\n",
    "      [-3.5587e-13,  3.0617e-41,  1.4013e-45,  0.0000e+00],\n",
    "      [ 1.4013e-45,  0.0000e+00,  1.4013e-45,  0.0000e+00]]]], # end of folder (2 per tensor)\n",
    "                                                               \n",
    "                                                               \n",
    "                                                               \n",
    "   [[[[ 0.0000e+00,  0.0000e+00,  1.4013e-45,  0.0000e+00],\n",
    "      [-1.9100e-04,  4.5552e-41,  1.4013e-45,  9.1834e-41],\n",
    "      [ 1.4013e-45,  0.0000e+00,  1.4013e-45,  2.3511e-38]],\n",
    "   \n",
    "     [[ 3.5873e-43,  0.0000e+00,  3.5873e-43,  0.0000e+00],\n",
    "      [-3.6196e-13,  3.0617e-41,  2.7185e-43,  0.0000e+00],\n",
    "      [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
    "      \n",
    "   \n",
    "    [[[ 0.0000e+00,  0.0000e+00,  1.8788e+31,  1.7220e+22],\n",
    "      [ 1.8704e+20,  1.7000e+22,  1.0311e-11,  6.7940e+22],\n",
    "      [ 8.3106e+20,  1.0431e-08,  6.5562e-10,  1.0991e-05]],\n",
    "  \n",
    "     [[ 2.1065e-07,  1.0490e-08,  3.1369e+27,  7.0800e+31],\n",
    "      [ 3.1095e-18,  1.8590e+34,  7.7767e+31,  7.1536e+22],\n",
    "      [ 3.3803e-18,  1.9421e+31,  2.7491e+20,  6.1949e-04]]]]]) # end of tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "- [NumPy broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html#module-numpy.doc.broadcasting)\n",
    "- [PyTorch broadcasting](https://pytorch.org/docs/stable/notes/broadcasting.html) (mostly from this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting is the step in matrix algebra involving vectors/matricies/tensors of different sizes where you make copies of each shape in order to do element-wise operations. For example, recall that adding a vector of shape 3x1 to a vector of shape 1x3 results in a vector of size 3x3. Each element in the result vector was created by adding a elements of the input vectors.\n",
    "\n",
    "`ex:\n",
    "          |1|   |1+1 1+2 1+3|   |2 3 4|\n",
    "|1 2 3| + |2| = |1+2 2+2 3+2| = |3 4 5|\n",
    "          |3|   |1+3 2+3 3+3|   |4 5 6|`\n",
    "\n",
    "Notice how each of the input vectors had to be copied three times to perform all of the element-wise operations. That copying is known as **broadcasting.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From PyTorch docs: \"If a PyTorch operation supports broadcasting, then its Tensor args can be automatically expanded to be of equal sizes *(without making copies of the data)*.\" (emphasis added)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to do tensor maths with massive tensors and without having to make copies when broadcasting is a big deal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two tensors are \"broadcastable\" if:\n",
    "- Neither has a shape of [0].\n",
    "- When iterating over the dimension sizes, starting at the trailing dimensison, the dimension sizes must be equal, one of them is 1, or one of them does not exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 1:**\n",
    "- Tensors have the same shape.\n",
    "- Addition works; no broadcasting takes place (no copies needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.7333e+22, 1.7591e+22],\n",
       "        [1.7184e+25, 4.3222e+27]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T(2,2) + T(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 2:**\n",
    "- One of them has a trailing dimension of size 1, like Tensor(4,9,...,1).\n",
    "- Works because 1||3 and 3||1 (|| now means \"is compatible with\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.5501e-09,  3.5505e-09,  3.5501e-09],\n",
       "        [-3.5675e-13,  7.6170e-41, -3.5282e-13],\n",
       "        [ 3.5501e-09,  3.5505e-09,  3.5501e-09]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T(1,3) + T(3,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 3:**\n",
    "- Missing dimensions.\n",
    "- Works because 2||2, and 3||na."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.5501e-09, 7.6170e-41],\n",
       "        [3.5505e-09, 4.5623e-41],\n",
       "        [3.5505e-09, 4.5553e-41]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T(3,2) + T(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 4:**\n",
    "- Diff shapes.\n",
    "- Does not work: 3||3, but 2|!|3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-efea1cc2b849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "T(1,2,3) + T(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 5:**\n",
    "- Diff shapes.\n",
    "- Works: 1||2, 3||1, 2||na, 1||na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.5501e-09, -3.5538e-13],\n",
       "          [ 3.5505e-09,  7.6170e-41],\n",
       "          [ 7.1009e-09,  3.5505e-09]],\n",
       "\n",
       "         [[ 3.5505e-09,  9.1107e-41],\n",
       "          [ 3.5505e-09,  4.5598e-41],\n",
       "          [ 3.5505e-09,  4.5553e-41]]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T(1,2,3,1) + T(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overall Rules**\n",
    "\n",
    "Given two non-scalar tensors, compare their trailing (right-most) dimensions' shapes. The tensors are broadcastable if one dimension is shape 1, one is missing, or if the shapes are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
