{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#In-This-Notebook\" data-toc-modified-id=\"In-This-Notebook-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>In This Notebook</a></span></li><li><span><a href=\"#Final-Result\" data-toc-modified-id=\"Final-Result-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Final Result</a></span></li><li><span><a href=\"#Loss-Function-Notes-&amp;-Scratch\" data-toc-modified-id=\"Loss-Function-Notes-&amp;-Scratch-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Loss Function Notes &amp; Scratch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Notes\" data-toc-modified-id=\"Notes-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Notes</a></span></li><li><span><a href=\"#Scratch-Work\" data-toc-modified-id=\"Scratch-Work-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Scratch Work</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In This Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Context**\n",
    "\n",
    "I worked on this notebook after getting back from my PNW van trip with Rose, Tim, and Eva. I started on a Thursday and ended on a Monday.\n",
    "\n",
    "The notes on loss function in section 3 was critically important to coming up with the final solution. While working on this notebook, I dug into the depths of the Learner class and studied callbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Breakthroughs in this notebook:**\n",
    "- **Massively improved results.** Achieved by changing the weights of CEL and MSE in the loss function. Before, I was weighting CEL by 10; now I'm weighting MSE by 5.\n",
    "- **Added metrics.** MSE, CEL, and ACC were all added.\n",
    "- **`view_results` working.**\n",
    "- **`show_batch` working.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "\n",
    "### Params ###\n",
    "im_size      = 224\n",
    "batch_size   = 64\n",
    "path         = Path('/home/rory/data/coco2017')\n",
    "valid_split  = .15\n",
    "\n",
    "\n",
    "### Load data (singles) ###\n",
    "# Grab cols\n",
    "def grab_cols(df, cols):\n",
    "    \"\"\"Expects: DataFrame df; str or list of strs cols. Returns: L or an LoL.\"\"\"\n",
    "    def _grab_col(df, col):\n",
    "        return L((ColReader(col)(df)).to_list())\n",
    "    \n",
    "    if isinstance(cols, str): return _grab_col(df, cols)\n",
    "    if len(cols)==1: return _grab_col(df, cols)\n",
    "    if len(cols)>=2:\n",
    "        r=L()\n",
    "        for c in cols:\n",
    "            r.append(_grab_col(df,c))\n",
    "        return r\n",
    "df = pd.read_pickle(path/'singles.pkl')\n",
    "imp, lbl, bbox = grab_cols(df, ['im','lbl','bbox'])\n",
    "bbox = bbox.map(lambda x:list(x)) # fixed pickle bug; lists incorrectly unpickled as tups\n",
    "# Create getters for pipeline\n",
    "imp2lbl  = {p:l for p,l in zip(imp,lbl)}\n",
    "imp2bbox = {p:b for p,b in zip(imp,bbox)}\n",
    "def get_lbl(p):  return imp2lbl[p]\n",
    "def get_bbox(p): return imp2bbox[p]\n",
    "\n",
    "\n",
    "### Datasets ###\n",
    "dss_tfms = [[PILImage.create],\n",
    "            [get_bbox, TensorBBox.create],\n",
    "            [get_lbl, Categorize()]]\n",
    "splits = RandomSplitter(valid_split)(imp)\n",
    "dss = Datasets(imp, tfms=dss_tfms, splits=splits)\n",
    "\n",
    "\n",
    "### DataLoaders ###\n",
    "cpu_tfms = [BBoxLabeler(), PointScaler(), Resize(im_size, method='squish'), ToTensor()]\n",
    "gpu_tfms = [IntToFloatTensor(), Normalize.from_stats(*imagenet_stats)]\n",
    "dls = dss.dataloaders(bs=batch_size,after_item=cpu_tfms,after_batch=gpu_tfms,drop_last=True)\n",
    "dls.n_inp = 1\n",
    "\n",
    "\n",
    "### Model ###\n",
    "class custom_module(Module):\n",
    "    \n",
    "    def __init__(self, body, head):\n",
    "        self.body, self.head = body, head\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(self.body(x))\n",
    "body = create_body(resnet34, pretrained=True)\n",
    "head = create_head(1024, 4+dss.c, ps=0.5)\n",
    "mod  = custom_module(body, head)\n",
    "\n",
    "\n",
    "### Loss ###\n",
    "def mse(f, bb, lbl): return MSELossFlat()(f[:,:4], torch.squeeze(bb))\n",
    "def cel(f, bb, lbl): return CrossEntropyLossFlat()(f[:,4:], lbl)\n",
    "def lbb_loss(f, bb, lbl): return 5*mse(f,bb,lbl) + cel(f,bb,lbl)\n",
    "def acc(f, bb, lbl): return accuracy(f[:,4:], lbl)\n",
    "\n",
    "\n",
    "### Training ###\n",
    "learner = Learner(dls, mod, loss_func=lbb_loss, metrics=[mse, cel, acc])\n",
    "lr_min, _ = learner.lr_find(); print(\"lr_min:\", lr_min)\n",
    "learner.fit_one_cycle(10, lr=lr_min)\n",
    "\n",
    "\n",
    "### Results ###\n",
    "def view_results(learner, n=16, nrows=4, ncols=4, offset=0):\n",
    "    # get batch of ims & targs, get preds\n",
    "    ims, targ_bbs, targ_lbls = learner.dls.one_batch()\n",
    "    preds = learner.model(ims)\n",
    "    pred_bbs, pred_lbls = preds[:,:4], preds[:,4:].argmax(dim=-1)\n",
    "    decoded_ims = Pipeline(gpu_tfms).decode(ims)\n",
    "    \n",
    "    # show grid results\n",
    "    for i,ctx in enumerate(get_grid(n, nrows, ncols)):\n",
    "        idx = i+offset*n\n",
    "        # title\n",
    "        pred_cls = dls.vocab[pred_lbls[idx].item()]\n",
    "        targ_cls = dls.vocab[targ_lbls[idx].item()]\n",
    "        icon = '✔️' if pred_cls==targ_cls else '✖️'\n",
    "        title = f\"{icon}  P {pred_cls} : A {targ_cls}\"\n",
    "        # im\n",
    "        show_image(decoded_ims[idx], ctx=ctx, title=title)\n",
    "        # bbs\n",
    "        pred_bb = TensorBBox(pred_bbs[idx])\n",
    "        targ_bb = TensorBBox(targ_bbs[idx])\n",
    "        ((pred_bb+1)*224//2).show(ctx=ctx, color='magenta')\n",
    "        ((targ_bb+1)*224//2).show(ctx=ctx);\n",
    "view_results(learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function Notes & Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My notes from my journal\n",
    "1. `xb,yb = b`\n",
    "2. `p = mod(xb)`\n",
    "3. `alpha = cel(mb) / rmse(mb); beta = 1`\n",
    "4. `if epoch <= 3: gamma=10; else: gamma=1` (do later)\n",
    "5. `loss(p, yb): rmse(p[0:4],yb[0])*alpha*gamma + cel(p[4:],yb[1])*beta`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method chain for learning (from https://github.com/fastai/fastai/blob/master/fastai/learner.py#L163)\n",
    "1. `learner.fit_one_cycle()`\n",
    "2. → `.fit()`\n",
    "3. → `._do_fit()`\n",
    "4. → `._do_epoch()`\n",
    "5. → `._do_epoch_train(); ._do_epoch_validate()` (rest of chain follows `_do_epoch_train`)\n",
    "6. → `.dl = .dls.train; .all_batches()`\n",
    "7. → `.n_iter = len(.dl); for o in enum(.dl): .one_batch(*o)` o=(i,b)\n",
    "8. → `.iter = i; ._split(b); ._do_one_batch()` (item 9 has `_split`, item 10 has `_do_one_batch`)\n",
    "9. → `._split(b)`: `i = dls.n_inp; .xb, .yb = b[:i], b[i:]`\n",
    "10. → `._do_one_batch()`:\n",
    "    - `.pred = .model(*xb)`\n",
    "    - `.loss = .loss_func(.pred, *.yb)`\n",
    "    - `._backward()` → `.loss.backward()`\n",
    "    - `._step()` → `.opt.step()`\n",
    "    - `.opt.zero_grad()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(dls, mod, loss_func=lbb_loss)\n",
    "learner.dl = learner.dls.train\n",
    "learner.b  = learner.dl.one_batch()\n",
    "learner._split(learner.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.pred = learner.model(learner.xb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 12])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1258,  0.3672,  0.5901, -0.1777, -0.8904,  0.7933,  0.2428,  1.9469,\n",
       "        -0.5976, -1.0789, -1.2176, -0.4324], device='cuda:0',\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.yb[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 4]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[learner.yb[0].shape[0], learner.yb[0].shape[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorBBox([[[-0.2176, -0.0629, -0.0134,  0.2128]],\n",
       " \n",
       "         [[-0.2596, -0.8973,  0.3544,  0.9628]],\n",
       " \n",
       "         [[-1.0000, -0.3716,  0.9917,  0.3761]],\n",
       " \n",
       "         [[-0.6538, -0.5697,  0.7310,  0.8563]],\n",
       " \n",
       "         [[-0.4638, -0.3515,  0.3256,  0.1168]],\n",
       " \n",
       "         [[-0.5657, -0.4710,  0.0906, -0.0882]],\n",
       " \n",
       "         [[-0.0990, -0.6553,  0.4875, -0.2109]],\n",
       " \n",
       "         [[-0.9313, -0.3214,  0.9131,  0.4786]],\n",
       " \n",
       "         [[-0.4485,  0.0178, -0.3423,  0.2311]],\n",
       " \n",
       "         [[-0.7116, -0.4122,  0.3024,  0.3671]],\n",
       " \n",
       "         [[-0.5355, -0.5242,  0.4081,  0.5527]],\n",
       " \n",
       "         [[-0.9284, -0.5109,  0.9340,  0.4554]],\n",
       " \n",
       "         [[-0.4018, -0.4036,  0.5217,  0.4458]],\n",
       " \n",
       "         [[-0.7367,  0.0744, -0.5844,  0.2837]],\n",
       " \n",
       "         [[-1.0000, -0.9713,  0.8297,  1.0000]],\n",
       " \n",
       "         [[-0.3388, -0.6430, -0.1341, -0.5146]],\n",
       " \n",
       "         [[-0.9924, -0.1374,  0.7230,  0.3086]],\n",
       " \n",
       "         [[-0.7736,  0.4367, -0.0809,  1.0000]],\n",
       " \n",
       "         [[-0.0785, -0.4619,  0.7832,  0.2556]],\n",
       " \n",
       "         [[-0.8504, -0.8671,  0.9277,  1.0000]],\n",
       " \n",
       "         [[-0.7168, -0.0292,  0.9685,  0.6674]],\n",
       " \n",
       "         [[-0.9340, -0.3124,  0.9251,  0.4337]],\n",
       " \n",
       "         [[-0.9582, -0.0628,  0.9190,  0.3587]],\n",
       " \n",
       "         [[-0.4542, -0.2821,  0.5953,  0.3931]],\n",
       " \n",
       "         [[-0.9947, -0.7470, -0.4878,  0.3361]],\n",
       " \n",
       "         [[-0.6138,  0.1200, -0.3926,  0.4012]],\n",
       " \n",
       "         [[-0.9274, -0.9914,  0.9981,  0.9672]],\n",
       " \n",
       "         [[-0.7843, -0.4022,  0.8472,  0.4472]],\n",
       " \n",
       "         [[-0.5037,  0.1187,  0.4360,  1.0000]],\n",
       " \n",
       "         [[-1.0000, -1.0000,  0.9899,  0.9919]],\n",
       " \n",
       "         [[-0.4118, -0.4749,  0.4502,  0.1030]],\n",
       " \n",
       "         [[-0.8431, -0.6516,  0.8209,  0.9398]],\n",
       " \n",
       "         [[-0.0785, -0.7955,  0.9137,  0.9758]],\n",
       " \n",
       "         [[-0.6543, -0.3895,  0.2293,  0.4015]],\n",
       " \n",
       "         [[-0.0557,  0.0612,  0.1686,  0.3840]],\n",
       " \n",
       "         [[-0.9850, -0.9955,  0.4180,  1.0000]],\n",
       " \n",
       "         [[-0.9957, -0.8633,  0.1020, -0.3829]],\n",
       " \n",
       "         [[-0.2042, -0.5289, -0.0802, -0.3425]],\n",
       " \n",
       "         [[-0.9358, -0.2500,  0.9245,  0.4347]],\n",
       " \n",
       "         [[-0.9039, -0.2496,  0.5719,  0.3835]],\n",
       " \n",
       "         [[-0.9880, -0.4865,  0.8337,  0.1337]],\n",
       " \n",
       "         [[-0.3283, -0.5452,  0.4910,  0.3081]],\n",
       " \n",
       "         [[-0.3146, -0.8033,  0.1797,  0.1317]],\n",
       " \n",
       "         [[-0.4764, -0.3601,  0.4185,  0.3663]],\n",
       " \n",
       "         [[-0.4337, -0.6135,  0.5281,  0.4697]],\n",
       " \n",
       "         [[ 0.0245, -0.3368,  0.8781,  0.9078]],\n",
       " \n",
       "         [[-0.4233, -0.9955,  0.6831, -0.2466]],\n",
       " \n",
       "         [[-0.8545, -0.0695,  0.8784,  0.7573]],\n",
       " \n",
       "         [[-0.2880, -0.2445,  0.2162,  0.4498]],\n",
       " \n",
       "         [[-0.2897, -0.9605,  0.5049,  0.8273]],\n",
       " \n",
       "         [[-0.4026, -0.5842,  0.0150,  0.8077]],\n",
       " \n",
       "         [[-0.9933, -0.9873,  0.0241,  0.9678]],\n",
       " \n",
       "         [[ 0.7458,  0.2646,  0.9913,  0.6774]],\n",
       " \n",
       "         [[-0.9899, -0.7832,  0.9989,  0.7674]],\n",
       " \n",
       "         [[-0.9426, -0.6915,  0.7770,  0.5923]],\n",
       " \n",
       "         [[ 0.3479, -0.1909,  0.9339,  0.1129]],\n",
       " \n",
       "         [[-0.6070, -0.9641,  0.3816,  0.5011]],\n",
       " \n",
       "         [[-0.3828, -0.5828,  0.5281,  0.9768]],\n",
       " \n",
       "         [[-0.2689, -0.0416,  0.0790,  0.9652]],\n",
       " \n",
       "         [[-0.0212,  0.3770,  0.0582,  0.5228]],\n",
       " \n",
       "         [[-0.2241, -0.3525,  0.2778,  0.2786]],\n",
       " \n",
       "         [[-0.8173, -1.0000,  0.5675,  0.9982]],\n",
       " \n",
       "         [[-0.6216,  0.0033,  0.3513,  0.6396]],\n",
       " \n",
       "         [[-0.3412, -0.4061, -0.2444, -0.2192]]], device='cuda:0'),\n",
       " TensorCategory([3, 4, 0, 5, 1, 2, 5, 0, 7, 7, 2, 0, 7, 5, 6, 3, 7, 6, 1, 1, 7, 0, 7, 0,\n",
       "         0, 5, 3, 7, 6, 3, 3, 2, 3, 1, 2, 7, 7, 3, 0, 0, 7, 1, 3, 1, 6, 6, 5, 0,\n",
       "         3, 4, 2, 7, 2, 0, 6, 0, 5, 4, 4, 2, 0, 4, 5, 3], device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.pred[:,4:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 0, 5, 1, 0, 5, 0, 7, 1, 0, 0, 7, 5, 6, 3, 7, 6, 1, 1, 1, 0, 0, 0,\n",
       "        0, 5, 3, 7, 6, 0, 6, 2, 3, 1, 1, 0, 3, 3, 0, 0, 7, 3, 3, 1, 6, 6, 5, 0,\n",
       "        3, 4, 2, 6, 0, 0, 6, 0, 5, 1, 4, 0, 0, 1, 5, 3], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(learner.pred[:,4:]).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(learner.yb[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#0) []"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cel_loss(pred, targ_bb, targ_lbl):\n",
    "#     mse = MSELossFlat()(pred[:,:4], torch.squeeze(targ_bb))\n",
    "    cel = CrossEntropyLossFlat()(pred[:,4:], targ_lbl)\n",
    "    return cel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0821, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbb_loss(learner.pred, learner.yb[0], learner.yb[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
