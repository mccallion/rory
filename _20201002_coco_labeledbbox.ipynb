{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Building-&amp;-training-the-model\" data-toc-modified-id=\"Building-&amp;-training-the-model-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Building &amp; training the model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Singles\" data-toc-modified-id=\"Singles-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Singles</a></span></li><li><span><a href=\"#DataLoaders\" data-toc-modified-id=\"DataLoaders-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>DataLoaders</a></span></li><li><span><a href=\"#Here-on-down-I'm-exploring-how-my-custom-loss_func-must-be-formatted.\" data-toc-modified-id=\"Here-on-down-I'm-exploring-how-my-custom-loss_func-must-be-formatted.-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Here on down I'm exploring how my custom loss_func must be formatted.</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building & training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "\n",
    "### Params ###\n",
    "im_size      = 224\n",
    "batch_size   = 64\n",
    "path         = Path('/home/rory/data/coco2017')\n",
    "train_json   = 'annotations/instances_train2017.json'\n",
    "valid_json   = 'annotations/instances_val2017.json'\n",
    "train_im_dir = 'train2017'\n",
    "valid_im_dir = 'val2017'\n",
    "\n",
    "\n",
    "### Get files and annos ###\n",
    "def get_annos(path, anno_file, im_folder):\n",
    "    xs, ys = get_annotations(path/anno_file)\n",
    "    return L(xs).map(lambda x: path/im_folder/x), ys\n",
    "train_files, train_annos = get_annos(path, train_json, train_im_dir)\n",
    "valid_files, valid_annos = get_annos(path, valid_json, valid_im_dir)\n",
    "files  = train_files + valid_files\n",
    "annos  = train_annos + valid_annos\n",
    "bboxes = [a[0] for a in annos]\n",
    "lbls   = [a[1] for a in annos]\n",
    "\n",
    "\n",
    "### Get largest anno ###\n",
    "def transpose(anno): return list(zip(*anno)) # tensor.t()\n",
    "def bbox_area(transposed_anno):\n",
    "    b = transposed_anno[0]\n",
    "    return((b[2]-b[0])*(b[3]-b[1])) # b-t * l-r\n",
    "def sort_annos(o): return sorted(transpose(o), key=bbox_area, reverse=True)\n",
    "sorted_annos = L(sort_annos(i) for i in annos)\n",
    "largest_anno = L(i[0] for i in sorted_annos)\n",
    "largest_bbox = L(i[0] for i in largest_anno)\n",
    "largest_lbl  = L(i[1] for i in largest_anno)\n",
    "# get_xyz helpers (used in following sections)\n",
    "files2lbl  = {f:l for f,l in zip(files,largest_lbl)}\n",
    "files2bbox = {f:b for f,b in zip(files,largest_bbox)}\n",
    "def get_lbl(f):  return files2lbl[f]\n",
    "def get_bbox(f): return files2bbox[f]\n",
    "\n",
    "\n",
    "### Get singles ###\n",
    "# identify singles\n",
    "lbls_per_im = L(len(l) for l in lbls)\n",
    "tuples = L(zip(files, largest_lbl, largest_bbox))\n",
    "singles = tuples[lbls_per_im.map(lambda n:n==1)]\n",
    "singles_tp = transpose(singles)\n",
    "# identify lbls with at least 500 singles\n",
    "lbl2paths = {l:[p for p in singles_tp[0] if get_lbl(p) == l] \n",
    "             for l in set(singles_tp[1])}\n",
    "lbl_subset=[]\n",
    "for lbl in lbl2paths:\n",
    "    l = len(lbl2paths[lbl])\n",
    "    if l > 500: lbl_subset += [lbl]\n",
    "# create subset of ims in lbl_subset\n",
    "subset = L(s for s in singles if s[1] in lbl_subset)\n",
    "files_subset = L(i[0] for i in subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PILImage mode=RGB size=640x482,\n",
       " TensorBBox([[359.8800, 262.5600, 529.5500, 433.3100]]),\n",
       " TensorCategory(1))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Datasets & DataLoaders ###\n",
    "# dss for im,bb,lbl\n",
    "dss_tfms = [[PILImage.create],\n",
    "            [get_bbox, TensorBBox.create],\n",
    "            [get_lbl, Categorize()]]\n",
    "splits = RandomSplitter(.15)(files_subset)\n",
    "dss = Datasets(files_subset, tfms=dss_tfms, splits=splits)\n",
    "dss.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3, 224, 224]), torch.Size([64, 1, 4]), torch.Size([64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dls\n",
    "cpu_tfms = [BBoxLabeler(), PointScaler(),\n",
    "            Resize(im_size, method=ResizeMethod.Squish), ToTensor()]\n",
    "gpu_tfms = [IntToFloatTensor(), Normalize.from_stats(*imagenet_stats)]\n",
    "dls = dss.dataloaders(bs=64, after_item=cpu_tfms, after_batch=gpu_tfms, n_inp=1)\n",
    "\n",
    "x,y,z = dls.one_batch()\n",
    "x.shape, y.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.vision.core.LabeledBBox"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Datasets & DataLoaders ###\n",
    "# dss for im,labeledbbox\n",
    "categorize = Categorize(lbl_subset)\n",
    "def get_labeledbbox(p):\n",
    "    return LabeledBBox(TensorBBox.create(get_bbox(p)), categorize(get_lbl(p)))\n",
    "dss_tfms = [[PILImage.create], [get_labeledbbox]]\n",
    "splits = RandomSplitter(.15)(files_subset)\n",
    "dss = Datasets(files_subset, tfms=dss_tfms, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls for im,labeledbbox\n",
    "cpu_tfms = [PointScaler(), Resize(im_size, method=ResizeMethod.Squish), ToTensor()]\n",
    "gpu_tfms = [IntToFloatTensor(), Normalize.from_stats(*imagenet_stats)]\n",
    "dls = dss.dataloaders(bs=64, after_item=cpu_tfms, after_batch=gpu_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224]) torch.Size([64, 1, 4]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "x,y = dls.one_batch()\n",
    "print(x.shape, y[0].shape, y[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model ###\n",
    "class custom_module(Module):\n",
    "    def __init__(self, body, head):\n",
    "        self.body, self.head = body, head\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(self.body(x))\n",
    "body = create_body(resnet34, pretrained=True)\n",
    "head = create_head(1024, 4+len(categorize.vocab), ps=0.5)\n",
    "mod = custom_module(body, head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here on down I'm exploring how my custom loss_func must be formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [TensorBBox([[[  1.2500,   0.0000, 640.0000, 480.0000]],\n",
       "\n",
       "        [[129.4300, 165.3200, 164.7900, 203.8700]],\n",
       "\n",
       "        [[ 49.9000,  62.3800, 640.0000, 229.3500]],\n",
       "\n",
       "        [[  3.1600,   2.6400, 480.8300, 420.2000]],\n",
       "\n",
       "        [[ 99.3000,  40.2600, 605.6600, 362.3200]],\n",
       "\n",
       "        [[  8.6300, 122.2500, 392.6300, 336.5400]],\n",
       "\n",
       "        [[410.4400, 125.1100, 516.0900, 238.0100]],\n",
       "\n",
       "        [[ 30.6300, 111.5600, 404.1600, 562.6800]],\n",
       "\n",
       "        [[166.1100, 103.5500, 463.8200, 429.3000]],\n",
       "\n",
       "        [[229.5700, 108.3600, 577.6000, 258.9500]],\n",
       "\n",
       "        [[216.8600,  85.4000, 492.2500, 421.2400]],\n",
       "\n",
       "        [[138.0700, 363.8700, 430.0200, 631.3700]],\n",
       "\n",
       "        [[ 99.9400, 238.2900, 159.7400, 305.7800]],\n",
       "\n",
       "        [[ 26.9700,   0.0000, 640.0000, 474.6100]],\n",
       "\n",
       "        [[159.3700,  87.9300, 329.6800, 319.7700]],\n",
       "\n",
       "        [[180.6900, 144.1400, 366.8900, 195.5000]],\n",
       "\n",
       "        [[ 90.0400,  38.0100, 409.8900, 591.1000]],\n",
       "\n",
       "        [[236.2200, 156.2200, 408.8100, 335.2800]],\n",
       "\n",
       "        [[288.3100, 127.5200, 320.5700, 159.9800]],\n",
       "\n",
       "        [[ 74.8200,  97.2400, 538.9300, 265.9500]],\n",
       "\n",
       "        [[  0.9500,  86.3300, 640.0000, 397.9400]],\n",
       "\n",
       "        [[  0.0000,  87.3800, 567.0900, 372.3700]],\n",
       "\n",
       "        [[152.4500, 195.6000, 346.6100, 595.4200]],\n",
       "\n",
       "        [[ 67.1700, 151.7500, 506.6500, 352.4200]],\n",
       "\n",
       "        [[131.1800, 386.2400, 224.3400, 527.4400]],\n",
       "\n",
       "        [[162.5200, 165.7500, 248.8100, 542.5600]],\n",
       "\n",
       "        [[289.1500, 327.5600, 345.6800, 380.0100]],\n",
       "\n",
       "        [[ 86.2900,  73.1100, 290.5200, 632.5700]],\n",
       "\n",
       "        [[186.1500, 177.5200, 640.0000, 213.9800]],\n",
       "\n",
       "        [[ 91.3000,  47.9000, 443.0500, 327.0500]],\n",
       "\n",
       "        [[  1.6900,   3.1100, 195.5100, 305.6400]],\n",
       "\n",
       "        [[145.6400, 403.7300, 235.2500, 531.9600]],\n",
       "\n",
       "        [[ 82.2300, 117.9700, 361.2000, 452.6700]],\n",
       "\n",
       "        [[343.5600, 269.8800, 457.0100, 300.9500]],\n",
       "\n",
       "        [[  0.0000, 393.3300, 612.0000, 545.9900]],\n",
       "\n",
       "        [[162.6600, 121.4800, 419.9600, 276.2700]],\n",
       "\n",
       "        [[114.4900, 175.9700, 191.4300, 249.4900]],\n",
       "\n",
       "        [[ 75.5100,  93.8400, 638.5600, 327.9100]],\n",
       "\n",
       "        [[ 82.3300, 260.3900, 204.8600, 386.7500]],\n",
       "\n",
       "        [[ 83.0600,  10.7900, 394.7900, 363.5100]],\n",
       "\n",
       "        [[ 55.0500,  66.4100, 406.0200, 473.8100]],\n",
       "\n",
       "        [[ 76.4100, 145.1800, 498.5900, 299.9200]],\n",
       "\n",
       "        [[347.7100, 126.3100, 458.8800, 236.3400]],\n",
       "\n",
       "        [[240.0000, 181.8800, 380.9900, 474.6200]],\n",
       "\n",
       "        [[227.5500, 192.3100, 307.2900, 262.8800]],\n",
       "\n",
       "        [[206.7800, 340.9400, 320.8900, 575.8300]],\n",
       "\n",
       "        [[ 97.1400, 320.0800, 267.9000, 640.0000]],\n",
       "\n",
       "        [[191.8200, 306.5300, 224.0000, 359.6200]],\n",
       "\n",
       "        [[237.3000, 362.4300, 359.5500, 632.8100]],\n",
       "\n",
       "        [[168.9700,  83.9500, 386.3700, 401.4300]],\n",
       "\n",
       "        [[  9.1500,  62.6600, 601.2500, 251.3400]],\n",
       "\n",
       "        [[257.8000, 121.8900, 446.5600, 350.5600]],\n",
       "\n",
       "        [[217.8100,  56.4600, 453.1400, 316.8600]],\n",
       "\n",
       "        [[134.8900,  55.6800, 291.3000, 210.6500]],\n",
       "\n",
       "        [[210.4400, 315.8800, 401.7600, 519.5500]],\n",
       "\n",
       "        [[ 49.4400, 124.5300, 324.7200, 449.2500]],\n",
       "\n",
       "        [[ 37.4200, 110.3500, 617.9500, 320.4900]],\n",
       "\n",
       "        [[254.6400, 138.8100, 381.9600, 252.7300]],\n",
       "\n",
       "        [[ 99.1900, 201.1200, 526.3000, 256.9600]],\n",
       "\n",
       "        [[131.8400, 134.8400, 514.7300, 238.0700]],\n",
       "\n",
       "        [[252.3500,  67.7500, 490.7400, 458.6300]],\n",
       "\n",
       "        [[ 11.1300, 182.3900, 266.3900, 617.8100]],\n",
       "\n",
       "        [[158.7000, 226.9800, 570.3500, 382.8000]],\n",
       "\n",
       "        [[115.6900, 143.1900, 306.6100, 225.7100]]], device='cuda:0'),TensorCategory([6, 5, 0, 1, 0, 7, 2, 4, 4, 2, 1, 6, 3, 4, 4, 0, 4, 4, 3, 0, 7, 1, 6, 7,\n",
       "        6, 4, 3, 6, 7, 2, 6, 6, 2, 3, 7, 0, 3, 7, 6, 4, 2, 0, 3, 6, 0, 6, 6, 3,\n",
       "        6, 1, 0, 5, 3, 0, 3, 4, 0, 3, 7, 0, 4, 2, 7, 7], device='cuda:0')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use this to check shape of y batch\n",
    "learn = Learner(dls, mod, loss_func=MSELossFlat())\n",
    "b = dls.one_batch()\n",
    "learn._split(b)\n",
    "learn.yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn.yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.vision.core.LabeledBBox"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn.yb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [TensorBBox([[[  1.2500,   0.0000, 640.0000, 480.0000]],\n",
       "\n",
       "        [[129.4300, 165.3200, 164.7900, 203.8700]],\n",
       "\n",
       "        [[ 49.9000,  62.3800, 640.0000, 229.3500]],\n",
       "\n",
       "        [[  3.1600,   2.6400, 480.8300, 420.2000]],\n",
       "\n",
       "        [[ 99.3000,  40.2600, 605.6600, 362.3200]],\n",
       "\n",
       "        [[  8.6300, 122.2500, 392.6300, 336.5400]],\n",
       "\n",
       "        [[410.4400, 125.1100, 516.0900, 238.0100]],\n",
       "\n",
       "        [[ 30.6300, 111.5600, 404.1600, 562.6800]],\n",
       "\n",
       "        [[166.1100, 103.5500, 463.8200, 429.3000]],\n",
       "\n",
       "        [[229.5700, 108.3600, 577.6000, 258.9500]],\n",
       "\n",
       "        [[216.8600,  85.4000, 492.2500, 421.2400]],\n",
       "\n",
       "        [[138.0700, 363.8700, 430.0200, 631.3700]],\n",
       "\n",
       "        [[ 99.9400, 238.2900, 159.7400, 305.7800]],\n",
       "\n",
       "        [[ 26.9700,   0.0000, 640.0000, 474.6100]],\n",
       "\n",
       "        [[159.3700,  87.9300, 329.6800, 319.7700]],\n",
       "\n",
       "        [[180.6900, 144.1400, 366.8900, 195.5000]],\n",
       "\n",
       "        [[ 90.0400,  38.0100, 409.8900, 591.1000]],\n",
       "\n",
       "        [[236.2200, 156.2200, 408.8100, 335.2800]],\n",
       "\n",
       "        [[288.3100, 127.5200, 320.5700, 159.9800]],\n",
       "\n",
       "        [[ 74.8200,  97.2400, 538.9300, 265.9500]],\n",
       "\n",
       "        [[  0.9500,  86.3300, 640.0000, 397.9400]],\n",
       "\n",
       "        [[  0.0000,  87.3800, 567.0900, 372.3700]],\n",
       "\n",
       "        [[152.4500, 195.6000, 346.6100, 595.4200]],\n",
       "\n",
       "        [[ 67.1700, 151.7500, 506.6500, 352.4200]],\n",
       "\n",
       "        [[131.1800, 386.2400, 224.3400, 527.4400]],\n",
       "\n",
       "        [[162.5200, 165.7500, 248.8100, 542.5600]],\n",
       "\n",
       "        [[289.1500, 327.5600, 345.6800, 380.0100]],\n",
       "\n",
       "        [[ 86.2900,  73.1100, 290.5200, 632.5700]],\n",
       "\n",
       "        [[186.1500, 177.5200, 640.0000, 213.9800]],\n",
       "\n",
       "        [[ 91.3000,  47.9000, 443.0500, 327.0500]],\n",
       "\n",
       "        [[  1.6900,   3.1100, 195.5100, 305.6400]],\n",
       "\n",
       "        [[145.6400, 403.7300, 235.2500, 531.9600]],\n",
       "\n",
       "        [[ 82.2300, 117.9700, 361.2000, 452.6700]],\n",
       "\n",
       "        [[343.5600, 269.8800, 457.0100, 300.9500]],\n",
       "\n",
       "        [[  0.0000, 393.3300, 612.0000, 545.9900]],\n",
       "\n",
       "        [[162.6600, 121.4800, 419.9600, 276.2700]],\n",
       "\n",
       "        [[114.4900, 175.9700, 191.4300, 249.4900]],\n",
       "\n",
       "        [[ 75.5100,  93.8400, 638.5600, 327.9100]],\n",
       "\n",
       "        [[ 82.3300, 260.3900, 204.8600, 386.7500]],\n",
       "\n",
       "        [[ 83.0600,  10.7900, 394.7900, 363.5100]],\n",
       "\n",
       "        [[ 55.0500,  66.4100, 406.0200, 473.8100]],\n",
       "\n",
       "        [[ 76.4100, 145.1800, 498.5900, 299.9200]],\n",
       "\n",
       "        [[347.7100, 126.3100, 458.8800, 236.3400]],\n",
       "\n",
       "        [[240.0000, 181.8800, 380.9900, 474.6200]],\n",
       "\n",
       "        [[227.5500, 192.3100, 307.2900, 262.8800]],\n",
       "\n",
       "        [[206.7800, 340.9400, 320.8900, 575.8300]],\n",
       "\n",
       "        [[ 97.1400, 320.0800, 267.9000, 640.0000]],\n",
       "\n",
       "        [[191.8200, 306.5300, 224.0000, 359.6200]],\n",
       "\n",
       "        [[237.3000, 362.4300, 359.5500, 632.8100]],\n",
       "\n",
       "        [[168.9700,  83.9500, 386.3700, 401.4300]],\n",
       "\n",
       "        [[  9.1500,  62.6600, 601.2500, 251.3400]],\n",
       "\n",
       "        [[257.8000, 121.8900, 446.5600, 350.5600]],\n",
       "\n",
       "        [[217.8100,  56.4600, 453.1400, 316.8600]],\n",
       "\n",
       "        [[134.8900,  55.6800, 291.3000, 210.6500]],\n",
       "\n",
       "        [[210.4400, 315.8800, 401.7600, 519.5500]],\n",
       "\n",
       "        [[ 49.4400, 124.5300, 324.7200, 449.2500]],\n",
       "\n",
       "        [[ 37.4200, 110.3500, 617.9500, 320.4900]],\n",
       "\n",
       "        [[254.6400, 138.8100, 381.9600, 252.7300]],\n",
       "\n",
       "        [[ 99.1900, 201.1200, 526.3000, 256.9600]],\n",
       "\n",
       "        [[131.8400, 134.8400, 514.7300, 238.0700]],\n",
       "\n",
       "        [[252.3500,  67.7500, 490.7400, 458.6300]],\n",
       "\n",
       "        [[ 11.1300, 182.3900, 266.3900, 617.8100]],\n",
       "\n",
       "        [[158.7000, 226.9800, 570.3500, 382.8000]],\n",
       "\n",
       "        [[115.6900, 143.1900, 306.6100, 225.7100]]], device='cuda:0'),TensorCategory([6, 5, 0, 1, 0, 7, 2, 4, 4, 2, 1, 6, 3, 4, 4, 0, 4, 4, 3, 0, 7, 1, 6, 7,\n",
       "        6, 4, 3, 6, 7, 2, 6, 6, 2, 3, 7, 0, 3, 7, 6, 4, 2, 0, 3, 6, 0, 6, 6, 3,\n",
       "        6, 1, 0, 5, 3, 0, 3, 4, 0, 3, 7, 0, 4, 2, 7, 7], device='cuda:0')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from doc(Learner._split) – if n_inp=1, xb = b[0] and yb=b[1:].\n",
    "    def _split(self, b):\n",
    "        i = getattr(self.dls, 'n_inp', 1 if len(b)==1 else len(b)-1)\n",
    "        self.xb,self.yb = b[:i],b[i:]\n",
    "\n",
    "# from doc(Learner._do_one_batch). Notice that self.loss_func is passed (pred, *yb). My custom loss will conform.\n",
    "    def _do_one_batch(self):\n",
    "        self.pred = self.model(*self.xb)\n",
    "        self('after_pred')\n",
    "        if len(self.yb): self.loss = self.loss_func(self.pred, *self.yb) # here it is\n",
    "        self('after_loss')\n",
    "        if not self.training or not len(self.yb): return\n",
    "        self('before_backward')\n",
    "        self._backward()\n",
    "        self('after_backward')\n",
    "        self._step()\n",
    "        self('after_step')\n",
    "        self.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to pause for now. I think the way forward is to make my loss function work for dss=im,bb,lbl; not im,lblbb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeledbbox_loss(input, target):\n",
    "    # RMSE\n",
    "    ...\n",
    "    # CEL\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train ###\n",
    "lr_min, _ = learn.lr_find()\n",
    "# learn.fit_one_cycle(10, lr=lr_min)\n",
    "# learn.save(...)\n",
    "\n",
    "def show_preds(dss=dss, inf=inf, pipe=pipe, n=8, offset=0, nrows=2, ncols=4, sz=224):\n",
    "    ctxs = get_grid(n, nrows, ncols)\n",
    "    for i,ctx in enumerate(ctxs):\n",
    "        im,bb = pipe(dss[i+offset]) # tfms for resizing ims and bbs\n",
    "        pred = inf.predict(im)\n",
    "        show_image(im, ctx=ctx)\n",
    "        ((bb+1)*sz//2).show(ctx=ctx)\n",
    "        pred[0].show(ctx=ctx, color='magenta')\n",
    "# p = Pipeline([PointScaler(), Resize(im_size, method=ResizeMethod.Squish)])\n",
    "# inf = load_learner('_20201002_coco_tensorbox_learner_20201005.pkl')\n",
    "# show_preds(dss, inf, p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
