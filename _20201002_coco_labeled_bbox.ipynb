{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Building-&amp;-training-the-model\" data-toc-modified-id=\"Building-&amp;-training-the-model-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Building &amp; training the model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building & training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "\n",
    "### Params ###\n",
    "im_size      = 224\n",
    "batch_size   = 64\n",
    "path         = Path('/home/rory/data/coco2017')\n",
    "train_json   = 'annotations/instances_train2017.json'\n",
    "valid_json   = 'annotations/instances_val2017.json'\n",
    "train_im_dir = 'train2017'\n",
    "valid_im_dir = 'val2017'\n",
    "\n",
    "\n",
    "### Get files and annos ###\n",
    "def get_annos(path, anno_file, im_folder):\n",
    "    xs, ys = get_annotations(path/anno_file)\n",
    "    return L(xs).map(lambda x: path/im_folder/x), ys\n",
    "train_files, train_annos = get_annos(path, train_json, train_im_dir)\n",
    "valid_files, valid_annos = get_annos(path, valid_json, valid_im_dir)\n",
    "files  = train_files + valid_files\n",
    "annos  = train_annos + valid_annos\n",
    "bboxes = [a[0] for a in annos]\n",
    "lbls   = [a[1] for a in annos]\n",
    "\n",
    "\n",
    "### Get largest anno ###\n",
    "def transpose(anno): return list(zip(*anno)) # tensor.t()\n",
    "def bbox_area(transposed_anno):\n",
    "    b = transposed_anno[0]\n",
    "    return((b[2]-b[0])*(b[3]-b[1])) # b-t * l-r\n",
    "def sort_annos(o): return sorted(transpose(o), key=bbox_area, reverse=True)\n",
    "sorted_annos = L(sort_annos(i) for i in annos)\n",
    "largest_anno = L(i[0] for i in sorted_annos)\n",
    "largest_bbox = L(i[0] for i in largest_anno)\n",
    "largest_lbl  = L(i[1] for i in largest_anno)\n",
    "# get_xyz helpers (used in following sections)\n",
    "files2lbl  = {f:l for f,l in zip(files,largest_lbl)}\n",
    "files2bbox = {f:b for f,b in zip(files,largest_bbox)}\n",
    "def get_lbl(f):  return files2lbl[f]\n",
    "def get_bbox(f): return files2bbox[f]\n",
    "\n",
    "\n",
    "### Get singles ###\n",
    "# identify singles\n",
    "lbls_per_im = L(len(l) for l in lbls)\n",
    "tuples = L(zip(files, largest_lbl, largest_bbox))\n",
    "singles = tuples[lbls_per_im.map(lambda n:n==1)]\n",
    "singles_tp = transpose(singles)\n",
    "# identify lbls with at least 500 singles\n",
    "lbl2paths = {l:[p for p in singles_tp[0] if get_lbl(p) == l] \n",
    "             for l in set(singles_tp[1])}\n",
    "lbl_subset=[]\n",
    "for lbl in lbl2paths:\n",
    "    l = len(lbl2paths[lbl])\n",
    "    if l > 500: lbl_subset += [lbl]\n",
    "# create subset of ims in lbl_subset\n",
    "subset = L(s for s in singles if s[1] in lbl_subset)\n",
    "files_subset = L(i[0] for i in subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Datasets & DataLoaders ###\n",
    "# dss for im,bb,lbl\n",
    "dss_tfms = [[PILImage.create],\n",
    "            [get_bbox, TensorBBox.create],\n",
    "            [get_lbl, Categorize()]]\n",
    "splits = RandomSplitter(.15)(files_subset)\n",
    "dss = Datasets(files_subset, tfms=dss_tfms, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental: dss for im,lblbb\n",
    "# def get_labeledbbox(p):\n",
    "#     return LabeledBBox(TensorBBox([get_bbox(p)]), [get_lbl(p)])\n",
    "# dss_tfms = [[PILImage.create], [get_labeledbbox]]\n",
    "# splits = RandomSplitter(.15)(files_subset)\n",
    "# dss = Datasets(files_subset, tfms=dss_tfms, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PILImage mode=RGB size=640x427,\n",
       " TensorBBox([[ 92.1200, 113.2300, 640.0000, 361.7500]]),\n",
       " TensorCategory(7))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dss.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls\n",
    "cpu_tfms = [BBoxLabeler(), PointScaler(), Resize(im_size, method=ResizeMethod.Squish), ToTensor()]\n",
    "gpu_tfms = [IntToFloatTensor(), Normalize()]\n",
    "dls = dss.dataloaders(bs=64, after_item=cpu_tfms, after_batch=gpu_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2.0032,  2.0184,  2.0335,  ..., -0.8235, -0.7782, -0.6421],\n",
       "          [ 1.9881,  2.0184,  2.0335,  ..., -0.8991, -0.8235, -0.7328],\n",
       "          [ 1.9730,  2.0184,  2.0335,  ..., -0.9596, -0.8689, -0.7933],\n",
       "          ...,\n",
       "          [-1.4282, -1.3828, -1.3375,  ..., -1.0200, -1.1258, -1.2014],\n",
       "          [-1.4735, -1.3828, -1.3375,  ..., -0.9747, -1.0654, -1.1410],\n",
       "          [-1.4433, -1.3526, -1.3072,  ..., -0.9596, -1.0049, -1.0654]],\n",
       " \n",
       "         [[ 1.9981,  1.9981,  1.9981,  ..., -0.5758, -0.5167, -0.3983],\n",
       "          [ 1.9833,  1.9833,  1.9981,  ..., -0.6942, -0.6054, -0.5167],\n",
       "          [ 1.9537,  1.9833,  1.9981,  ..., -0.7681, -0.6794, -0.5906],\n",
       "          ...,\n",
       "          [-1.3450, -1.3303, -1.3007,  ..., -1.0936, -1.2119, -1.2267],\n",
       "          [-1.3598, -1.3303, -1.2859,  ..., -1.0492, -1.1527, -1.1823],\n",
       "          [-1.3894, -1.3155, -1.2859,  ..., -1.0048, -1.0936, -1.1232]],\n",
       " \n",
       "         [[ 1.8727,  1.8859,  1.8859,  ..., -0.4608, -0.4873, -0.3415],\n",
       "          [ 1.8727,  1.8727,  1.8859,  ..., -0.5934, -0.6199, -0.5536],\n",
       "          [ 1.8727,  1.8727,  1.8727,  ..., -0.6597, -0.6597, -0.6464],\n",
       "          ...,\n",
       "          [-1.2563, -1.2563, -1.2298,  ..., -1.0044, -1.1104, -1.1900],\n",
       "          [-1.2961, -1.2563, -1.2430,  ..., -0.9911, -1.0839, -1.1635],\n",
       "          [-1.3093, -1.2430, -1.2165,  ..., -0.9514, -1.0309, -1.1104]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.8330, -0.8069,  0.5917,  1.0000]], device='cuda:0'),\n",
       " tensor(4, device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,z = dls.one_batch()\n",
    "i=0; x[i],y[i],z[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model & Loss ### (i'm using siamese example)\n",
    "class custom_module(Module):\n",
    "    def __init__(self, encoder, head):\n",
    "        self.encoder, self.head = encoder, head\n",
    "\n",
    "    def forward(self, x):\n",
    "        params = self.encoder(x)\n",
    "        return self.head(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = create_body(resnet34)\n",
    "head = create_head(512*2*2, 2, ps=0.5)\n",
    "mod = custom_module(enc, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train ###\n",
    "lr_min, _ = learn.lr_find()\n",
    "\n",
    "learn.fit_one_cycle(10, lr=lr_min) # valid_loss of .0786 after 9 epochs\n",
    "\n",
    "### Showing results ###\n",
    "def _descale(x,sz): return (x+1)*sz//2\n",
    "def show_learner_results(learner, n=4, nrows=1, ncols=4, sz=224):\n",
    "    xb, yb = learner.dls.one_batch()\n",
    "    yp = learner.model(xb) # this is GPU hungry; need to get inference on one item\n",
    "    xb, yb, yp = xb.cpu(), yb.cpu(), yp.cpu()\n",
    "    \n",
    "    ctxs = get_grid(n, nrows, ncols)\n",
    "    for i,ctx in enumerate(ctxs):\n",
    "        im, actual, forecast  = xb[i], yb[i], yp[i]\n",
    "        loss = learner.loss_func(actual, forecast).item()\n",
    "        \n",
    "        im = F.relu(_descale(im.int(),sz))\n",
    "        actual = TensorBBox(_descale(actual,sz))\n",
    "        forecast = TensorBBox(_descale(forecast,sz))\n",
    "\n",
    "        show_image(im, ctx=ctx, title=f'Loss: {round(loss,4)}')\n",
    "        actual.show(ctx=ctx, color='magenta')\n",
    "        forecast.show(ctx=ctx)\n",
    "show_learner_results(learn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
