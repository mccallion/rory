{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Improvements-pursued-in-this-notebook\" data-toc-modified-id=\"Improvements-pursued-in-this-notebook-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Improvements pursued in this notebook</a></span></li><li><span><a href=\"#MNIST-Basics:-Final-Code\" data-toc-modified-id=\"MNIST-Basics:-Final-Code-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>MNIST Basics: Final Code</a></span></li><li><span><a href=\"#Downloading-new-data\" data-toc-modified-id=\"Downloading-new-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Downloading new data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvements pursued in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Add RGB\n",
    "- Change from binary classifier to multi category classifier:\n",
    "    - add ims 0-9\n",
    "    - add change loss fxn to cross entropy loss w/ softmax\n",
    "    - change shape of final activation from 1 to 10\n",
    "    - change label to 1HE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Basics: Final Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports ###\n",
    "from fastai.vision.all import *\n",
    "from fastcore.test import *\n",
    "\n",
    "\n",
    "### Data ###\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path\n",
    "\n",
    "# train\n",
    "train3 = torch.stack( \n",
    "    [tensor(Image.open(o)) for o in (path/'train'/'3').ls()]         # Create list of 6131 28x28 im tensors, and\n",
    "    ).float()/255                                                    ## stack them into one [6131,28,28] tensor.\n",
    "train7 = torch.stack(\n",
    "    [tensor(Image.open(o)) for o in (path/'train'/'7').ls()]         # Repeat for sevens.\n",
    "    ).float()/255\n",
    "train_ims = torch.cat([train3,train7]).view(-1, 28*28)               # Combine 3s a& 7s then reshape as [6131,786].\n",
    "train_lbls = tensor([1]*len(train3) + [0]*len(train7)).unsqueeze(1)  # Create lbl tensors: 1 if im is 3 else 0.\n",
    "train_ds = list(zip(train_ims,train_lbls))                           # Zip im,lbl to create dataset.\n",
    "train_dl = DataLoader(train_ds, batch_size = 64*2*2*2, shuffle=True) # Create batches; create DataLoader (an iter).\n",
    "\n",
    "# valid\n",
    "valid3 = torch.stack(\n",
    "    [tensor(Image.open(o)) for o in (path/'valid'/'3').ls()]\n",
    "    ).float()/255\n",
    "valid7 = torch.stack(\n",
    "    [tensor(Image.open(o)) for o in (path/'valid'/'7').ls()]\n",
    "    ).float()/255\n",
    "valid_ims = torch.cat([valid3,valid7]).view(-1, 28*28)\n",
    "valid_lbls = tensor([1]*len(valid3) + [0]*len(valid7)).unsqueeze(1)\n",
    "valid_ds = list(zip(valid_ims,valid_lbls))\n",
    "valid_dl = DataLoader(valid_ds, batch_size = 64*2*2*2, shuffle=True)\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl)\n",
    "\n",
    "\n",
    "### Mini-batch Average Accuracy given yp,y ###\n",
    "def avg_batch_acc(yp,y):\n",
    "    sig_yp = yp.sigmoid()\n",
    "    correct = (sig_yp > 0.5) == y\n",
    "    return correct.float().mean()\n",
    "\n",
    "\n",
    "### Loss Function \"Calibrated Confidence\" ###\n",
    "def loss(yp, y):                                  # I like to call this \"Calibrated Confidence\":\n",
    "    pred = yp.sigmoid()                           # - correct   & high confidence → low loss\n",
    "    return torch.where(y==1, 1-pred, pred).mean() # - incorrect & high confidence → high loss\n",
    "\n",
    "\n",
    "## Model ###\n",
    "three_layer_nn = nn.Sequential( # nn.Sequential composes fxns. Each fxn is a layer, ∴ this is a 3 layer nn.\n",
    "    nn.Linear(28*28,30),        # nn.Linear creates linear parameters W and B as in Y = X@W+B.\n",
    "    nn.ReLU(),                  # nn.Linear is a class. When called, it's __main__(x) function computes X@W+B.\n",
    "    nn.Linear(30,1))            # nn.ReLU is the same as item-wise max(t, 0), which replaces all negs with 0s.\n",
    "\n",
    "\n",
    "### Combine data, model, stepper, loss, accuracy in a Learner ###\n",
    "learn = Learner(dls,                   # train and valid dls\n",
    "                three_layer_nn,        # model\n",
    "                opt_func=SGD,          # fastai.SGD optimizer\n",
    "                loss_func=loss,        # loss fxn\n",
    "                metrics=avg_batch_acc) # judgement metric\n",
    "\n",
    "### Train ###\n",
    "epochs = 40\n",
    "lr = 0.1\n",
    "learn.fit(epochs,lr)\n",
    "plt.plot(L(learn.recorder.values).itemgot(2)) # L.itemgot(2) returns every 2nd row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super-short version with all of the helpers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.056472</td>\n",
       "      <td>0.009414</td>\n",
       "      <td>0.998037</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path\n",
    "\n",
    "dls = ImageDataLoaders.from_folder(path)\n",
    "learn = cnn_learner(dls, resnet18, pretrained=False, loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "### Data ###\n",
    "path = untar_data(URLs.MNIST)\n",
    "n_cls = 10\n",
    "batch_size = 64*2*2*2\n",
    "\n",
    "# Train\n",
    "# ims\n",
    "for i in range(n_cls):\n",
    "    new_ims = torch.stack(\n",
    "        [tensor(Image.open(fn)) for fn in (path/'training'/f'{i}').ls()]\n",
    "    ).float()/255\n",
    "    if i == 0: ims = new_ims\n",
    "    else: ims = torch.cat([ims,new_ims])\n",
    "train_ims = ims.view(-1,28*28)\n",
    "# lbls\n",
    "train_lbls = []\n",
    "for i in range(n_cls):\n",
    "    l = L([0]*n_cls)\n",
    "    l[i] = 1\n",
    "    lbls += [l] * len((path/'training'/f'{i}').ls())    \n",
    "train_lbls = tensor(lbls)\n",
    "\n",
    "# Valid\n",
    "# ims\n",
    "for i in range(n_cls):\n",
    "    new_ims = torch.stack(\n",
    "        [tensor(Image.open(fn)) for fn in (path/'testing'/f'{i}').ls()]\n",
    "    ).float()/255\n",
    "    if i == 0: ims = new_ims\n",
    "    else: ims = torch.cat([ims,new_ims])\n",
    "valid_ims = ims.view(-1,28*28)\n",
    "# lbls\n",
    "valid_lbls = []\n",
    "for i in range(n_cls):\n",
    "    l = L([0]*n_cls)\n",
    "    l[i] = 1\n",
    "    lbls += [l] * len((path/'testing'/f'{i}').ls())    \n",
    "valid_lbls = tensor(lbls)\n",
    "\n",
    "# DataLoaders\n",
    "train_ds = L(zip(train_ims, train_lbls))\n",
    "valid_ds = L(zip(valid_ims, valid_lbls))\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = nn.Linear(10,10)\n",
    "list(mod.parameters())[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model ###\n",
    "three_layer_nn = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loss Function ###\n",
    "def loss(yp, y):\n",
    "    pred = yp.sigmoid()\n",
    "    return torch.where(y==1, 1-pred, pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mini-batch Average Accuracy given yp,y ###\n",
    "def avg_batch_acc(yp,y):\n",
    "    sig_yp = yp.sigmoid()\n",
    "    correct = (sig_yp > 0.5) == y\n",
    "    return correct.float().mean()\n",
    "\n",
    "\n",
    "### Combine data, model, stepper, loss, accuracy in a Learner ###\n",
    "learn = Learner(dls,                   # train and valid dls\n",
    "                three_layer_nn,        # model\n",
    "                opt_func=SGD,          # fastai.SGD optimizer\n",
    "                loss_func=loss,        # loss fxn\n",
    "                metrics=avg_batch_acc) # judgement metric\n",
    "\n",
    "### Train ###\n",
    "epochs = 40\n",
    "lr = 0.1\n",
    "learn.fit(epochs,lr)\n",
    "plt.plot(L(learn.recorder.values).itemgot(2)) # L.itemgot(2) returns every 2nd row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
