{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data</a></span></li><li><span><a href=\"#Code\" data-toc-modified-id=\"Code-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Code</a></span><ul class=\"toc-item\"><li><span><a href=\"#JH\" data-toc-modified-id=\"JH-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>JH</a></span></li></ul></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Train</a></span><ul class=\"toc-item\"><li><span><a href=\"#With-scaling-preds\" data-toc-modified-id=\"With-scaling-preds-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>With scaling preds</a></span></li><li><span><a href=\"#Without-scaling-preds\" data-toc-modified-id=\"Without-scaling-preds-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Without scaling preds</a></span></li></ul></li><li><span><a href=\"#Stepping-Through-a-Batch\" data-toc-modified-id=\"Stepping-Through-a-Batch-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Stepping Through a Batch</a></span><ul class=\"toc-item\"><li><span><a href=\"#JH\" data-toc-modified-id=\"JH-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>JH</a></span><ul class=\"toc-item\"><li><span><a href=\"#Init\" data-toc-modified-id=\"Init-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Init</a></span></li><li><span><a href=\"#Get-batch,-acts,-item\" data-toc-modified-id=\"Get-batch,-acts,-item-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Get batch, acts, item</a></span></li><li><span><a href=\"#ssd-item-loss\" data-toc-modified-id=\"ssd-item-loss-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>ssd item loss</a></span></li><li><span><a href=\"#lbl-loss\" data-toc-modified-id=\"lbl-loss-4.1.4\"><span class=\"toc-item-num\">4.1.4&nbsp;&nbsp;</span>lbl loss</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**~ My Code ~**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports & Paths ###\n",
    "from fastai.vision.all import *\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def random_seed(s, use_cuda):\n",
    "    #Also, remember to use num_workers=0 when creating the DataBunch\n",
    "    np.random.seed(s)\n",
    "    torch.manual_seed(s)\n",
    "    random.seed(s)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(s)\n",
    "        torch.cuda.manual_seed_all(s)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False      \n",
    "random_seed(42,True)\n",
    "\n",
    "\n",
    "### Params ###\n",
    "im_sz   = 224\n",
    "bs      = 64\n",
    "val_pct = .2\n",
    "sub_pct = 1\n",
    "path = untar_data(URLs.PASCAL_2007)\n",
    "annos_path = path/'train.json'\n",
    "ims_path = path/'train'\n",
    "\n",
    "\n",
    "### Items ###\n",
    "fns, annos = get_annotations(annos_path)\n",
    "fn2anno = {f:a for f,a in zip(fns,annos)}\n",
    "def get_im(f):   return ims_path/f\n",
    "def get_bbox(f): return fn2anno[f][0]\n",
    "def get_lbl(f):  return fn2anno[f][1]\n",
    "\n",
    "\n",
    "### DataLoaders ###\n",
    "itfms = Resize(im_sz, method='squish')\n",
    "btfms = setup_aug_tfms([Rotate(), Brightness(), Contrast(), Flip(),\n",
    "                       Normalize.from_stats(*imagenet_stats)])\n",
    "db = DataBlock(\n",
    "    blocks=[ImageBlock, BBoxBlock, BBoxLblBlock(add_na=False)],\n",
    "    get_x=get_im, get_y=[get_bbox, get_lbl], n_inp=1,\n",
    "    splitter=RandomSplitter(val_pct),\n",
    "    item_tfms=itfms, batch_tfms=btfms)\n",
    "subset = L(fns).shuffle()[0:int(len(fns)*sub_pct)]\n",
    "# dls = db.dataloaders(subset, bs=bs)\n",
    "dls = db.dataloaders(fns, bs=bs, seed=42)\n",
    "dls.v = dls.vocab\n",
    "dls.ncls = len(dls.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: (#20) ['aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair','cow'...]\n",
      "Size of train data: 2001\n",
      "Size of valid data: 500\n",
      "batch[0]: \t torch.float32 \t torch.Size([64, 3, 224, 224])\n",
      "batch[1]: \t torch.float32 \t torch.Size([64, 12, 4])\n",
      "batch[2]: \t torch.int64 \t torch.Size([64, 12])\n"
     ]
    }
   ],
   "source": [
    "### Inspection ###\n",
    "print(\"Vocab:\", dls.v)\n",
    "print(\"Size of train data:\",len(dls.train.items))\n",
    "print(\"Size of valid data:\",len(dls.valid.items))\n",
    "for i,t in enumerate(dls.one_batch()):\n",
    "    print(f\"batch[{i}]:\",'\\t',t.dtype,'\\t',t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of tensor shapes:\n",
    "- torch.Size([128, 3, 224, 224]): bs, channels (rgb), im_sz, im_sz\n",
    "- torch.Size([128, 20, 4]): bs, max objs for a single im in batch, bb coords\n",
    "- torch.Size([128, 20]): bs, max objs for a single im in batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Anchors ###\n",
    "anc_grids = [4,2,1]\n",
    "# anc_grids = [4]\n",
    "anc_zooms = [0.75, 1., 1.3]\n",
    "# anc_zooms = [1.]\n",
    "anc_ratios = [(1.,1.), (1.,0.5), (0.5,1.)]\n",
    "# anc_ratios = [(1.,1.)]\n",
    "anchor_scales = [(anz*i,anz*j) for anz in anc_zooms for (i,j) in anc_ratios]\n",
    "k = len(anchor_scales)\n",
    "anc_offsets = [1/(o*2) for o in anc_grids]\n",
    "anc_x = np.concatenate([np.tile(np.linspace(ao, 1-ao, ag), ag)\n",
    "                        for ao,ag in zip(anc_offsets,anc_grids)])\n",
    "anc_y = np.concatenate([np.repeat(np.linspace(ao, 1-ao, ag), ag)\n",
    "                        for ao,ag in zip(anc_offsets,anc_grids)])\n",
    "anc_ctrs = np.repeat(np.stack([anc_x,anc_y], axis=1), k, axis=0)\n",
    "anc_sizes  =   np.concatenate([np.array([[o/ag,p/ag] for i in range(ag*ag) for o,p in anchor_scales])\n",
    "               for ag in anc_grids])\n",
    "grid_sizes = tensor(np.concatenate([np.array([ 1/ag       for i in range(ag*ag) for o,p in anchor_scales])\n",
    "               for ag in anc_grids]), requires_grad=False).unsqueeze(1)\n",
    "anchors = tensor(np.concatenate([anc_ctrs, anc_sizes], axis=1), requires_grad=False).float()\n",
    "\n",
    "def hw2corners(ctr, hw): return torch.cat([ctr-hw/2,ctr+hw/2], dim=1)\n",
    "anchor_cnr = hw2corners(anchors[:,:2], anchors[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Architecture ###\n",
    "class StdConv(nn.Module):\n",
    "    def __init__(self, n_in, n_out, stride=2, dp=0.1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(n_in,n_out,3,stride=stride,padding=1)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        self.dropout = nn.Dropout(dp)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.dropout(self.bn(F.relu(self.conv(x))))\n",
    "    \n",
    "def flatten_conv(x,k):\n",
    "    bs,nf,gx,gy = x.size()\n",
    "    x = x.permute(0,2,3,1).contiguous()\n",
    "    return x.view(bs,-1,nf//k)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, k, n_in, bias):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.bbs  = nn.Conv2d(n_in,            4*k, 3, padding=1)\n",
    "        self.lbls = nn.Conv2d(n_in, (dls.ncls+1)*k, 3, padding=1)\n",
    "        self.lbls.bias.data.zero_().add_(bias)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return [flatten_conv(self.bbs(x),  self.k),\n",
    "                flatten_conv(self.lbls(x), self.k)]\n",
    "    \n",
    "class SSD_MultiHead(nn.Module):\n",
    "    def __init__(self, k, bias=-4., drop=0.4):\n",
    "        super().__init__()\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.sconv1 = StdConv(512,256, dp=drop)\n",
    "        self.sconv2 = StdConv(256,256, dp=drop)\n",
    "        self.sconv3 = StdConv(256,256, dp=drop)\n",
    "        self.out1 = OutConv(k, 256, bias)\n",
    "        self.out2 = OutConv(k, 256, bias)\n",
    "        self.out3 = OutConv(k, 256, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop(F.relu(x))\n",
    "        x = self.sconv1(x)\n",
    "        bbs1,lbls1 = self.out1(x)\n",
    "        x = self.sconv2(x)\n",
    "        bbs2,lbls2 = self.out2(x)\n",
    "        x = self.sconv3(x)\n",
    "        bbs3,lbls3 = self.out3(x)\n",
    "        return [torch.cat([ bbs1, bbs2, bbs3], dim=1),\n",
    "                torch.cat([lbls1,lbls2,lbls3], dim=1)]\n",
    "    \n",
    "class CustMod(Module):\n",
    "    \"\"\"A module made from a pretrained body and an untrained head.\"\"\"\n",
    "    def __init__(self, body, head):\n",
    "        self.body, self.head = body, head\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.head(self.body(x))\n",
    "\n",
    "    \n",
    "    \n",
    "### FocalLoss ###\n",
    "def one_hot_embedding(labels, num_classes):\n",
    "    return torch.eye(num_classes)[labels.data].to(device)\n",
    "\n",
    "class BCE_Loss(nn.Module):\n",
    "    def __init__(self, num_classes, device):\n",
    "        super().__init__()\n",
    "        self.num_classes, self.device = num_classes, device\n",
    "    \n",
    "    def forward(self, preds, targets):\n",
    "        t = one_hot_embedding(targets, self.num_classes+1)\n",
    "        t = tensor(t[:,:-1].contiguous())\n",
    "        x = preds[:,:-1]\n",
    "        w = self.get_weight(x,t).detach()\n",
    "        return F.binary_cross_entropy_with_logits(x, t, w, reduction='sum') / self.num_classes\n",
    "    \n",
    "    def get_weight(self,x,t):\n",
    "        return None\n",
    "\n",
    "class FocalLoss(BCE_Loss):\n",
    "    def get_weight(self,x,t):\n",
    "        alpha,gamma = 0.25,2.\n",
    "        p = x.sigmoid()\n",
    "        pt = p*t + (1-p)*(1-t)\n",
    "        w = alpha*t + (1-alpha)*(1-t)\n",
    "        return w * (1-pt).pow(gamma)\n",
    "\n",
    "    \n",
    "### IoU ###\n",
    "def intersection(box_a,box_b):\n",
    "    min_xy = torch.max(box_a[:,None,:2],box_b[None,:,:2])\n",
    "    max_xy = torch.min(box_a[:,None,2:],box_b[None,:,2:])\n",
    "    inter = torch.clamp(max_xy-min_xy,min=0)\n",
    "    return inter[:,:,0] * inter[:,:,1]\n",
    "def get_size(box):\n",
    "    return (box[:,2]-box[:,0]) * (box[:,3] - box[:,1])\n",
    "def jaccard(box_a,box_b):\n",
    "    inter = intersection(box_a,box_b)\n",
    "    union = get_size(box_a).unsqueeze(1) + get_size(box_b).unsqueeze(0) - inter\n",
    "    return inter/union\n",
    "\n",
    "\n",
    "### ssd_loss ###\n",
    "def get_y(bbox,clas):\n",
    "    bbox = bbox.view(-1,4)\n",
    "    bb_keep = ((bbox[:,2] - bbox[:,0])>0.).nonzero()[:,0]\n",
    "    return bbox[bb_keep], clas[bb_keep]\n",
    "    \n",
    "def actn_to_bb(actn, anchors):\n",
    "    actn_bbs = torch.tanh(actn)\n",
    "    actn_ctrs = (actn_bbs.cuda()[:,:2] * grid_sizes.cuda()/2) + anchors.cuda()[:,:2]\n",
    "    actn_hw = (1 + actn_bbs.cuda()[:,2:]/2) * anchors.cuda()[:,2:]\n",
    "    return hw2corners(actn_ctrs,actn_hw)\n",
    "\n",
    "def map_to_ground_truth(overlaps, print_it=False):\n",
    "    prior_overlap, prior_idx = overlaps.max(1)\n",
    "    if print_it: print(prior_overlap)\n",
    "    gt_overlap, gt_idx = overlaps.max(0)\n",
    "    gt_overlap[prior_idx] = 1.99\n",
    "    for i,o in enumerate(prior_idx): gt_idx[o] = i\n",
    "    return gt_overlap,gt_idx\n",
    "\n",
    "def ssd_1_loss(b_bb, b_c, bbox, clas, print_it=False, use_ab=True):\n",
    "    bbox,clas = get_y(bbox,clas)\n",
    "    a_ic = actn_to_bb(b_bb, anchors)\n",
    "    overlaps = jaccard(bbox.data, (anchor_cnr.cuda() if use_ab else a_ic).data)\n",
    "    gt_overlap,gt_idx = map_to_ground_truth(overlaps)\n",
    "    gt_clas = clas[gt_idx]\n",
    "    pos = gt_overlap > 0.4\n",
    "    pos_idx = torch.nonzero(pos)[:,0]\n",
    "    gt_clas[~pos] = dls.ncls\n",
    "    gt_bbox = bbox[gt_idx]\n",
    "    loc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\n",
    "    clas_loss  = loss_f(b_c, gt_clas)\n",
    "    return loc_loss, clas_loss\n",
    "\n",
    "def ssd_loss(acts, bbs, lbls, print_it=False):\n",
    "    bb_sum, lbl_sum = 0., 0.\n",
    "    for abb, albl, bb, lbl in zip(*acts, bbs, lbls):\n",
    "        bb_loss, lbl_loss = ssd_1_loss(abb, albl, bb, lbl, print_it)\n",
    "        bb_sum += bb_loss\n",
    "        lbl_sum += lbl_loss\n",
    "    met.bb.append(bb_sum)\n",
    "    met.lbl.append(lbl_sum)\n",
    "    return bb_sum + lbl_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowLosses(Metric):\n",
    "    \n",
    "    def __init__(self): self.bb,self.lbl = [],[]\n",
    "        \n",
    "    def reset(self):    self.bb,self.lbl = [],[] \n",
    "        \n",
    "    def accumulate(self, learn): pass\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        bb_loss  = round((sum(self.bb )/len(self.bb )).item(), 2)\n",
    "        lbl_loss = round((sum(self.lbl)/len(self.lbl)).item(), 2)\n",
    "        return bb_loss, lbl_loss\n",
    "    \n",
    "    @property\n",
    "    def name(self): return \"MAE, Focal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With scaling preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device='cuda'\n",
    "# size = im_sz\n",
    "# body = create_body(resnet34, pretrained=True)\n",
    "# head = SSD_MultiHead(k, -4.)\n",
    "# mod = CustMod(body, head)\n",
    "# loss_f = FocalLoss(dls.ncls, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner = Learner(dls.cuda(), mod, loss_func=ssd_loss)\n",
    "# learner.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fit_one_cycle(8, lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without scaling preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "size = im_sz\n",
    "body = create_body(resnet34, pretrained=True)\n",
    "head = SSD_MultiHead(k)\n",
    "mod = CustMod(body, head)\n",
    "loss_f = FocalLoss(dls.ncls, device)\n",
    "met = ShowLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(dls.cuda(), mod, loss_func=ssd_loss, metrics=met)\n",
    "learner.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>MAE, Focal</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>37.807579</td>\n",
       "      <td>32.324768</td>\n",
       "      <td>(21.07, 11.17)</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>33.459534</td>\n",
       "      <td>134.450790</td>\n",
       "      <td>(36.67, 97.53)</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>32.157589</td>\n",
       "      <td>29.494228</td>\n",
       "      <td>(19.59, 9.82)</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31.064367</td>\n",
       "      <td>102.948166</td>\n",
       "      <td>(23.06, 79.31)</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>30.416964</td>\n",
       "      <td>27.452950</td>\n",
       "      <td>(19.23, 8.14)</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>29.479332</td>\n",
       "      <td>27.339811</td>\n",
       "      <td>(19.28, 7.98)</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(6, lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stepping Through a Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = create_body(resnet34, pretrained=True)\n",
    "b_idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "size=im_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1250, 0.1250, 0.1875, 0.1875],\n",
       "        [0.1250, 0.1250, 0.1875, 0.0938],\n",
       "        [0.1250, 0.1250, 0.0938, 0.1875],\n",
       "        [0.1250, 0.1250, 0.2500, 0.2500],\n",
       "        [0.1250, 0.1250, 0.2500, 0.1250],\n",
       "        [0.1250, 0.1250, 0.1250, 0.2500],\n",
       "        [0.1250, 0.1250, 0.3250, 0.3250],\n",
       "        [0.1250, 0.1250, 0.3250, 0.1625],\n",
       "        [0.1250, 0.1250, 0.1625, 0.3250],\n",
       "        [0.3750, 0.1250, 0.1875, 0.1875],\n",
       "        [0.3750, 0.1250, 0.1875, 0.0938],\n",
       "        [0.3750, 0.1250, 0.0938, 0.1875],\n",
       "        [0.3750, 0.1250, 0.2500, 0.2500],\n",
       "        [0.3750, 0.1250, 0.2500, 0.1250],\n",
       "        [0.3750, 0.1250, 0.1250, 0.2500],\n",
       "        [0.3750, 0.1250, 0.3250, 0.3250],\n",
       "        [0.3750, 0.1250, 0.3250, 0.1625],\n",
       "        [0.3750, 0.1250, 0.1625, 0.3250],\n",
       "        [0.6250, 0.1250, 0.1875, 0.1875],\n",
       "        [0.6250, 0.1250, 0.1875, 0.0938],\n",
       "        [0.6250, 0.1250, 0.0938, 0.1875],\n",
       "        [0.6250, 0.1250, 0.2500, 0.2500],\n",
       "        [0.6250, 0.1250, 0.2500, 0.1250],\n",
       "        [0.6250, 0.1250, 0.1250, 0.2500],\n",
       "        [0.6250, 0.1250, 0.3250, 0.3250],\n",
       "        [0.6250, 0.1250, 0.3250, 0.1625],\n",
       "        [0.6250, 0.1250, 0.1625, 0.3250],\n",
       "        [0.8750, 0.1250, 0.1875, 0.1875],\n",
       "        [0.8750, 0.1250, 0.1875, 0.0938],\n",
       "        [0.8750, 0.1250, 0.0938, 0.1875],\n",
       "        [0.8750, 0.1250, 0.2500, 0.2500],\n",
       "        [0.8750, 0.1250, 0.2500, 0.1250],\n",
       "        [0.8750, 0.1250, 0.1250, 0.2500],\n",
       "        [0.8750, 0.1250, 0.3250, 0.3250],\n",
       "        [0.8750, 0.1250, 0.3250, 0.1625],\n",
       "        [0.8750, 0.1250, 0.1625, 0.3250],\n",
       "        [0.1250, 0.3750, 0.1875, 0.1875],\n",
       "        [0.1250, 0.3750, 0.1875, 0.0938],\n",
       "        [0.1250, 0.3750, 0.0938, 0.1875],\n",
       "        [0.1250, 0.3750, 0.2500, 0.2500],\n",
       "        [0.1250, 0.3750, 0.2500, 0.1250],\n",
       "        [0.1250, 0.3750, 0.1250, 0.2500],\n",
       "        [0.1250, 0.3750, 0.3250, 0.3250],\n",
       "        [0.1250, 0.3750, 0.3250, 0.1625],\n",
       "        [0.1250, 0.3750, 0.1625, 0.3250],\n",
       "        [0.3750, 0.3750, 0.1875, 0.1875],\n",
       "        [0.3750, 0.3750, 0.1875, 0.0938],\n",
       "        [0.3750, 0.3750, 0.0938, 0.1875],\n",
       "        [0.3750, 0.3750, 0.2500, 0.2500],\n",
       "        [0.3750, 0.3750, 0.2500, 0.1250],\n",
       "        [0.3750, 0.3750, 0.1250, 0.2500],\n",
       "        [0.3750, 0.3750, 0.3250, 0.3250],\n",
       "        [0.3750, 0.3750, 0.3250, 0.1625],\n",
       "        [0.3750, 0.3750, 0.1625, 0.3250],\n",
       "        [0.6250, 0.3750, 0.1875, 0.1875],\n",
       "        [0.6250, 0.3750, 0.1875, 0.0938],\n",
       "        [0.6250, 0.3750, 0.0938, 0.1875],\n",
       "        [0.6250, 0.3750, 0.2500, 0.2500],\n",
       "        [0.6250, 0.3750, 0.2500, 0.1250],\n",
       "        [0.6250, 0.3750, 0.1250, 0.2500],\n",
       "        [0.6250, 0.3750, 0.3250, 0.3250],\n",
       "        [0.6250, 0.3750, 0.3250, 0.1625],\n",
       "        [0.6250, 0.3750, 0.1625, 0.3250],\n",
       "        [0.8750, 0.3750, 0.1875, 0.1875],\n",
       "        [0.8750, 0.3750, 0.1875, 0.0938],\n",
       "        [0.8750, 0.3750, 0.0938, 0.1875],\n",
       "        [0.8750, 0.3750, 0.2500, 0.2500],\n",
       "        [0.8750, 0.3750, 0.2500, 0.1250],\n",
       "        [0.8750, 0.3750, 0.1250, 0.2500],\n",
       "        [0.8750, 0.3750, 0.3250, 0.3250],\n",
       "        [0.8750, 0.3750, 0.3250, 0.1625],\n",
       "        [0.8750, 0.3750, 0.1625, 0.3250],\n",
       "        [0.1250, 0.6250, 0.1875, 0.1875],\n",
       "        [0.1250, 0.6250, 0.1875, 0.0938],\n",
       "        [0.1250, 0.6250, 0.0938, 0.1875],\n",
       "        [0.1250, 0.6250, 0.2500, 0.2500],\n",
       "        [0.1250, 0.6250, 0.2500, 0.1250],\n",
       "        [0.1250, 0.6250, 0.1250, 0.2500],\n",
       "        [0.1250, 0.6250, 0.3250, 0.3250],\n",
       "        [0.1250, 0.6250, 0.3250, 0.1625],\n",
       "        [0.1250, 0.6250, 0.1625, 0.3250],\n",
       "        [0.3750, 0.6250, 0.1875, 0.1875],\n",
       "        [0.3750, 0.6250, 0.1875, 0.0938],\n",
       "        [0.3750, 0.6250, 0.0938, 0.1875],\n",
       "        [0.3750, 0.6250, 0.2500, 0.2500],\n",
       "        [0.3750, 0.6250, 0.2500, 0.1250],\n",
       "        [0.3750, 0.6250, 0.1250, 0.2500],\n",
       "        [0.3750, 0.6250, 0.3250, 0.3250],\n",
       "        [0.3750, 0.6250, 0.3250, 0.1625],\n",
       "        [0.3750, 0.6250, 0.1625, 0.3250],\n",
       "        [0.6250, 0.6250, 0.1875, 0.1875],\n",
       "        [0.6250, 0.6250, 0.1875, 0.0938],\n",
       "        [0.6250, 0.6250, 0.0938, 0.1875],\n",
       "        [0.6250, 0.6250, 0.2500, 0.2500],\n",
       "        [0.6250, 0.6250, 0.2500, 0.1250],\n",
       "        [0.6250, 0.6250, 0.1250, 0.2500],\n",
       "        [0.6250, 0.6250, 0.3250, 0.3250],\n",
       "        [0.6250, 0.6250, 0.3250, 0.1625],\n",
       "        [0.6250, 0.6250, 0.1625, 0.3250],\n",
       "        [0.8750, 0.6250, 0.1875, 0.1875],\n",
       "        [0.8750, 0.6250, 0.1875, 0.0938],\n",
       "        [0.8750, 0.6250, 0.0938, 0.1875],\n",
       "        [0.8750, 0.6250, 0.2500, 0.2500],\n",
       "        [0.8750, 0.6250, 0.2500, 0.1250],\n",
       "        [0.8750, 0.6250, 0.1250, 0.2500],\n",
       "        [0.8750, 0.6250, 0.3250, 0.3250],\n",
       "        [0.8750, 0.6250, 0.3250, 0.1625],\n",
       "        [0.8750, 0.6250, 0.1625, 0.3250],\n",
       "        [0.1250, 0.8750, 0.1875, 0.1875],\n",
       "        [0.1250, 0.8750, 0.1875, 0.0938],\n",
       "        [0.1250, 0.8750, 0.0938, 0.1875],\n",
       "        [0.1250, 0.8750, 0.2500, 0.2500],\n",
       "        [0.1250, 0.8750, 0.2500, 0.1250],\n",
       "        [0.1250, 0.8750, 0.1250, 0.2500],\n",
       "        [0.1250, 0.8750, 0.3250, 0.3250],\n",
       "        [0.1250, 0.8750, 0.3250, 0.1625],\n",
       "        [0.1250, 0.8750, 0.1625, 0.3250],\n",
       "        [0.3750, 0.8750, 0.1875, 0.1875],\n",
       "        [0.3750, 0.8750, 0.1875, 0.0938],\n",
       "        [0.3750, 0.8750, 0.0938, 0.1875],\n",
       "        [0.3750, 0.8750, 0.2500, 0.2500],\n",
       "        [0.3750, 0.8750, 0.2500, 0.1250],\n",
       "        [0.3750, 0.8750, 0.1250, 0.2500],\n",
       "        [0.3750, 0.8750, 0.3250, 0.3250],\n",
       "        [0.3750, 0.8750, 0.3250, 0.1625],\n",
       "        [0.3750, 0.8750, 0.1625, 0.3250],\n",
       "        [0.6250, 0.8750, 0.1875, 0.1875],\n",
       "        [0.6250, 0.8750, 0.1875, 0.0938],\n",
       "        [0.6250, 0.8750, 0.0938, 0.1875],\n",
       "        [0.6250, 0.8750, 0.2500, 0.2500],\n",
       "        [0.6250, 0.8750, 0.2500, 0.1250],\n",
       "        [0.6250, 0.8750, 0.1250, 0.2500],\n",
       "        [0.6250, 0.8750, 0.3250, 0.3250],\n",
       "        [0.6250, 0.8750, 0.3250, 0.1625],\n",
       "        [0.6250, 0.8750, 0.1625, 0.3250],\n",
       "        [0.8750, 0.8750, 0.1875, 0.1875],\n",
       "        [0.8750, 0.8750, 0.1875, 0.0938],\n",
       "        [0.8750, 0.8750, 0.0938, 0.1875],\n",
       "        [0.8750, 0.8750, 0.2500, 0.2500],\n",
       "        [0.8750, 0.8750, 0.2500, 0.1250],\n",
       "        [0.8750, 0.8750, 0.1250, 0.2500],\n",
       "        [0.8750, 0.8750, 0.3250, 0.3250],\n",
       "        [0.8750, 0.8750, 0.3250, 0.1625],\n",
       "        [0.8750, 0.8750, 0.1625, 0.3250],\n",
       "        [0.2500, 0.2500, 0.3750, 0.3750],\n",
       "        [0.2500, 0.2500, 0.3750, 0.1875],\n",
       "        [0.2500, 0.2500, 0.1875, 0.3750],\n",
       "        [0.2500, 0.2500, 0.5000, 0.5000],\n",
       "        [0.2500, 0.2500, 0.5000, 0.2500],\n",
       "        [0.2500, 0.2500, 0.2500, 0.5000],\n",
       "        [0.2500, 0.2500, 0.6500, 0.6500],\n",
       "        [0.2500, 0.2500, 0.6500, 0.3250],\n",
       "        [0.2500, 0.2500, 0.3250, 0.6500],\n",
       "        [0.7500, 0.2500, 0.3750, 0.3750],\n",
       "        [0.7500, 0.2500, 0.3750, 0.1875],\n",
       "        [0.7500, 0.2500, 0.1875, 0.3750],\n",
       "        [0.7500, 0.2500, 0.5000, 0.5000],\n",
       "        [0.7500, 0.2500, 0.5000, 0.2500],\n",
       "        [0.7500, 0.2500, 0.2500, 0.5000],\n",
       "        [0.7500, 0.2500, 0.6500, 0.6500],\n",
       "        [0.7500, 0.2500, 0.6500, 0.3250],\n",
       "        [0.7500, 0.2500, 0.3250, 0.6500],\n",
       "        [0.2500, 0.7500, 0.3750, 0.3750],\n",
       "        [0.2500, 0.7500, 0.3750, 0.1875],\n",
       "        [0.2500, 0.7500, 0.1875, 0.3750],\n",
       "        [0.2500, 0.7500, 0.5000, 0.5000],\n",
       "        [0.2500, 0.7500, 0.5000, 0.2500],\n",
       "        [0.2500, 0.7500, 0.2500, 0.5000],\n",
       "        [0.2500, 0.7500, 0.6500, 0.6500],\n",
       "        [0.2500, 0.7500, 0.6500, 0.3250],\n",
       "        [0.2500, 0.7500, 0.3250, 0.6500],\n",
       "        [0.7500, 0.7500, 0.3750, 0.3750],\n",
       "        [0.7500, 0.7500, 0.3750, 0.1875],\n",
       "        [0.7500, 0.7500, 0.1875, 0.3750],\n",
       "        [0.7500, 0.7500, 0.5000, 0.5000],\n",
       "        [0.7500, 0.7500, 0.5000, 0.2500],\n",
       "        [0.7500, 0.7500, 0.2500, 0.5000],\n",
       "        [0.7500, 0.7500, 0.6500, 0.6500],\n",
       "        [0.7500, 0.7500, 0.6500, 0.3250],\n",
       "        [0.7500, 0.7500, 0.3250, 0.6500],\n",
       "        [0.5000, 0.5000, 0.7500, 0.7500],\n",
       "        [0.5000, 0.5000, 0.7500, 0.3750],\n",
       "        [0.5000, 0.5000, 0.3750, 0.7500],\n",
       "        [0.5000, 0.5000, 1.0000, 1.0000],\n",
       "        [0.5000, 0.5000, 1.0000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000, 1.0000],\n",
       "        [0.5000, 0.5000, 1.3000, 1.3000],\n",
       "        [0.5000, 0.5000, 1.3000, 0.6500],\n",
       "        [0.5000, 0.5000, 0.6500, 1.3000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get batch, acts, item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dls.cpu().valid))\n",
    "acts = mod(batch[0])\n",
    "bbs, lbls = batch[1], batch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get acts and targs for a single im\n",
    "abb,albl,bb,lbl = list(zip(*acts,bbs,lbls))[b_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([189, 4]), torch.Size([189, 21]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abb.shape,albl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.5219, -0.7125,  0.2134,  0.1583],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000]]),\n",
       " tensor([12, 14, 12, 14,  0,  0,  0,  0,  0,  0,  0,  0]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb,lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ssd item loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process single im acts and targs in loss fxn\n",
    "#assignments\n",
    "b_bb,b_c,bbox,clas=abb,albl,bb,lbl\n",
    "print_it=False\n",
    "use_ab=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.5219, -0.7125,  0.2134,  0.1583],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792]]),\n",
       " tensor([12, 14, 12, 14]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox,clas = get_y(bbox,clas)\n",
    "bbox,clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([189, 4]),\n",
       " tensor([[-0.8334, -0.9761, -0.3795, -0.5666],\n",
       "         [-0.7941, -0.9038, -0.4184, -0.7025],\n",
       "         [-0.8372, -0.7897, -0.6151, -0.5645],\n",
       "         [-1.1843, -0.9008, -0.7673, -0.4571],\n",
       "         [-0.9295, -1.0600, -0.3284, -0.8027]], device='cuda:0',\n",
       "        grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ic = actn_to_bb(b_bb, anchors)\n",
    "a_ic.shape, a_ic[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 189]),\n",
       " tensor([[1.4417e-02, 7.2087e-03, 7.2087e-03, 2.5631e-02, 1.2815e-02, 1.2815e-02,\n",
       "          4.3316e-02, 2.1658e-02, 2.1658e-02, 1.4417e-02, 7.2087e-03, 7.2087e-03,\n",
       "          2.5631e-02, 1.2815e-02, 1.2815e-02, 4.3316e-02, 2.1658e-02, 2.1658e-02,\n",
       "          1.6285e-03, 8.1941e-04, 0.0000e+00, 5.2958e-03, 2.6744e-03, 0.0000e+00,\n",
       "          1.1657e-02, 5.9183e-03, 1.1688e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.4417e-02, 7.2087e-03, 7.2087e-03, 2.5631e-02, 1.2815e-02, 1.2815e-02,\n",
       "          4.3316e-02, 2.1658e-02, 2.1658e-02, 1.4417e-02, 7.2087e-03, 7.2087e-03,\n",
       "          2.5631e-02, 1.2815e-02, 1.2815e-02, 4.3316e-02, 2.1658e-02, 2.1658e-02,\n",
       "          1.6285e-03, 8.1941e-04, 0.0000e+00, 5.2958e-03, 2.6744e-03, 0.0000e+00,\n",
       "          1.1657e-02, 5.9183e-03, 1.1688e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.4417e-02, 7.2087e-03, 7.2087e-03, 2.5631e-02, 1.2815e-02, 1.2815e-02,\n",
       "          4.3316e-02, 2.1658e-02, 2.1658e-02, 1.4417e-02, 7.2087e-03, 7.2087e-03,\n",
       "          2.5631e-02, 1.2815e-02, 1.2815e-02, 4.3316e-02, 2.1658e-02, 2.1658e-02,\n",
       "          1.6285e-03, 8.1941e-04, 0.0000e+00, 5.2958e-03, 2.6744e-03, 0.0000e+00,\n",
       "          1.1657e-02, 5.9183e-03, 1.1688e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.2309e-02, 7.2087e-03, 6.1610e-03, 1.9533e-02, 1.2815e-02, 9.7958e-03,\n",
       "          3.0158e-02, 1.9676e-02, 1.5175e-02, 1.2309e-02, 7.2087e-03, 6.1610e-03,\n",
       "          1.9533e-02, 1.2815e-02, 9.7958e-03, 3.0158e-02, 1.9676e-02, 1.5175e-02,\n",
       "          1.3929e-03, 8.1941e-04, 0.0000e+00, 4.0551e-03, 2.6744e-03, 0.0000e+00,\n",
       "          8.1915e-03, 5.3843e-03, 8.2389e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          5.7669e-02, 2.8835e-02, 2.8835e-02, 1.0252e-01, 5.1262e-02, 5.1262e-02,\n",
       "          1.6633e-01, 8.3412e-02, 8.6632e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          9.8980e-03, 5.1660e-03, 0.0000e+00, 2.9880e-02, 1.5912e-02, 0.0000e+00,\n",
       "          5.7669e-02, 2.8835e-02, 2.8835e-02, 8.9492e-02, 5.1262e-02, 4.5012e-02,\n",
       "          1.2785e-01, 8.3412e-02, 6.7659e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          8.7331e-03, 5.1660e-03, 0.0000e+00, 2.3606e-02, 1.5912e-02, 0.0000e+00,\n",
       "          1.1968e-01, 6.2667e-02, 7.0937e-02, 1.7836e-01, 1.0381e-01, 1.0742e-01,\n",
       "          2.2822e-01, 1.6158e-01, 1.4361e-01],\n",
       "         [3.5483e-02, 2.2710e-02, 1.8445e-02, 5.0500e-02, 3.1407e-02, 3.0369e-02,\n",
       "          7.0511e-02, 4.3270e-02, 4.8126e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2784e-04, 1.4346e-04, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.8865e-02, 4.4252e-04, 7.7632e-03, 3.9445e-02, 9.3812e-03, 1.8624e-02,\n",
       "          6.7592e-02, 2.4578e-02, 3.5723e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          2.4550e-03, 0.0000e+00, 0.0000e+00, 2.1029e-02, 0.0000e+00, 0.0000e+00,\n",
       "          5.0508e-02, 0.0000e+00, 8.0289e-03],\n",
       "         [1.4252e-02, 0.0000e+00, 8.0844e-03, 3.7045e-02, 0.0000e+00, 2.4639e-02,\n",
       "          6.6991e-02, 8.4485e-03, 5.1679e-02, 1.5282e-02, 0.0000e+00, 8.0844e-03,\n",
       "          4.5248e-02, 0.0000e+00, 2.4639e-02, 8.9699e-02, 1.1106e-02, 5.1679e-02,\n",
       "          7.0944e-05, 0.0000e+00, 0.0000e+00, 5.5953e-03, 0.0000e+00, 0.0000e+00,\n",
       "          1.8260e-02, 2.3986e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.2991e-01, 6.5254e-02, 7.0222e-02, 1.9742e-01, 1.0082e-01, 1.2484e-01,\n",
       "          2.8634e-01, 1.5034e-01, 2.1098e-01, 1.4044e-01, 7.0222e-02, 7.0222e-02,\n",
       "          2.4968e-01, 1.2484e-01, 1.2484e-01, 4.1212e-01, 2.0677e-01, 2.1098e-01,\n",
       "          5.8074e-04, 3.0934e-04, 0.0000e+00, 2.6357e-02, 1.4472e-02, 0.0000e+00,\n",
       "          6.7897e-02, 3.8776e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.2181e-01, 6.5254e-02, 6.6063e-02, 1.5927e-01, 1.0082e-01, 1.0191e-01,\n",
       "          2.0247e-01, 1.5034e-01, 1.5179e-01, 1.3162e-01, 7.0222e-02, 6.6063e-02,\n",
       "          1.9975e-01, 1.2484e-01, 1.0191e-01, 2.8329e-01, 2.0677e-01, 1.5179e-01,\n",
       "          5.4846e-04, 3.0934e-04, 0.0000e+00, 2.1868e-02, 1.4472e-02, 0.0000e+00,\n",
       "          5.0522e-02, 3.8776e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          3.0176e-01, 2.0919e-01, 1.6458e-01, 3.8390e-01, 2.7848e-01, 2.5408e-01,\n",
       "          3.7979e-01, 2.9748e-01, 3.6421e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.9925e-02, 1.5579e-02, 0.0000e+00, 6.4254e-02, 5.2953e-02, 0.0000e+00,\n",
       "          1.6264e-01, 6.4866e-02, 9.3231e-02, 2.3457e-01, 1.1273e-01, 1.6113e-01,\n",
       "          2.5895e-01, 1.4661e-01, 2.4922e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.3562e-02, 7.1860e-03, 0.0000e+00, 4.7247e-02, 2.8855e-02, 0.0000e+00,\n",
       "          3.4536e-01, 4.0295e-01, 2.6864e-01, 2.5032e-01, 4.2523e-01, 2.3871e-01,\n",
       "          1.4812e-01, 2.9624e-01, 2.0063e-01],\n",
       "         [1.2587e-01, 7.2247e-02, 6.6432e-02, 2.0175e-01, 1.1837e-01, 1.1064e-01,\n",
       "          2.5792e-01, 1.5954e-01, 1.7231e-01, 5.7705e-02, 3.3999e-02, 3.0558e-02,\n",
       "          8.9835e-02, 5.4819e-02, 5.0439e-02, 1.2775e-01, 8.2263e-02, 7.6957e-02,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          2.5840e-01, 1.2920e-01, 1.2920e-01, 4.0557e-01, 2.2969e-01, 2.0659e-01,\n",
       "          4.7072e-01, 3.3258e-01, 2.9776e-01, 1.1137e-01, 5.9138e-02, 5.7600e-02,\n",
       "          1.6506e-01, 1.0097e-01, 8.9953e-02, 2.1480e-01, 1.5993e-01, 1.2555e-01,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          2.0412e-02, 0.0000e+00, 1.4549e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1175e-02, 0.0000e+00, 7.0204e-03,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          5.6192e-01, 3.9254e-01, 4.1144e-01, 5.3848e-01, 5.5513e-01, 5.2445e-01,\n",
       "          3.2202e-01, 4.6994e-01, 4.2396e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          3.7772e-02, 0.0000e+00, 4.6560e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.4365e-01, 1.0981e-01, 5.3891e-02, 1.3500e-01, 1.5513e-01, 7.5220e-02,\n",
       "          8.0505e-02, 1.3169e-01, 7.8829e-02]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps = jaccard(bbox.data, anchor_cnr.data)\n",
    "overlaps.shape, overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.2587e-01, 7.2247e-02, 6.6432e-02, 2.0175e-01, 1.1837e-01, 1.1064e-01,\n",
       "         1.9900e+00, 1.5954e-01, 1.7231e-01, 5.7705e-02, 3.3999e-02, 3.0558e-02,\n",
       "         8.9835e-02, 5.4819e-02, 5.0439e-02, 1.2775e-01, 8.2263e-02, 7.6957e-02,\n",
       "         1.6285e-03, 8.1941e-04, 0.0000e+00, 5.5953e-03, 2.6744e-03, 0.0000e+00,\n",
       "         1.8260e-02, 5.9183e-03, 1.1688e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         2.5840e-01, 1.2920e-01, 1.2920e-01, 4.0557e-01, 2.2969e-01, 2.0659e-01,\n",
       "         4.7072e-01, 3.3258e-01, 2.9776e-01, 1.4044e-01, 7.0222e-02, 7.0222e-02,\n",
       "         2.4968e-01, 1.2484e-01, 1.2484e-01, 4.1212e-01, 2.0677e-01, 2.1098e-01,\n",
       "         1.6285e-03, 8.1941e-04, 0.0000e+00, 2.6357e-02, 1.4472e-02, 0.0000e+00,\n",
       "         6.7897e-02, 3.8776e-02, 1.1688e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.2181e-01, 6.5254e-02, 6.6063e-02, 1.5927e-01, 1.0082e-01, 1.0191e-01,\n",
       "         2.0247e-01, 1.5034e-01, 1.5179e-01, 1.3162e-01, 7.0222e-02, 6.6063e-02,\n",
       "         1.9975e-01, 1.2484e-01, 1.0191e-01, 2.8329e-01, 2.0677e-01, 1.5179e-01,\n",
       "         1.6285e-03, 8.1941e-04, 0.0000e+00, 2.1868e-02, 1.4472e-02, 0.0000e+00,\n",
       "         5.0522e-02, 3.8776e-02, 1.1688e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.2309e-02, 7.2087e-03, 6.1610e-03, 1.9533e-02, 1.2815e-02, 9.7958e-03,\n",
       "         3.0158e-02, 1.9676e-02, 1.5175e-02, 1.2309e-02, 7.2087e-03, 6.1610e-03,\n",
       "         1.9533e-02, 1.2815e-02, 9.7958e-03, 3.0158e-02, 1.9676e-02, 1.5175e-02,\n",
       "         1.3929e-03, 8.1941e-04, 0.0000e+00, 4.0551e-03, 2.6744e-03, 0.0000e+00,\n",
       "         8.1915e-03, 5.3843e-03, 8.2389e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.9900e+00, 3.9254e-01, 4.1144e-01, 5.3848e-01, 5.5513e-01, 5.2445e-01,\n",
       "         3.7979e-01, 4.6994e-01, 4.2396e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.9925e-02, 1.5579e-02, 0.0000e+00, 6.4254e-02, 5.2953e-02, 0.0000e+00,\n",
       "         1.6264e-01, 6.4866e-02, 9.3231e-02, 2.3457e-01, 1.1273e-01, 1.6113e-01,\n",
       "         2.5895e-01, 1.4661e-01, 2.4922e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.3562e-02, 7.1860e-03, 0.0000e+00, 4.7247e-02, 2.8855e-02, 0.0000e+00,\n",
       "         3.4536e-01, 4.0295e-01, 2.6864e-01, 2.5032e-01, 1.9900e+00, 2.3871e-01,\n",
       "         1.9900e+00, 2.9624e-01, 2.0063e-01]),\n",
       " tensor([3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 2, 0, 0,\n",
       "         2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 0,\n",
       "         2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         3, 3, 3, 3, 3, 3, 2, 3, 3, 0, 0, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_overlap,gt_idx = map_to_ground_truth(overlaps)\n",
    "gt_overlap,gt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        14, 14, 14, 14, 14, 14, 12, 14, 14, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_clas = clas[gt_idx]\n",
    "gt_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False,  True, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,  True,\n",
       "        False, False,  True, False, False, False, False, False, False, False,\n",
       "        False,  True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False,  True, False,  True,  True,  True,  True,\n",
       "        False,  True,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False,  True, False, False,  True, False,  True, False, False])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = gt_overlap > 0.4\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  6,  39,  42,  51, 144, 146, 147, 148, 149, 151, 152, 181, 184, 186])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_idx = torch.nonzero(pos)[:,0]\n",
    "pos_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 14, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        14, 20, 14, 14, 14, 14, 20, 14, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 12, 20, 20, 12, 20, 12, 20, 20])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_clas[~pos] = dls.ncls\n",
    "gt_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([189, 4]),\n",
       " tensor([[-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.5219, -0.7125,  0.2134,  0.1583],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_bbox = bbox[gt_idx]\n",
    "gt_bbox.shape, gt_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6299, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_loss = ((a_ic.cpu()[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\n",
    "loc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6595, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cpu'\n",
    "clas_loss  = loss_f(b_c.cpu(), gt_clas.cpu())\n",
    "clas_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lbl loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clas_loss\n",
    "#assignments\n",
    "preds,targets = b_c.cpu(),gt_clas.cpu()\n",
    "num_classes=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([189, 21]),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = one_hot_embedding(targets, num_classes+1)\n",
    "t.shape, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([189, 20]),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tensor(t[:,:-1].contiguous())\n",
    "t.shape, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([189, 20]),\n",
       " tensor([[-4.0802, -3.6891, -3.8384,  ..., -3.7442, -3.4973, -3.8569],\n",
       "         [-3.3145, -3.9785, -4.4999,  ..., -4.2666, -4.1959, -3.7895],\n",
       "         [-3.8018, -4.3627, -4.3670,  ..., -4.2720, -3.6047, -3.8739],\n",
       "         ...,\n",
       "         [-4.0017, -3.9917, -4.0002,  ..., -3.9941, -3.9885, -3.9979],\n",
       "         [-4.0118, -3.9898, -3.9929,  ..., -4.0014, -4.0001, -3.9908],\n",
       "         [-3.9951, -4.0137, -4.0054,  ..., -3.9829, -3.9871, -3.9828]],\n",
       "        grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = preds[:,:-1]\n",
    "x.shape,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(x,t):\n",
    "    alpha,gamma = 0.25,2.\n",
    "    p = x.sigmoid()\n",
    "    pt = p*t + (1-p)*(1-t)\n",
    "    w = alpha*t + (1-alpha)*(1-t)\n",
    "    return w * (1-pt).pow(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([189, 20]),\n",
       " tensor([[2.0725e-04, 4.4598e-04, 3.3307e-04,  ..., 4.0050e-04, 6.4780e-04,\n",
       "          3.2122e-04],\n",
       "         [9.2278e-04, 2.5309e-04, 9.0553e-05,  ..., 1.4356e-04, 1.6502e-04,\n",
       "          3.6657e-04],\n",
       "         [3.5785e-04, 1.1875e-04, 1.1775e-04,  ..., 1.4205e-04, 5.2567e-04,\n",
       "          3.1073e-04],\n",
       "         ...,\n",
       "         [2.4181e-04, 2.4661e-04, 2.4252e-04,  ..., 2.4544e-04, 2.4818e-04,\n",
       "          2.4365e-04],\n",
       "         [2.3708e-04, 2.4751e-04, 2.4603e-04,  ..., 2.4197e-04, 2.4256e-04,\n",
       "          2.4704e-04],\n",
       "         [2.4495e-04, 2.3618e-04, 2.4009e-04,  ..., 2.5093e-04, 2.4887e-04,\n",
       "          2.5096e-04]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = get_weight(x,t).detach()\n",
    "w.shape, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
