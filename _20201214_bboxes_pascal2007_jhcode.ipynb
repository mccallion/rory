{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data</a></span></li><li><span><a href=\"#Code\" data-toc-modified-id=\"Code-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Code</a></span><ul class=\"toc-item\"><li><span><a href=\"#JH\" data-toc-modified-id=\"JH-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>JH</a></span></li></ul></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Train</a></span></li><li><span><a href=\"#Stepping-Through-a-Batch\" data-toc-modified-id=\"Stepping-Through-a-Batch-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Stepping Through a Batch</a></span><ul class=\"toc-item\"><li><span><a href=\"#JH\" data-toc-modified-id=\"JH-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>JH</a></span><ul class=\"toc-item\"><li><span><a href=\"#Init\" data-toc-modified-id=\"Init-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Init</a></span></li><li><span><a href=\"#Get-batch,-acts,-item\" data-toc-modified-id=\"Get-batch,-acts,-item-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Get batch, acts, item</a></span></li><li><span><a href=\"#ssd-item-loss\" data-toc-modified-id=\"ssd-item-loss-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>ssd item loss</a></span></li><li><span><a href=\"#lbl-loss\" data-toc-modified-id=\"lbl-loss-4.1.4\"><span class=\"toc-item-num\">4.1.4&nbsp;&nbsp;</span>lbl loss</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**~ My Code ~**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports & Paths ###\n",
    "from fastai.vision.all import *\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def random_seed(s, use_cuda):\n",
    "    #Also, remember to use num_workers=0 when creating the DataBunch\n",
    "    np.random.seed(s)\n",
    "    torch.manual_seed(s)\n",
    "    random.seed(s)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(s)\n",
    "        torch.cuda.manual_seed_all(s)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False      \n",
    "random_seed(42,True)\n",
    "\n",
    "\n",
    "### Params ###\n",
    "im_sz   = 224\n",
    "bs      = 64\n",
    "val_pct = .2\n",
    "sub_pct = 1\n",
    "path = untar_data(URLs.PASCAL_2007)\n",
    "annos_path = path/'train.json'\n",
    "ims_path = path/'train'\n",
    "\n",
    "\n",
    "### Items ###\n",
    "fns, annos = get_annotations(annos_path)\n",
    "fn2anno = {f:a for f,a in zip(fns,annos)}\n",
    "def get_im(f):   return ims_path/f\n",
    "def get_bbox(f): return fn2anno[f][0]\n",
    "def get_lbl(f):  return fn2anno[f][1]\n",
    "\n",
    "\n",
    "### DataLoaders ###\n",
    "itfms = Resize(im_sz, method='squish')\n",
    "btfms = setup_aug_tfms([Rotate(), Brightness(), Contrast(), Flip(),\n",
    "                       Normalize.from_stats(*imagenet_stats)])\n",
    "db = DataBlock(\n",
    "    blocks=[ImageBlock, BBoxBlock, BBoxLblBlock(add_na=False)],\n",
    "    get_x=get_im, get_y=[get_bbox, get_lbl], n_inp=1,\n",
    "    splitter=RandomSplitter(val_pct),\n",
    "    item_tfms=itfms, batch_tfms=btfms)\n",
    "subset = L(fns).shuffle()[0:int(len(fns)*sub_pct)]\n",
    "# dls = db.dataloaders(subset, bs=bs)\n",
    "dls = db.dataloaders(fns, bs=bs, seed=42)\n",
    "dls.v = dls.vocab\n",
    "dls.ncls = len(dls.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: (#20) ['aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair','cow'...]\n",
      "Size of train data: 2001\n",
      "Size of valid data: 500\n",
      "batch[0]: \t torch.float32 \t torch.Size([64, 3, 224, 224])\n",
      "batch[1]: \t torch.float32 \t torch.Size([64, 12, 4])\n",
      "batch[2]: \t torch.int64 \t torch.Size([64, 12])\n"
     ]
    }
   ],
   "source": [
    "### Inspection ###\n",
    "print(\"Vocab:\", dls.v)\n",
    "print(\"Size of train data:\",len(dls.train.items))\n",
    "print(\"Size of valid data:\",len(dls.valid.items))\n",
    "for i,t in enumerate(dls.one_batch()):\n",
    "    print(f\"batch[{i}]:\",'\\t',t.dtype,'\\t',t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of tensor shapes:\n",
    "- torch.Size([128, 3, 224, 224]): bs, channels (rgb), im_sz, im_sz\n",
    "- torch.Size([128, 20, 4]): bs, max objs for a single im in batch, bb coords\n",
    "- torch.Size([128, 20]): bs, max objs for a single im in batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Anchors ###\n",
    "anc_grids = [4,2,1]\n",
    "# anc_grids = [4]\n",
    "anc_zooms = [0.75, 1., 1.3]\n",
    "# anc_zooms = [1.]\n",
    "anc_ratios = [(1.,1.), (1.,0.5), (0.5,1.)]\n",
    "# anc_ratios = [(1.,1.)]\n",
    "anchor_scales = [(anz*i,anz*j) for anz in anc_zooms for (i,j) in anc_ratios]\n",
    "k = len(anchor_scales)\n",
    "anc_offsets = [1/(o*2) for o in anc_grids]\n",
    "anc_x = np.concatenate([np.tile(np.linspace(ao, 1-ao, ag), ag)\n",
    "                        for ao,ag in zip(anc_offsets,anc_grids)])\n",
    "anc_y = np.concatenate([np.repeat(np.linspace(ao, 1-ao, ag), ag)\n",
    "                        for ao,ag in zip(anc_offsets,anc_grids)])\n",
    "anc_ctrs = np.repeat(np.stack([anc_x,anc_y], axis=1), k, axis=0)\n",
    "anc_sizes  =   np.concatenate([np.array([[o/ag,p/ag] for i in range(ag*ag) for o,p in anchor_scales])\n",
    "               for ag in anc_grids])\n",
    "grid_sizes = tensor(np.concatenate([np.array([ 1/ag       for i in range(ag*ag) for o,p in anchor_scales])\n",
    "               for ag in anc_grids]), requires_grad=False).unsqueeze(1)\n",
    "anchors = tensor(np.concatenate([anc_ctrs, anc_sizes], axis=1), requires_grad=False).float()\n",
    "\n",
    "def hw2corners(ctr, hw): return torch.cat([ctr-hw/2,ctr+hw/2], dim=1)\n",
    "anchor_cnr = hw2corners(anchors[:,:2], anchors[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Architecture ###\n",
    "class StdConv(nn.Module):\n",
    "    def __init__(self, n_in,n_out,stride=2,dp = 0.1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(n_in,n_out,3,stride=stride,padding=1)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        self.dropout = nn.Dropout(dp)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.dropout(self.bn(F.relu(self.conv(x))))\n",
    "    \n",
    "def flatten_conv(x,k):\n",
    "    bs,nf,gx,gy = x.size()\n",
    "    x = x.permute(0,2,3,1).contiguous()\n",
    "    return x.view(bs,-1,nf//k)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, k, n_in, bias):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.bbs  = nn.Conv2d(n_in,            4*k, 3, padding=1)\n",
    "        self.lbls = nn.Conv2d(n_in, (dls.ncls+1)*k, 3, padding=1)\n",
    "        self.lbls.bias.data.zero_().add_(bias)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return [flatten_conv(self.bbs(x),  self.k),\n",
    "                flatten_conv(self.lbls(x), self.k)]\n",
    "    \n",
    "drop=0.4\n",
    "class SSD_MultiHead(nn.Module):\n",
    "    def __init__(self, k, bias):\n",
    "        super().__init__()\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.sconv1 = StdConv(512,256, dp=drop)\n",
    "        self.sconv2 = StdConv(256,256, dp=drop)\n",
    "        self.sconv3 = StdConv(256,256, dp=drop)\n",
    "        self.out1 = OutConv(k, 256, bias)\n",
    "        self.out2 = OutConv(k, 256, bias)\n",
    "        self.out3 = OutConv(k, 256, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop(F.relu(x))\n",
    "        x = self.sconv1(x)\n",
    "        bbs1,lbls1 = self.out1(x)\n",
    "        x = self.sconv2(x)\n",
    "        bbs2,lbls2 = self.out2(x)\n",
    "        x = self.sconv3(x)\n",
    "        bbs3,lbls3 = self.out3(x)\n",
    "        return [torch.cat([ bbs1, bbs2, bbs3], dim=1),\n",
    "                torch.cat([lbls1,lbls2,lbls3], dim=1)]\n",
    "    \n",
    "class CustMod(Module):\n",
    "    \"\"\"A module made from a pretrained body and an untrained head.\"\"\"\n",
    "    def __init__(self, body, head):\n",
    "        self.body, self.head = body, head\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.head(self.body(x))\n",
    "\n",
    "### FocalLoss ###\n",
    "def one_hot_embedding(labels, num_classes):\n",
    "    return torch.eye(num_classes)[labels.data].to(device)\n",
    "\n",
    "class BCE_Loss(nn.Module):\n",
    "    def __init__(self, num_classes, device):\n",
    "        super().__init__()\n",
    "        self.num_classes, self.device = num_classes, device\n",
    "    \n",
    "    def forward(self, preds, targets):\n",
    "        t = one_hot_embedding(targets, self.num_classes+1)\n",
    "        t = tensor(t[:,:-1].contiguous())\n",
    "        x = preds[:,:-1]\n",
    "        w = self.get_weight(x,t).detach()\n",
    "        return F.binary_cross_entropy_with_logits(x, t, w, reduction='sum') / self.num_classes\n",
    "    \n",
    "    def get_weight(self,x,t):\n",
    "        return None\n",
    "\n",
    "class FocalLoss(BCE_Loss):\n",
    "    def get_weight(self,x,t):\n",
    "        alpha,gamma = 0.25,2.\n",
    "        p = x.sigmoid()\n",
    "        pt = p*t + (1-p)*(1-t)\n",
    "        w = alpha*t + (1-alpha)*(1-t)\n",
    "        return w * (1-pt).pow(gamma)\n",
    "\n",
    "loss_f = FocalLoss(dls.ncls, device='cpu')\n",
    "\n",
    "### IoU ###\n",
    "def intersection(box_a,box_b):\n",
    "    min_xy = torch.max(box_a[:,None,:2],box_b[None,:,:2])\n",
    "    max_xy = torch.min(box_a[:,None,2:],box_b[None,:,2:])\n",
    "    inter = torch.clamp(max_xy-min_xy,min=0)\n",
    "    return inter[:,:,0] * inter[:,:,1]\n",
    "\n",
    "def get_size(box):\n",
    "    return (box[:,2]-box[:,0]) * (box[:,3] - box[:,1])\n",
    "\n",
    "def jaccard(box_a,box_b):\n",
    "    inter = intersection(box_a,box_b)\n",
    "    union = get_size(box_a).unsqueeze(1) + get_size(box_b).unsqueeze(0) - inter\n",
    "    return inter/union\n",
    "\n",
    "### ssd_loss ###\n",
    "def get_y(bbox,clas):\n",
    "    bbox = bbox.view(-1,4)/size\n",
    "    bb_keep = ((bbox[:,2] - bbox[:,0])>0.).nonzero()[:,0]\n",
    "    return bbox[bb_keep], clas[bb_keep]\n",
    "    \n",
    "def actn_to_bb(actn, anchors):\n",
    "    actn_bbs = torch.tanh(actn)\n",
    "    actn_ctrs = (actn_bbs.cuda()[:,:2] * grid_sizes.cuda()/2) + anchors.cuda()[:,:2]\n",
    "    actn_hw = (1 + actn_bbs.cuda()[:,2:]/2) * anchors.cuda()[:,2:]\n",
    "    return hw2corners(actn_ctrs,actn_hw)\n",
    "\n",
    "def map_to_ground_truth(overlaps, print_it=False):\n",
    "    prior_overlap, prior_idx = overlaps.max(1)\n",
    "    if print_it: print(prior_overlap)\n",
    "    gt_overlap, gt_idx = overlaps.max(0)\n",
    "    gt_overlap[prior_idx] = 1.99\n",
    "    for i,o in enumerate(prior_idx): gt_idx[o] = i\n",
    "    return gt_overlap,gt_idx\n",
    "\n",
    "def ssd_1_loss(b_bb, b_c, bbox, clas, print_it=False, use_ab=True):\n",
    "    bbox,clas = get_y(bbox,clas)\n",
    "    a_ic = actn_to_bb(b_bb, anchors)\n",
    "    overlaps = jaccard(bbox.data, (anchor_cnr.cuda() if use_ab else a_ic).data)\n",
    "    gt_overlap,gt_idx = map_to_ground_truth(overlaps)\n",
    "    gt_clas = clas[gt_idx]\n",
    "    pos = gt_overlap > 0.4\n",
    "    pos_idx = torch.nonzero(pos)[:,0]\n",
    "    gt_clas[~pos] = dls.ncls\n",
    "    gt_bbox = bbox[gt_idx]\n",
    "    loc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\n",
    "    clas_loss  = loss_f(b_c, gt_clas)\n",
    "    return loc_loss, clas_loss\n",
    "\n",
    "def ssd_loss(acts, bbs, lbls, print_it=True):\n",
    "    bb_sum, lbl_sum = 0., 0.\n",
    "    for abb, albl, bb, lbl in zip(*acts, bbs, lbls):\n",
    "        bb_loss, lbl_loss = ssd_1_loss(abb, albl, bb, lbl, print_it)\n",
    "        bb_sum += bb_loss\n",
    "        lbl_sum += lbl_loss\n",
    "    if print_it: print(f\"bb:{bb_sum:.02f} | lbl: {lbl_sum:.02f}\")\n",
    "    return bb_sum + lbl_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stepping Through a Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = create_body(resnet34, pretrained=True)\n",
    "b_idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "size=im_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1250, 0.1250, 0.1875, 0.1875],\n",
       "        [0.1250, 0.1250, 0.1875, 0.0938],\n",
       "        [0.1250, 0.1250, 0.0938, 0.1875],\n",
       "        [0.1250, 0.1250, 0.2500, 0.2500],\n",
       "        [0.1250, 0.1250, 0.2500, 0.1250],\n",
       "        [0.1250, 0.1250, 0.1250, 0.2500],\n",
       "        [0.1250, 0.1250, 0.3250, 0.3250],\n",
       "        [0.1250, 0.1250, 0.3250, 0.1625],\n",
       "        [0.1250, 0.1250, 0.1625, 0.3250],\n",
       "        [0.3750, 0.1250, 0.1875, 0.1875],\n",
       "        [0.3750, 0.1250, 0.1875, 0.0938],\n",
       "        [0.3750, 0.1250, 0.0938, 0.1875],\n",
       "        [0.3750, 0.1250, 0.2500, 0.2500],\n",
       "        [0.3750, 0.1250, 0.2500, 0.1250],\n",
       "        [0.3750, 0.1250, 0.1250, 0.2500],\n",
       "        [0.3750, 0.1250, 0.3250, 0.3250],\n",
       "        [0.3750, 0.1250, 0.3250, 0.1625],\n",
       "        [0.3750, 0.1250, 0.1625, 0.3250],\n",
       "        [0.6250, 0.1250, 0.1875, 0.1875],\n",
       "        [0.6250, 0.1250, 0.1875, 0.0938],\n",
       "        [0.6250, 0.1250, 0.0938, 0.1875],\n",
       "        [0.6250, 0.1250, 0.2500, 0.2500],\n",
       "        [0.6250, 0.1250, 0.2500, 0.1250],\n",
       "        [0.6250, 0.1250, 0.1250, 0.2500],\n",
       "        [0.6250, 0.1250, 0.3250, 0.3250],\n",
       "        [0.6250, 0.1250, 0.3250, 0.1625],\n",
       "        [0.6250, 0.1250, 0.1625, 0.3250],\n",
       "        [0.8750, 0.1250, 0.1875, 0.1875],\n",
       "        [0.8750, 0.1250, 0.1875, 0.0938],\n",
       "        [0.8750, 0.1250, 0.0938, 0.1875],\n",
       "        [0.8750, 0.1250, 0.2500, 0.2500],\n",
       "        [0.8750, 0.1250, 0.2500, 0.1250],\n",
       "        [0.8750, 0.1250, 0.1250, 0.2500],\n",
       "        [0.8750, 0.1250, 0.3250, 0.3250],\n",
       "        [0.8750, 0.1250, 0.3250, 0.1625],\n",
       "        [0.8750, 0.1250, 0.1625, 0.3250],\n",
       "        [0.1250, 0.3750, 0.1875, 0.1875],\n",
       "        [0.1250, 0.3750, 0.1875, 0.0938],\n",
       "        [0.1250, 0.3750, 0.0938, 0.1875],\n",
       "        [0.1250, 0.3750, 0.2500, 0.2500],\n",
       "        [0.1250, 0.3750, 0.2500, 0.1250],\n",
       "        [0.1250, 0.3750, 0.1250, 0.2500],\n",
       "        [0.1250, 0.3750, 0.3250, 0.3250],\n",
       "        [0.1250, 0.3750, 0.3250, 0.1625],\n",
       "        [0.1250, 0.3750, 0.1625, 0.3250],\n",
       "        [0.3750, 0.3750, 0.1875, 0.1875],\n",
       "        [0.3750, 0.3750, 0.1875, 0.0938],\n",
       "        [0.3750, 0.3750, 0.0938, 0.1875],\n",
       "        [0.3750, 0.3750, 0.2500, 0.2500],\n",
       "        [0.3750, 0.3750, 0.2500, 0.1250],\n",
       "        [0.3750, 0.3750, 0.1250, 0.2500],\n",
       "        [0.3750, 0.3750, 0.3250, 0.3250],\n",
       "        [0.3750, 0.3750, 0.3250, 0.1625],\n",
       "        [0.3750, 0.3750, 0.1625, 0.3250],\n",
       "        [0.6250, 0.3750, 0.1875, 0.1875],\n",
       "        [0.6250, 0.3750, 0.1875, 0.0938],\n",
       "        [0.6250, 0.3750, 0.0938, 0.1875],\n",
       "        [0.6250, 0.3750, 0.2500, 0.2500],\n",
       "        [0.6250, 0.3750, 0.2500, 0.1250],\n",
       "        [0.6250, 0.3750, 0.1250, 0.2500],\n",
       "        [0.6250, 0.3750, 0.3250, 0.3250],\n",
       "        [0.6250, 0.3750, 0.3250, 0.1625],\n",
       "        [0.6250, 0.3750, 0.1625, 0.3250],\n",
       "        [0.8750, 0.3750, 0.1875, 0.1875],\n",
       "        [0.8750, 0.3750, 0.1875, 0.0938],\n",
       "        [0.8750, 0.3750, 0.0938, 0.1875],\n",
       "        [0.8750, 0.3750, 0.2500, 0.2500],\n",
       "        [0.8750, 0.3750, 0.2500, 0.1250],\n",
       "        [0.8750, 0.3750, 0.1250, 0.2500],\n",
       "        [0.8750, 0.3750, 0.3250, 0.3250],\n",
       "        [0.8750, 0.3750, 0.3250, 0.1625],\n",
       "        [0.8750, 0.3750, 0.1625, 0.3250],\n",
       "        [0.1250, 0.6250, 0.1875, 0.1875],\n",
       "        [0.1250, 0.6250, 0.1875, 0.0938],\n",
       "        [0.1250, 0.6250, 0.0938, 0.1875],\n",
       "        [0.1250, 0.6250, 0.2500, 0.2500],\n",
       "        [0.1250, 0.6250, 0.2500, 0.1250],\n",
       "        [0.1250, 0.6250, 0.1250, 0.2500],\n",
       "        [0.1250, 0.6250, 0.3250, 0.3250],\n",
       "        [0.1250, 0.6250, 0.3250, 0.1625],\n",
       "        [0.1250, 0.6250, 0.1625, 0.3250],\n",
       "        [0.3750, 0.6250, 0.1875, 0.1875],\n",
       "        [0.3750, 0.6250, 0.1875, 0.0938],\n",
       "        [0.3750, 0.6250, 0.0938, 0.1875],\n",
       "        [0.3750, 0.6250, 0.2500, 0.2500],\n",
       "        [0.3750, 0.6250, 0.2500, 0.1250],\n",
       "        [0.3750, 0.6250, 0.1250, 0.2500],\n",
       "        [0.3750, 0.6250, 0.3250, 0.3250],\n",
       "        [0.3750, 0.6250, 0.3250, 0.1625],\n",
       "        [0.3750, 0.6250, 0.1625, 0.3250],\n",
       "        [0.6250, 0.6250, 0.1875, 0.1875],\n",
       "        [0.6250, 0.6250, 0.1875, 0.0938],\n",
       "        [0.6250, 0.6250, 0.0938, 0.1875],\n",
       "        [0.6250, 0.6250, 0.2500, 0.2500],\n",
       "        [0.6250, 0.6250, 0.2500, 0.1250],\n",
       "        [0.6250, 0.6250, 0.1250, 0.2500],\n",
       "        [0.6250, 0.6250, 0.3250, 0.3250],\n",
       "        [0.6250, 0.6250, 0.3250, 0.1625],\n",
       "        [0.6250, 0.6250, 0.1625, 0.3250],\n",
       "        [0.8750, 0.6250, 0.1875, 0.1875],\n",
       "        [0.8750, 0.6250, 0.1875, 0.0938],\n",
       "        [0.8750, 0.6250, 0.0938, 0.1875],\n",
       "        [0.8750, 0.6250, 0.2500, 0.2500],\n",
       "        [0.8750, 0.6250, 0.2500, 0.1250],\n",
       "        [0.8750, 0.6250, 0.1250, 0.2500],\n",
       "        [0.8750, 0.6250, 0.3250, 0.3250],\n",
       "        [0.8750, 0.6250, 0.3250, 0.1625],\n",
       "        [0.8750, 0.6250, 0.1625, 0.3250],\n",
       "        [0.1250, 0.8750, 0.1875, 0.1875],\n",
       "        [0.1250, 0.8750, 0.1875, 0.0938],\n",
       "        [0.1250, 0.8750, 0.0938, 0.1875],\n",
       "        [0.1250, 0.8750, 0.2500, 0.2500],\n",
       "        [0.1250, 0.8750, 0.2500, 0.1250],\n",
       "        [0.1250, 0.8750, 0.1250, 0.2500],\n",
       "        [0.1250, 0.8750, 0.3250, 0.3250],\n",
       "        [0.1250, 0.8750, 0.3250, 0.1625],\n",
       "        [0.1250, 0.8750, 0.1625, 0.3250],\n",
       "        [0.3750, 0.8750, 0.1875, 0.1875],\n",
       "        [0.3750, 0.8750, 0.1875, 0.0938],\n",
       "        [0.3750, 0.8750, 0.0938, 0.1875],\n",
       "        [0.3750, 0.8750, 0.2500, 0.2500],\n",
       "        [0.3750, 0.8750, 0.2500, 0.1250],\n",
       "        [0.3750, 0.8750, 0.1250, 0.2500],\n",
       "        [0.3750, 0.8750, 0.3250, 0.3250],\n",
       "        [0.3750, 0.8750, 0.3250, 0.1625],\n",
       "        [0.3750, 0.8750, 0.1625, 0.3250],\n",
       "        [0.6250, 0.8750, 0.1875, 0.1875],\n",
       "        [0.6250, 0.8750, 0.1875, 0.0938],\n",
       "        [0.6250, 0.8750, 0.0938, 0.1875],\n",
       "        [0.6250, 0.8750, 0.2500, 0.2500],\n",
       "        [0.6250, 0.8750, 0.2500, 0.1250],\n",
       "        [0.6250, 0.8750, 0.1250, 0.2500],\n",
       "        [0.6250, 0.8750, 0.3250, 0.3250],\n",
       "        [0.6250, 0.8750, 0.3250, 0.1625],\n",
       "        [0.6250, 0.8750, 0.1625, 0.3250],\n",
       "        [0.8750, 0.8750, 0.1875, 0.1875],\n",
       "        [0.8750, 0.8750, 0.1875, 0.0938],\n",
       "        [0.8750, 0.8750, 0.0938, 0.1875],\n",
       "        [0.8750, 0.8750, 0.2500, 0.2500],\n",
       "        [0.8750, 0.8750, 0.2500, 0.1250],\n",
       "        [0.8750, 0.8750, 0.1250, 0.2500],\n",
       "        [0.8750, 0.8750, 0.3250, 0.3250],\n",
       "        [0.8750, 0.8750, 0.3250, 0.1625],\n",
       "        [0.8750, 0.8750, 0.1625, 0.3250],\n",
       "        [0.2500, 0.2500, 0.3750, 0.3750],\n",
       "        [0.2500, 0.2500, 0.3750, 0.1875],\n",
       "        [0.2500, 0.2500, 0.1875, 0.3750],\n",
       "        [0.2500, 0.2500, 0.5000, 0.5000],\n",
       "        [0.2500, 0.2500, 0.5000, 0.2500],\n",
       "        [0.2500, 0.2500, 0.2500, 0.5000],\n",
       "        [0.2500, 0.2500, 0.6500, 0.6500],\n",
       "        [0.2500, 0.2500, 0.6500, 0.3250],\n",
       "        [0.2500, 0.2500, 0.3250, 0.6500],\n",
       "        [0.7500, 0.2500, 0.3750, 0.3750],\n",
       "        [0.7500, 0.2500, 0.3750, 0.1875],\n",
       "        [0.7500, 0.2500, 0.1875, 0.3750],\n",
       "        [0.7500, 0.2500, 0.5000, 0.5000],\n",
       "        [0.7500, 0.2500, 0.5000, 0.2500],\n",
       "        [0.7500, 0.2500, 0.2500, 0.5000],\n",
       "        [0.7500, 0.2500, 0.6500, 0.6500],\n",
       "        [0.7500, 0.2500, 0.6500, 0.3250],\n",
       "        [0.7500, 0.2500, 0.3250, 0.6500],\n",
       "        [0.2500, 0.7500, 0.3750, 0.3750],\n",
       "        [0.2500, 0.7500, 0.3750, 0.1875],\n",
       "        [0.2500, 0.7500, 0.1875, 0.3750],\n",
       "        [0.2500, 0.7500, 0.5000, 0.5000],\n",
       "        [0.2500, 0.7500, 0.5000, 0.2500],\n",
       "        [0.2500, 0.7500, 0.2500, 0.5000],\n",
       "        [0.2500, 0.7500, 0.6500, 0.6500],\n",
       "        [0.2500, 0.7500, 0.6500, 0.3250],\n",
       "        [0.2500, 0.7500, 0.3250, 0.6500],\n",
       "        [0.7500, 0.7500, 0.3750, 0.3750],\n",
       "        [0.7500, 0.7500, 0.3750, 0.1875],\n",
       "        [0.7500, 0.7500, 0.1875, 0.3750],\n",
       "        [0.7500, 0.7500, 0.5000, 0.5000],\n",
       "        [0.7500, 0.7500, 0.5000, 0.2500],\n",
       "        [0.7500, 0.7500, 0.2500, 0.5000],\n",
       "        [0.7500, 0.7500, 0.6500, 0.6500],\n",
       "        [0.7500, 0.7500, 0.6500, 0.3250],\n",
       "        [0.7500, 0.7500, 0.3250, 0.6500],\n",
       "        [0.5000, 0.5000, 0.7500, 0.7500],\n",
       "        [0.5000, 0.5000, 0.7500, 0.3750],\n",
       "        [0.5000, 0.5000, 0.3750, 0.7500],\n",
       "        [0.5000, 0.5000, 1.0000, 1.0000],\n",
       "        [0.5000, 0.5000, 1.0000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000, 1.0000],\n",
       "        [0.5000, 0.5000, 1.3000, 1.3000],\n",
       "        [0.5000, 0.5000, 1.3000, 0.6500],\n",
       "        [0.5000, 0.5000, 0.6500, 1.3000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get batch, acts, item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get batch, acts\n",
    "head = SSD_MultiHead(k, -4.)\n",
    "mod = CustMod(body, head)\n",
    "mod.cpu().eval()\n",
    "\n",
    "batch = next(iter(dls.cpu().valid))\n",
    "acts = mod(batch[0])\n",
    "bbs, lbls = batch[1], batch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get acts and targs for a single im\n",
    "abb,albl,bb,lbl = list(zip(*acts,bbs,lbls))[b_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([189, 4]), torch.Size([189, 21]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abb.shape,albl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9177, -0.7167,  0.5527,  0.9417],\n",
       "         [-0.5219, -0.7125,  0.2134,  0.1583],\n",
       "         [ 0.0437,  0.1958,  0.5321,  0.7083],\n",
       "         [-0.0026,  0.1167,  0.3728,  0.4792],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000]]),\n",
       " tensor([12, 14, 12, 14,  0,  0,  0,  0,  0,  0,  0,  0]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb,lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ssd item loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process single im acts and targs in loss fxn\n",
    "#assignments\n",
    "b_bb,b_c,bbox,clas=abb,albl,bb,lbl\n",
    "print_it=False\n",
    "use_ab=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-2.3297e-03, -3.1808e-03,  9.5253e-04,  7.0685e-04],\n",
       "         [ 1.9510e-04,  8.7426e-04,  2.3756e-03,  3.1622e-03],\n",
       "         [-1.1476e-05,  5.2083e-04,  1.6641e-03,  2.1391e-03]]),\n",
       " tensor([12, 14, 12, 14]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox,clas = get_y(bbox,clas)\n",
    "bbox,clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([189, 4]),\n",
       " tensor([[0.0261, 0.0401, 0.2435, 0.2494],\n",
       "         [0.0523, 0.1568, 0.2402, 0.2531],\n",
       "         [0.1014, 0.0593, 0.2156, 0.2501],\n",
       "         [0.0030, 0.0022, 0.2046, 0.2665],\n",
       "         [0.0405, 0.0229, 0.2655, 0.1392]], device='cuda:0',\n",
       "        grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ic = actn_to_bb(b_bb, anchors)\n",
    "a_ic.shape, a_ic[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 189]),\n",
       " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6586e-04, 0.0000e+00, 0.0000e+00,\n",
       "          4.6010e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1484e-05, 0.0000e+00, 0.0000e+00,\n",
       "          1.1503e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0372e-05, 0.0000e+00, 0.0000e+00,\n",
       "          2.8756e-05, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0771e-05, 0.0000e+00, 0.0000e+00,\n",
       "          1.2081e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6930e-06, 0.0000e+00, 0.0000e+00,\n",
       "          3.0202e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7329e-07, 0.0000e+00, 0.0000e+00,\n",
       "          7.5504e-06, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 7.9822e-05, 0.0000e+00, 0.0000e+00,\n",
       "          4.7232e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9955e-05, 0.0000e+00, 0.0000e+00,\n",
       "          1.1808e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9889e-06, 0.0000e+00, 0.0000e+00,\n",
       "          2.9520e-06, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3087e-05, 0.0000e+00, 0.0000e+00,\n",
       "          2.5671e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0772e-05, 0.0000e+00, 0.0000e+00,\n",
       "          6.4178e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6930e-06, 0.0000e+00, 0.0000e+00,\n",
       "          1.6045e-06, 0.0000e+00, 0.0000e+00]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps = jaccard(bbox.data, anchor_cnr.data)\n",
    "overlaps.shape, overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9900e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.9900e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1484e-05, 0.0000e+00, 0.0000e+00,\n",
       "         1.1503e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0372e-05, 0.0000e+00, 0.0000e+00,\n",
       "         2.8756e-05, 0.0000e+00, 0.0000e+00]),\n",
       " tensor([0, 0, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_overlap,gt_idx = map_to_ground_truth(overlaps)\n",
    "gt_overlap,gt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 12, 12, 14, 12, 12, 14, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_clas = clas[gt_idx]\n",
    "gt_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  True, False, False,  True, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = gt_overlap > 0.4\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_idx = torch.nonzero(pos)[:,0]\n",
    "pos_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20, 20, 20, 14, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_clas[~pos] = dls.ncls\n",
    "gt_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([189, 4]),\n",
       " tensor([[-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-1.1476e-05,  5.2083e-04,  1.6641e-03,  2.1391e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-2.3297e-03, -3.1808e-03,  9.5253e-04,  7.0685e-04],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03],\n",
       "         [-4.0970e-03, -3.1994e-03,  2.4674e-03,  4.2039e-03]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_bbox = bbox[gt_idx]\n",
    "gt_bbox.shape, gt_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1364, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_loss = ((a_ic.cpu()[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\n",
    "loc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.1986, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cpu'\n",
    "clas_loss  = loss_f(b_c.cpu(), gt_clas.cpu())\n",
    "clas_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lbl loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clas_loss\n",
    "#assignments\n",
    "preds,targets = b_c.cpu(),gt_clas.cpu()\n",
    "num_classes=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([189, 21]),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = one_hot_embedding(targets, num_classes+1)\n",
    "t.shape, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([189, 20]),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tensor(t[:,:-1].contiguous())\n",
    "t.shape, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([189, 20]),\n",
       " tensor([[-4.0802, -3.6891, -3.8384,  ..., -3.7442, -3.4973, -3.8569],\n",
       "         [-3.3145, -3.9785, -4.4999,  ..., -4.2666, -4.1959, -3.7895],\n",
       "         [-3.8018, -4.3627, -4.3670,  ..., -4.2720, -3.6047, -3.8739],\n",
       "         ...,\n",
       "         [-4.0017, -3.9917, -4.0002,  ..., -3.9941, -3.9885, -3.9979],\n",
       "         [-4.0118, -3.9898, -3.9929,  ..., -4.0014, -4.0001, -3.9908],\n",
       "         [-3.9951, -4.0137, -4.0054,  ..., -3.9829, -3.9871, -3.9828]],\n",
       "        grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = preds[:,:-1]\n",
    "x.shape,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(x,t):\n",
    "    alpha,gamma = 0.25,2.\n",
    "    p = x.sigmoid()\n",
    "    pt = p*t + (1-p)*(1-t)\n",
    "    w = alpha*t + (1-alpha)*(1-t)\n",
    "    return w * (1-pt).pow(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([189, 20]),\n",
       " tensor([[2.0725e-04, 4.4598e-04, 3.3307e-04,  ..., 4.0050e-04, 6.4780e-04,\n",
       "          3.2122e-04],\n",
       "         [9.2278e-04, 2.5309e-04, 9.0553e-05,  ..., 1.4356e-04, 1.6502e-04,\n",
       "          3.6657e-04],\n",
       "         [3.5785e-04, 1.1875e-04, 1.1775e-04,  ..., 1.4205e-04, 5.2567e-04,\n",
       "          3.1073e-04],\n",
       "         ...,\n",
       "         [2.4181e-04, 2.4661e-04, 2.4252e-04,  ..., 2.4544e-04, 2.4818e-04,\n",
       "          2.4365e-04],\n",
       "         [2.3708e-04, 2.4751e-04, 2.4603e-04,  ..., 2.4197e-04, 2.4256e-04,\n",
       "          2.4704e-04],\n",
       "         [2.4495e-04, 2.3618e-04, 2.4009e-04,  ..., 2.5093e-04, 2.4887e-04,\n",
       "          2.5096e-04]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = get_weight(x,t).detach()\n",
    "w.shape, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
