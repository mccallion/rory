{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data</a></span></li><li><span><a href=\"#Arch\" data-toc-modified-id=\"Arch-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Arch</a></span></li><li><span><a href=\"#Loss\" data-toc-modified-id=\"Loss-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Loss</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Train</a></span></li><li><span><a href=\"#Stepping-Through-a-Batch\" data-toc-modified-id=\"Stepping-Through-a-Batch-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Stepping Through a Batch</a></span></li><li><span><a href=\"#Loss\" data-toc-modified-id=\"Loss-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Loss</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**~ JH's Code ~**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports & Paths ###\n",
    "from fastai.vision.all import *\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "### Params ###\n",
    "im_sz   = 224\n",
    "bs      = 64\n",
    "val_pct = .2\n",
    "sub_pct = 1\n",
    "path = untar_data(URLs.PASCAL_2007)\n",
    "annos_path = path/'train.json'\n",
    "ims_path = path/'train'\n",
    "\n",
    "\n",
    "### Items ###\n",
    "fns, annos = get_annotations(annos_path)\n",
    "fn2anno = {f:a for f,a in zip(fns,annos)}\n",
    "def get_im(f):   return ims_path/f\n",
    "def get_bbox(f): return fn2anno[f][0]\n",
    "def get_lbl(f):  return fn2anno[f][1]\n",
    "\n",
    "\n",
    "### DataLoaders ###\n",
    "tfmz = setup_aug_tfms([Rotate(), Brightness(), Contrast(), Flip(),\n",
    "                       Normalize.from_stats(*imagenet_stats)])\n",
    "db = DataBlock(\n",
    "    blocks=[ImageBlock, BBoxBlock, BBoxLblBlock(add_na=False)],\n",
    "    get_x=get_im, get_y=[get_bbox, get_lbl],\n",
    "    splitter=RandomSplitter(val_pct),\n",
    "    item_tfms=Resize(im_sz, method='squish'),\n",
    "    batch_tfms=tfmz, n_inp=1)\n",
    "subset = L(fns).shuffle()[0:int(len(fns)*sub_pct)]\n",
    "dls = db.dataloaders(subset, bs=bs)\n",
    "dls.v = dls.vocab\n",
    "dls.ncls = len(dls.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: (#20) ['aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair','cow'...]\n",
      "Size of train data: 2001\n",
      "Size of valid data: 500\n",
      "batch[0]: \t torch.float32 \t torch.Size([64, 3, 224, 224])\n",
      "batch[1]: \t torch.float32 \t torch.Size([64, 10, 4])\n",
      "batch[2]: \t torch.int64 \t torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "### Inspection ###\n",
    "print(\"Vocab:\", dls.v)\n",
    "print(\"Size of train data:\",len(dls.train.items))\n",
    "print(\"Size of valid data:\",len(dls.valid.items))\n",
    "for i,t in enumerate(dls.one_batch()):\n",
    "    print(f\"batch[{i}]:\",'\\t',t.dtype,'\\t',t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of tensor shapes:\n",
    "- torch.Size([128, 3, 224, 224]): bs, channels (rgb), im_sz, im_sz\n",
    "- torch.Size([128, 20, 4]): bs, max objs for a single im in batch, bb coords\n",
    "- torch.Size([128, 20]): bs, max objs for a single im in batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Anchors ###\n",
    "anc_grids = [4,2,1]\n",
    "# anc_grids = [4]\n",
    "anc_zooms = [0.75, 1., 1.3]\n",
    "# anc_zooms = [1.]\n",
    "anc_ratios = [(1.,1.), (1.,0.5), (0.5,1.)]\n",
    "# anc_ratios = [(1.,1.)]\n",
    "anchor_scales = [(anz*i,anz*j) for anz in anc_zooms for (i,j) in anc_ratios]\n",
    "k = len(anchor_scales)\n",
    "anc_offsets = [1/(o*2) for o in anc_grids]\n",
    "anc_x = np.concatenate([np.tile(np.linspace(ao, 1-ao, ag), ag)\n",
    "                        for ao,ag in zip(anc_offsets,anc_grids)])\n",
    "anc_y = np.concatenate([np.repeat(np.linspace(ao, 1-ao, ag), ag)\n",
    "                        for ao,ag in zip(anc_offsets,anc_grids)])\n",
    "anc_ctrs = np.repeat(np.stack([anc_x,anc_y], axis=1), k, axis=0)\n",
    "anc_sizes  =   np.concatenate([np.array([[o/ag,p/ag] for i in range(ag*ag) for o,p in anchor_scales])\n",
    "               for ag in anc_grids])\n",
    "grid_sizes = tensor(np.concatenate([np.array([ 1/ag       for i in range(ag*ag) for o,p in anchor_scales])\n",
    "               for ag in anc_grids]), requires_grad=False).unsqueeze(1)\n",
    "anchors = tensor(np.concatenate([anc_ctrs, anc_sizes], axis=1), requires_grad=False).float()\n",
    "\n",
    "def hw2corners(ctr, hw): return torch.cat([ctr-hw/2,ctr+hw/2], dim=1)\n",
    "anchor_cnr = hw2corners(anchors[:,:2], anchors[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([189, 4]), tensor([0.8750, 0.6250, 0.1875, 0.0938]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors.shape, anchors[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Architecture ###\n",
    "class StdConv(nn.Module):\n",
    "    def __init__(self, n_in,n_out,stride=2,dp = 0.1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(n_in,n_out,3,stride=stride,padding=1)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        self.dropout = nn.Dropout(dp)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.dropout(self.bn(F.relu(self.conv(x))))\n",
    "    \n",
    "def flatten_conv(x,k):\n",
    "    bs,nf,gx,gy = x.size()\n",
    "    x = x.permute(0,2,3,1).contiguous()\n",
    "    return x.view(bs,-1,nf//k)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, k, n_in, bias):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.bbs  = nn.Conv2d(n_in,            4*k, 3, padding=1)\n",
    "        self.lbls = nn.Conv2d(n_in, (dls.ncls+1)*k, 3, padding=1)\n",
    "        self.lbls.bias.data.zero_().add_(bias)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return [flatten_conv(self.bbs(x),  self.k),\n",
    "                flatten_conv(self.lbls(x), self.k)]\n",
    "    \n",
    "drop=0.4\n",
    "class SSD_MultiHead(nn.Module):\n",
    "    def __init__(self, k, bias):\n",
    "        super().__init__()\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.sconv1 = StdConv(512,256, dp=drop)\n",
    "        self.sconv2 = StdConv(256,256, dp=drop)\n",
    "        self.sconv3 = StdConv(256,256, dp=drop)\n",
    "        self.out1 = OutConv(k, 256, bias)\n",
    "        self.out2 = OutConv(k, 256, bias)\n",
    "        self.out3 = OutConv(k, 256, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop(F.relu(x))\n",
    "        x = self.sconv1(x)\n",
    "        bbs1,lbls1 = self.out1(x)\n",
    "        x = self.sconv2(x)\n",
    "        bbs2,lbls2 = self.out2(x)\n",
    "        x = self.sconv3(x)\n",
    "        bbs3,lbls3 = self.out3(x)\n",
    "        return [torch.cat([ bbs1, bbs2, bbs3], dim=1),\n",
    "                torch.cat([lbls1,lbls2,lbls3], dim=1)]\n",
    "    \n",
    "class CustMod(Module):\n",
    "    \"\"\"A module made from a pretrained body and an untrained head.\"\"\"\n",
    "    def __init__(self, body, head):\n",
    "        self.body, self.head = body, head\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.head(self.body(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FocalLoss ###\n",
    "def one_hot_embedding(labels, num_classes):\n",
    "    return torch.eye(num_classes)[labels.data].to('cuda')\n",
    "\n",
    "class BCE_Loss(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def forward(self, preds, targets):\n",
    "        t = one_hot_embedding(targets, self.num_classes+1)\n",
    "        t = tensor(t[:,:-1].contiguous())\n",
    "        x = preds[:,:-1]\n",
    "        w = self.get_weight(x,t).detach()\n",
    "        return F.binary_cross_entropy_with_logits(x, t, w, reduction='sum') / self.num_classes\n",
    "    \n",
    "    def get_weight(self,x,t):\n",
    "        return None\n",
    "\n",
    "class FocalLoss(BCE_Loss):\n",
    "    def get_weight(self,x,t):\n",
    "        alpha,gamma = 0.25,2.\n",
    "        p = x.sigmoid()\n",
    "        pt = p*t + (1-p)*(1-t)\n",
    "        w = alpha*t + (1-alpha)*(1-t)\n",
    "        return w * (1-pt).pow(gamma)\n",
    "\n",
    "loss_f = FocalLoss(dls.ncls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IoU ###\n",
    "def intersection(box_a,box_b):\n",
    "    min_xy = torch.max(box_a[:,None,:2],box_b[None,:,:2])\n",
    "    max_xy = torch.min(box_a[:,None,2:],box_b[None,:,2:])\n",
    "    inter = torch.clamp(max_xy-min_xy,min=0)\n",
    "    return inter[:,:,0] * inter[:,:,1]\n",
    "\n",
    "def get_size(box):\n",
    "    return (box[:,2]-box[:,0]) * (box[:,3] - box[:,1])\n",
    "\n",
    "def jaccard(box_a,box_b):\n",
    "    inter = intersection(box_a,box_b)\n",
    "    union = get_size(box_a).unsqueeze(1) + get_size(box_b).unsqueeze(0) - inter\n",
    "    return inter/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ssd_loss ###\n",
    "def get_y(bbox,clas):\n",
    "    bbox = bbox.view(-1,4)/size\n",
    "    bb_keep = ((bbox[:,2] - bbox[:,0])>0.).nonzero()[:,0]\n",
    "    return bbox[bb_keep], clas[bb_keep]\n",
    "    \n",
    "def actn_to_bb(actn, anchors):\n",
    "    actn_bbs = torch.tanh(actn)\n",
    "    actn_ctrs = (actn_bbs.cuda()[:,:2] * grid_sizes.cuda()/2) + anchors.cuda()[:,:2]\n",
    "    actn_hw = (1 + actn_bbs.cuda()[:,2:]/2) * anchors.cuda()[:,2:]\n",
    "    return hw2corners(actn_ctrs,actn_hw)\n",
    "\n",
    "def map_to_ground_truth(overlaps, print_it=False):\n",
    "    prior_overlap, prior_idx = overlaps.max(1)\n",
    "    if print_it: print(prior_overlap)\n",
    "    gt_overlap, gt_idx = overlaps.max(0)\n",
    "    gt_overlap[prior_idx] = 1.99\n",
    "    for i,o in enumerate(prior_idx): gt_idx[o] = i\n",
    "    return gt_overlap,gt_idx\n",
    "\n",
    "def ssd_1_loss(b_bb, b_c, bbox, clas, print_it=False, use_ab=True):\n",
    "    bbox,clas = get_y(bbox,clas)\n",
    "    a_ic = actn_to_bb(b_bb, anchors)\n",
    "    overlaps = jaccard(bbox.data, (anchor_cnr.cuda() if use_ab else a_ic).data)\n",
    "    gt_overlap,gt_idx = map_to_ground_truth(overlaps)\n",
    "    gt_clas = clas[gt_idx]\n",
    "    pos = gt_overlap > 0.4\n",
    "    pos_idx = torch.nonzero(pos)[:,0]\n",
    "    gt_clas[~pos] = dls.ncls\n",
    "    gt_bbox = bbox[gt_idx]\n",
    "    loc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\n",
    "    clas_loss  = loss_f(b_c, gt_clas)\n",
    "    return loc_loss, clas_loss\n",
    "\n",
    "def ssd_loss(pred, targ_bb, targ_lbl, print_it=True):\n",
    "    bb_sum,lbl_sum = 0.,0.\n",
    "    for pred_bb,pred_lbl,bbox,clas in zip(*pred,targ_bb,targ_lbl):\n",
    "        bb_loss,lbl_loss = ssd_1_loss(pred_bb,pred_lbl,bbox,clas,print_it)\n",
    "        bb_sum += bb_loss\n",
    "        lbl_sum += lbl_loss\n",
    "    if print_it: print(f\"bb:{bb_sum:.02f} | lbl: {lbl_sum:.02f}\")\n",
    "    return bb_sum + lbl_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = im_sz\n",
    "batch_size = bs\n",
    "head_reg4 = SSD_MultiHead(k, -4.)\n",
    "model = CustMod(create_body(resnet34, pretrained=True), head_reg4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb:10.85 | lbl: 4.43\n",
      "bb:10.77 | lbl: 4.50\n",
      "bb:11.00 | lbl: 4.56\n",
      "bb:11.22 | lbl: 4.14\n",
      "bb:11.11 | lbl: 4.46\n",
      "bb:11.15 | lbl: 4.20\n",
      "bb:10.91 | lbl: 4.51\n",
      "bb:10.92 | lbl: 4.39\n",
      "bb:10.94 | lbl: 4.25\n",
      "bb:10.94 | lbl: 4.50\n",
      "bb:10.70 | lbl: 4.48\n",
      "bb:11.12 | lbl: 4.38\n",
      "bb:10.61 | lbl: 4.61\n",
      "bb:11.17 | lbl: 3.98\n",
      "bb:10.87 | lbl: 4.70\n",
      "bb:10.88 | lbl: 4.51\n",
      "bb:10.75 | lbl: 4.17\n",
      "bb:10.72 | lbl: 4.65\n",
      "bb:10.76 | lbl: 4.36\n",
      "bb:10.70 | lbl: 4.25\n",
      "bb:10.56 | lbl: 4.34\n",
      "bb:10.58 | lbl: 4.42\n",
      "bb:10.72 | lbl: 4.47\n",
      "bb:10.21 | lbl: 4.31\n",
      "bb:10.38 | lbl: 4.48\n",
      "bb:10.28 | lbl: 4.33\n",
      "bb:10.33 | lbl: 4.49\n",
      "bb:9.92 | lbl: 4.66\n",
      "bb:9.71 | lbl: 4.37\n",
      "bb:9.48 | lbl: 3.86\n",
      "bb:9.28 | lbl: 4.30\n",
      "bb:8.86 | lbl: 4.39\n",
      "bb:8.32 | lbl: 4.47\n",
      "bb:8.17 | lbl: 4.10\n",
      "bb:7.53 | lbl: 4.13\n",
      "bb:7.02 | lbl: 4.30\n",
      "bb:6.70 | lbl: 4.21\n",
      "bb:6.02 | lbl: 3.94\n",
      "bb:5.93 | lbl: 4.00\n",
      "bb:5.69 | lbl: 4.27\n",
      "bb:5.39 | lbl: 3.77\n",
      "bb:5.39 | lbl: 4.18\n",
      "bb:5.12 | lbl: 3.64\n",
      "bb:5.10 | lbl: 3.52\n",
      "bb:4.99 | lbl: 3.09\n",
      "bb:4.93 | lbl: 3.36\n",
      "bb:4.86 | lbl: 3.07\n",
      "bb:4.87 | lbl: 2.59\n",
      "bb:4.89 | lbl: 2.09\n",
      "bb:4.88 | lbl: 1.95\n",
      "bb:4.84 | lbl: 2.14\n",
      "bb:4.80 | lbl: 2.63\n",
      "bb:4.85 | lbl: 3.44\n",
      "bb:4.83 | lbl: 2.51\n",
      "bb:4.80 | lbl: 1.96\n",
      "bb:4.86 | lbl: 2.08\n",
      "bb:4.81 | lbl: 2.38\n",
      "bb:4.80 | lbl: 2.27\n",
      "bb:4.86 | lbl: 1.94\n",
      "bb:4.81 | lbl: 1.95\n",
      "bb:4.84 | lbl: 2.50\n",
      "bb:4.87 | lbl: 1.74\n",
      "bb:4.91 | lbl: 1.85\n",
      "bb:4.88 | lbl: 1.99\n",
      "bb:4.85 | lbl: 2.41\n",
      "bb:4.87 | lbl: 2.11\n",
      "bb:4.88 | lbl: 2.08\n",
      "bb:4.88 | lbl: 2.32\n",
      "bb:4.86 | lbl: 2.58\n",
      "bb:4.86 | lbl: 8.38\n",
      "bb:4.89 | lbl: 6.90\n",
      "bb:4.85 | lbl: 133.69\n",
      "bb:4.81 | lbl: 106.23\n",
      "bb:4.85 | lbl: 100.48\n",
      "bb:4.85 | lbl: 73.87\n",
      "bb:4.85 | lbl: 147.46\n",
      "bb:4.85 | lbl: 42.90\n",
      "bb:4.93 | lbl: 864.93\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAApIElEQVR4nO3dd5xU5b3H8c9vtldYYFmaSxVQOqwFS2xRUbHGEmwkGhGNJdEYk5hczb2mqYleK6IisaFo1NiN3hixYKELCCgiTXrdXbbOPPePGXDBYdmFmT1nZr7v12tf7Jw5Z87vYXfnN895nvP8zDmHiIjIrgJeByAiIv6kBCEiIlEpQYiISFRKECIiEpUShIiIRKUEISIiUaV7HUBTtGvXznXr1s3rMEREEsr06dPXO+eK9/b4hEgQ3bp1Y9q0aV6HISKSUMxs6b4cr0tMIiISlRKEiIhEpQQhIiJRKUGIiEhUShAiIhJV3BKEmU0ws7VmNneX7Veb2UIzm2dmt8Xr/CIism/i2YOYCIxouMHMjgFOBwY65/oBd8Tx/CIiCWvLtjrenLeadeU1nsUQtwThnJsCbNxl8xXAn51zNZF91sbr/CIiiezLdeVc/vh05n2zxbMYWnoMojdwpJl9bGbvmtlBLXx+EZGEUFETBCA/y7v7mVv6zOlAEXAocBAw2cx6uChl7cxsDDAGoLS0tEWDFBHxWmVNPQB5HiaIlu5BrACed2GfACGgXbQdnXPjnXNlzrmy4uK9XkpERCQhVUQShJc9iJZOEC8CxwKYWW8gE1jfwjGIiPieH3oQcTuzmU0CjgbamdkK4GZgAjAhMvW1Fhgd7fKSiEiq+zZBpHkWQ9wShHNu1G6eujBe5xQRSRYVNUEy0oysdO8ShO6kFhHxocqaek8vL4EShIiIL1XW1JOXqQQhIiK7qKip93QGEyhBiIj4UmVtvacD1KAEISLiSxU1QY1BiIjId1XqEpOIiESjWUwiIhKVBqlFROQ7nHORHoQGqUVEpIHquhAh5+06TKAEISLiO35YyRWUIEREfGfHQn26k1pERBqq8MFS39DyFeUSyuot1bw5bzXfbK6iTV4mbfOzaJuXSWFOOvVBR13QURcMEQw52uRnUlKYTXF+FpnpyrsisvcqfXKJKaUThHOOqV9tYFtNkKyMAFnpaaQFjBlLN/H63FXMWLYZgMy0ALXBUJNft01eJj2L8+jXqRX9O7eif+dCinIzKa+uY2t1PVur6jAzurfNo3NRDmkB2+n4YMixaVst+VnpZGd4O4tBRFpeZa33tSAghRPElqo6bnxuDm/MWx31+X6dCrnhxD6M6N+BHu3yqKwNsqGihg2VtZRX15MRMDLSA2SkBTBgY2Uta7ZWs7a8hlVbqlm0ppxnPl3OxA+/bjSOzLQAXdvm0rF1Dpu3hV9jXXkNoUgZpaLcDEoKs+nQKptOrXPYryiXLkU5dCnKISMtwNIN2/h6QyVL1leyeks1dcEQ9SFHfSSh9e1QyEHd23Bwtzbs1yYHM2skGhHxg4qaIKAehCdmLtvE1ZNmsnpLNb86qS+H9WxLbX2ImvoQNfVBehbn07Vt3k7H5Gelk5+V/p3tjQmGHEvWVzB35VYqauopyE6nMCeDwux0giFYsr6Cr9ZVsnhdJau3VtEmL4s+JQV0aJVN27xMyqvrWb21mjVbq1m1pZrZyzezaVtd1HO1L8iiU+scstID5GSkkZ4dvgz2xrzVPDNtOQAlhVkU5WbuSCD1IUd2RholhVnhJFQYTkK9SwroXZJP69zMvf9PFpG95odyo5DkCeKNuav4bOUW2uZl0TY/k3b5WXy2cgt3vLmQksJsJo8dztDSoridPy1g9GpfQK/2BVGfP7h7m2a/ZkVNPSs3VbF84zbqgiG6ts2ja9vc3f4ihUKOL9ZW8MnXG5mxdBMVNfVkpBnpgQDpaUZVbZDVW6v5aPEG1pbXUB/6tgJsSWEWvUsK6FNSQJ8OBfTtUMj+Jfm67CUSZ0oQLeDjJRt5bOpSgqGdy16fcGAJt589iFa5GR5Ftvfys9Lp0yH8ht0UgYDt2P+iQ7s2um8w5Fi9NXx5bNHqchatqWDhmq08/tFSaurDl6wCBh0Ks+lclEOn1jl0bp1DUW4mGWlGZnoamekBSgqzOKhbGyUSkb20YxZTpsYg4ubmU/vxu1MOZEtVHRsqa9lQUYMDDuneRtfio0gLGJ0jb/rH9Gm/Y3sw5Ph6QyULV5ezcHU5yzdtY+WmKmYs28Src1bt1OvYLicjjSP2b8dxfdtzVJ9iOhRm6/9cpIkqa+rJzgiQnubtjMikThAQ/gRdlJdJUV4mvdrnex1OQkoLGD2L8+lZnM/JAzru9Fww5KiqC1JbH9rxtXh9Be8sWMv/fb6Wt+avAYiM3+RGvvIY0LkVw7oWUVKY7UWTRHytoibo+QA1pECCkPhKC1j4Fznr222lbXM5pk97fn+aY+GacqYu3rBjttWCVeX8a96aHb2Ozq1zGFLamr4dCtivTS5dinIpbZNLu/xM9TgkZflhqW9QgpA4MjP6diikb4fCnbbX1oeY980WZizbzIxlm5i5bDOvzFm10z6F2ekM7NKagV1aMbBLa4Z2bU37AvU2JDVU1tR7vswGKEGIBzLTAwwpLWJIaRGX0h2A6rogKzZtY9nGbSzbsI2FayqYs2Iz46d8RX3IYQbDe7TlrKFdOKl/B198uhKJFz/UgoA4JggzmwCMBNY65/pHtt0CXAasi+z2G+fca/GKQRJHdkZa1CnB1XVB5q/aypRF63hh5kp+8exsfvfiXE4a0IGrj92f7u2afl+KSKKorK2nOD9rzzvGWTxT1ETgXuCxXbbf6Zy7I47nlSSSnZHG0NIihpYWce1x+zN96Sb+MWMlL81aySuzV3HZ97rz02N6keuD7rhIrFTWBOnW1vvf6bjNoXLOTQE2xuv1JfWYGWXd2vCnswbwzg1HM3JgR+57ZzHf/+u7vPbZKpz77nRbkUTkl0tMXkyyvcrM5pjZBDOL323MktTaF2Tzt/MG8+zY4bTKzeTKJ2dw5v0f8q95qwlFuS9DJJH4ZRZTSyeIB4CewGBgFfDX3e1oZmPMbJqZTVu3bt3udpMUd1C3Nrx81eH88cwBrK+oYczj0xnxv1N4YeaKHQsWiiSSUMixrTaYegnCObfGORd0zoWAh4CDG9l3vHOuzDlXVlxc3HJBSsJJTwtw/iGl/OcXR3PXeYMxjJ8/M5vj75zCG3N16UkSy/alvvM9XuobWjhBmFnD23DPBOa25PkluaWnBThjSGdev/ZIxl80jPSAMfaJGZwzbiozlm3yOjyRJqmMLPXthx5EPKe5TgKOBtqZ2QrgZuBoMxsMOOBr4PJ4nV9SVyBgnNCvA8f2bc/kaSv421uLOOv+Dzl1UCduPvVA2vlg+qDI7lT4pJocxDFBOOdGRdn8SLzOJ7Kr7ZeeThvcifHvLmbcu1/x/hfr+O/T+zNyYEct5SG+tGOpbx9M3VbxZEl6+VnpXHdCH1655ghK2+Ry9aSZXPnkDNZX1Hgdmsh3+KUWBChBSArpXVLAP644jF+O6MP/fb6WE+6cwpRFmiEn/uKnS0xKEJJS0tMCXHl0L1655giK87MY/egn3PfOl5rpJL6xfRZTXqrNYhLxi94lBbzw08MYObATt7+5kLFPTKe8Onq9b5GWVBGZxaQehIiHcjPTufuHg/ntKQfw9udrOf2+D1iyvtLrsCTFaQxCxCfMjJ8c2YMnLj2EzdvqOPuBD5m7covXYUkKq6ypxwxyPa5HDUoQIgAM79mWZ8cOJys9wKjxH/HJEq0zKd6oiBQL8sM0bCUIkYiexfk8d8VhtC/M4qJHPubfC9Z4HZKkoPBCfd73HkAJQmQnnVrnMPny4fQuKWDMY9P556yVXockKaayxh8L9YEShMh3tM3P4qnLDmFY1yJ+/swsnpu+wuuQJIX4pRYEKEGIRFWQncHEHx/MYT3bccNzs3n6k2VehyQpojIyBuEHShAiu5GTmcbDo8v43v7F/Or5z3j8o6VehyQpoMInxYJACUKkUdkZaYy/eBjH9W3P716cy8QPlngdkiS5ytp6X9SCACUIkT3KSk/jgQuHccKBJdzy8nyeUE9C4kiD1CIJJjM9wL3nD+XYvu357Ytz+YcGriVONEgtkoAy0wPcf8FQjugVHrh+dc4qr0OSJFMXDFFbH1IPQiQRbR+TGNa1iGufnsnb83UzncSOn9ZhAiUIkWbLzUxnwo8Ool+nQq58cgazlm/2OiRJEt/WgtAgtUjC2n6fREmrLK54Yrqq00lMVEaW+lYPQiTBFeVlMu7CYWzaVstPn5xBXTDkdUiS4Cp0iUkkefTr1Io/nTWAj5ds5E+vLfA6HElwlT4qNwrgjyhEEtiZQ7owe/kWJnywhEH7teL0wZ29DkkS1I5Bai21IZI8bjrlAA7u3oYb/zGHed+o4JDsnQqf9SCUIERiICMtwH3nD6UoN5PL/j6NteXVXockCejbaa5JPovJzCaY2VozmxvluV+YmTOzdvE6v0hLKy7I4qGLy9i0rY7LH59OdV3Q65AkwVTWps4sponAiF03mtl+wPGA1k+WpNO/cyv+du4gZi7bzK+f/wznnNchSQKpqKknPWBkpfvj4k7conDOTQGiFfa9E/gloL8cSUonDejIdcf35oWZK3ng3cVehyMJpDKy1Lcf6lFDC89iMrPTgJXOudl++Q8QiYerj+3FF2sruP3NhfQszufEfh28DkkSgJ8W6oMWHKQ2s1zgJuC/mrj/GDObZmbT1q1bF9/gRGLMzLj97IEM7NKaa5+eyYxlm7wOSRJAuAfhjwFqaNlZTD2B7sBsM/sa6ALMMLOoH62cc+Odc2XOubLi4uIWDFMkNrIz0nhkdBklhdlcOvFTvlpX4XVI4nN+qgUBLZggnHOfOefaO+e6Oee6ASuAoc651S0Vg0hLa5efxd9/fDBmxuhHP2FdudZskt1LmUtMZjYJmAr0MbMVZnZpvM4l4mfd2uXxyOgy1pXXcMnET3fMdRfZVWVNvW/uoob4zmIa5Zzr6JzLcM51cc49ssvz3Zxz6+N1fhE/GVJaxH3nD2XeN1u49umZhEKaxCfftX0Wk1/4Y7KtSAo47oASbj61H29/vpb7//Ol1+GID4UvMaXmILVIyrt4eFfOGNyJv761iPe+0Ow8+ZZzjsraFB2kFpHw9Nc/njWA/dvnc+3Ts/hmc5XXIYlP1NSHCIacEoRIKsvNTOeBC4dRWx/iyidnUFuvQkPiv5VcQQlCxBM9i/O5/eyBzFq+mVtfne91OOIDlT6rJgdKECKeOWlAR8Z8rwePTV3Kox8s8Toc8di3PQj/DFL7J1WJpKAbR/Rl2YZt/Pcr8ykuyGLkwE5ehyQeqazx11LfoB6EiKfSAsZdPxxMWdcirntmNlMXb/A6JPGILjGJyHdkZ6Tx0MVllLbNZczj01iweqvXIYkHNEgtIlG1zs3k75ccTF5mOqMnfMLqLSpZmmrUgxCR3ercOoeJlxxERXU9Vz45XdNfU8yOHkQqrMUkIs3Xt0Mht509iBnLNP011WyvYZ6T6Z9ZTEoQIj5zysCOXHZkdx6bupTnZ6zwOhxpIVV1QdICRkaaf6ptKkGI+NCNI/pyaI82/OaFz5j/jQatU0FVbYicjDTf1KMGJQgRX0pPC3DPqKG0yslg7BPT2bKtzuuQJM6q6oJkZ/jn8hIoQYj4VnFBFvdfMIxVW6r42TMzCaqGRFKrqQuSk+mvt2R/RSMiOxnWtYibT+3HOwvXcdfbi7wOR+Koqi5Idrp6ECLSDBccUsp5Zftxz7+/5I25KuGerKrqgr6awQRNTBBmlmdmgcj3vc3sNDPLiG9oIgLhGhK/P70fg/ZrzfWTZ/Hl2nKvQ5I4qKpN3DGIKUC2mXUG/g/4MTAxXkGJyM6yM9IYd+FQcjLTGPPYdLZWa9A62VTXBclJ0ARhzrltwFnAPc65M4ED4xeWiOyqY6sc7jt/KMs2buP6ybNxToPWyaS6LpS4CcLMhgMXAK9GtvnnfnCRFHFIj7b8+uQDeGv+Gh55XzUkkkl4mqu/hoWbGs3PgF8DLzjn5plZD+CduEUlIrt1yeHdOP7AEv7yxgJmLd/sdTgSIwk7SO2ce9c5d5pz7i+Rwer1zrlr4hybiERhZtxx9iDaF2Rz1VMzdBNdkqhO1EFqM3vKzArNLA+YDyw0sxv2cMwEM1trZnMbbPsfM5tjZrPM7F9mpvJZInuhVW4G954/hNVbqrnhOY1HJIOqBB6kPtA5txU4A3gNKAUu2sMxE4ERu2y73Tk30Dk3GHgF+K8mRyoiOxlSWsSvTurLv+av4dEPvvY6HNkHdcEQ9SGXsAkiI3LfwxnAP51zdUCjH1mcc1OAjbtsa7jqWN6eXkNEGnfpEd35/gEl/PG1z/n4K5UrTVR+XOobmp4gHgS+JvymPsXMugJ7tcSkmf3BzJYTnhGlHoTIPjAz/nruIErb5nLFkzNYvnGb1yHJXqiKJIisROxBOOfuds51ds6d7MKWAsfszQmdczc55/YDngSu2t1+ZjbGzKaZ2bR169btzalEUkKrnAwevriMumCIyx6btqN0pSSO6tpw9cCEvMRkZq3M7G/b37DN7K+EexP74ingB7t70jk33jlX5pwrKy4u3sdTiSS3HsX53Hv+UBatKef6ybMJaeXXhLK9B5GQCQKYAJQD50a+tgKPNvdkZrZ/g4enAQua+xoiEt1RvYv5zckH8Ma81dz97y+8DkeaYUeC8Nly3029G7qnc67hp/3fm9msxg4ws0nA0UA7M1sB3AycbGZ9gBCwFBjb7IhFZLcuPaI7C1aXc9fbX9C3QyEj+nfwOiRpgu2D1H67D6KpCaLKzI5wzr0PYGaHA1WNHeCcGxVl8yPNjE9EmsHMuPWM/nyxtoLrJ8+iV/vD6dW+wOuwZA+qfJogmtqfGQvcZ2Zfm9nXwL3A5XGLSkT22k4rvz6ulV8TQXVtAo9BOOdmO+cGAQOBgc65IcCxcY1MRPbajpVfN2zjumc0aO13iT5IDYRvdGtws9t1cYhHRGLkkB5t+d3IA3n78zXc8+8vvQ5HGlGV4DfKRWMxi0JE4uLi4V05a2hn7nx7Ef9esMbrcGQ3qmoTewwiGvVZRXzOzPjjmQM4sGMhP39mNis26U5rP6qpT8Ab5cys3My2RvkqB7QSq0gCyM5I4/4LhhIKOa56aia1kTcj8Y+q2iABg4w0f12YaTRBOOcKnHOFUb4KnHOqKCeSILq1y+O2swcya/lm/vT6516HI7vYvtS3WQIlCBFJHicN6MiPD+/Gox98zeufrfI6HGnAj9XkQAlCJKX8+qQDGLRfa3753By+Xl/pdTgS4cdqcqAEIZJSMtMD3Hf+EAIB46pJMzQe4RPV9f6rJgdKECIpp0tRLredPZC5K7dy+5taL9MPqtSDEBG/OLFfBy46tCsPvbeEdxep3orX/FiPGpQgRFLWTaccQJ+SAq6fPIt15TVeh5PSqupCZGuQWkT8IjsjjbtHDaG8up7rn9V6TV6qrg2Sk+G/t2P/RSQiLaZPhwJ+N/JApixaxyPvL/E6nJSlS0wi4ksXHFLKif1KuO3NBcxevtnrcFJSte6DEBE/MjP+8oOBtC/I5upJM1U/wgNVdUGy0pUgRMSHWudmcveowazcXMVvnv8M5zQe0ZLUgxARXxvWtQ3XHd+bV+as4ulPl3sdTsqoC4aoCzqNQYiIv11xVE+O6NWOW16ax8LV5V6HkxKqfVpNDpQgRKSBQMD423mDKMhO56qnZlBZU+91SEmvui683InugxAR32tfkM1d5w1h8boKfvmPORqPiLPtPYjsdP+9HfsvIhHx3BH7t+OGE/vy6pxVPPTeV16Hk9T8Wo8alCBEZDfGHtWDkwd04M+vL+D9L9Z7HU7S2l6POqXGIMxsgpmtNbO5DbbdbmYLzGyOmb1gZq3jdX4R2Tdmxm1nD6JncT5XT5rB8o2qZx0PVSk6SD0RGLHLtreA/s65gcAi4NdxPL+I7KP8rHQevGgY9UHH2Cem7/i0K7GzPUGk1CC1c24KsHGXbf9yzm2fFvER0CVe5xeR2OhRnM9dPxzM/FVbuXrSTOqDKjIUSzUp2oPYk0uA13f3pJmNMbNpZjZt3TqtVy/ipeMOKOH3p/Xj7c/XcNMLczWzKYZ29CCUIMLM7CagHnhyd/s458Y758qcc2XFxcUtF5yIRHXx8G5cc2wvnpm2nDv+tdDrcJJGVW24R+bHHkR6S5/QzEYDI4HjnD6GiCSUnx/fm3UVNdz3zmLa5Wfx48O7ex1SwvPzIHWLJggzGwHcCBzlnNOUCJEEY2b8z+n92VBRy3+/Mp+8zHTOPWg/r8NKaDtulMv0310H8ZzmOgmYCvQxsxVmdilwL1AAvGVms8xsXLzOLyLxkZ4W4O5RQziiVzt++Y853P7mAlWj2wfVdUECBplp/ksQcetBOOdGRdn8SLzOJyItJzsjjQk/Ooj/+udc7ntnMUs3bOOOcwb5cqDV76pqg2RnpGFmXofyHS0+BiEiySEjLcAfzxxAt7Z5/On1BXyzuYqHLi6jbX6W16ElFL+WGwUttSEi+8DMuPyonjxwwVDmfbOVcx6cyrryGq/DSihVdUHf9ryUIERkn500oCNP/OQQVm2u5qJHPmZTZa3XISUMv1aTAyUIEYmRg7q14eHRZXy1vpKLJ3yi2tZNVFWrS0wikgIO79WOBy8cxoLVW/nxo5+q4FATVNeFlCBEJDUc07c9d/9wCLOWb+Ynf59GTb0W+GtMVV2QrAx/vhX7MyoRSWgnDejIHecMZOpXG/jFs3N0n0Qjqn08i0nTXEUkLs4c0oXVW2r4yxsL6NQ6m1+fdIDXIflSlY8HqZUgRCRuxh7Vg282V/Hgu1/RqVUOow/r5nVIvuPnQWolCBGJGzPjltP6sWpLNbe8PI8OrbI5sV8Hr8PylWrdByEiqSotYNwzagiDurTmmkkz+WTJxj0flEKq60JKECKSunIy03hkdBldinK4ZOKnzFq+2euQfKE+GKI2qGmuIpLi2uZn8eRPDqUoL4PREz7h81VbvQ7Jc9X1kWJBPlzqG5QgRKQFdWiVzVM/OZScjDQueuRjvlxb4XVInqqq9W+xIFCCEJEWtl+bXJ687BAALnz4Y5ZtSN3aYdU+rkcNShAi4oGexfk8fukhVNcHOefBD/lybbnXIXlie4Lw630QShAi4okDOhby9JhDCYbg3Ac/Yt43W7wOqcVtr0edna4EISKyk74dCpl8+aFkpwcYNf4jZizb5HVILWrHGIR6ECIi39WjOJ/JY4fTJi+TCx/+mA8Xr/c6pBZTpTEIEZHGdSnKZfLlw+lSlMOPHv2Ut+ev8TqkFrFjDEIJQkRk99oXZvPMmOH07VDA5U9M55+zVnodUtxV122/D0IJQkSkUUV5mTz5k0Mo61rEz56ZxRMfLfU6pLj69hKTP9+K/RmViKSsguwM/n7JwRzTpz2/fXEu495d7HVIcaMb5UREmik7I40HLxrGqYM68efXF3DX24twLvmKDqXsILWZTTCztWY2t8G2c8xsnpmFzKwsXucWkcSXkRbgrvMGc/awLtz19hf85Y2FSZckquuCmEFWuj8/q8czqonAiF22zQXOAqbE8bwikiTSAsZtPxjIBYeUMu7dxfz+5flJlSS2FwsyM69DiSpuBYOcc1PMrNsu2z4HfPufISL+EwgYt57Rn6z0NCZ8sITaYIhbT+9PIJD47yPV9f6tJgc+rihnZmOAMQClpaUeRyMiXjIzfjfyALIzAtz/n8Vsq6nn9nMGkZHmz0szTVVV699iQeDjBOGcGw+MBygrK0uePqWI7BUz45cj+pKXlc7tby6koibIvecP8fUb7J6Ey436N8n5NzIRkSh+ekwv/uf0frz9+RoumfgpFTX1Xoe016rqgr69SQ6UIEQkAV00vBt3njeIj5ds5MKHP2ZjZa3XIe2V7YPUfhXPaa6TgKlAHzNbYWaXmtmZZrYCGA68amZvxuv8IpLczhzShfsvGMr8VVsZefd7CVnnuro+6OtLZHFLEM65Uc65js65DOdcF+fcI865FyLfZznnSpxzJ8br/CKS/E7s14F/jD0MM+PccVN54qOlCTUNtqo2RROEiEhLGNClFa9cfQTDe7blty/O5fpnZ+9YwsLvqutS9BKTiEhLKcrLZMKPDuLa4/bnhZkrGfXQR2xKgHGJKiUIEZH4SwsYPz++Nw9cMIz5q7Zy9rgPWbm5yuuwGlVVq1lMIiItZkT/Djx2ycGs3VrD2Q98yBdryr0Oabeq6/19o5wShIgknUN7tOWZy4dTH3KcPW4q05du9Dqk7wiGHLX1IV1iEhFpaQd2KuT5Kw6jKDeDUQ99zEuzv/E6pJ1U+7xYEChBiEgS269NLs9feTiDu7TmmkkzfVVXYnstCI1BiIh4pE1eJo//5GB+MDRcV+Lap2ft+PTupe1Tcf08BuHbxfpERGIlKz2NO84ZSM/2edz2xkKWbdzGgxcNo6Qw27OYticpjUGIiHjMzLjy6F6Mu3Aoi9aUc8rd7/PJEu8Gr6vrQoAShIiIb4zo35EXf3o4BdnpnP/QR0z8YIkn4xJ+r0cNShAikoJ6lxTwz6sO5+g+7bnl5flcN3k2lS28bPi3g9T+fRv2b2QiInFUmJ3B+IuGcf3xvXlx1kpO+t/3+PirDS12/kQYpFaCEJGUFQgYVx+3P8+MGQ7ADx/6iFtfmd8is5w0SC0ikgAO7t6G1689kgsOKeXh95dwyt3v8dmKLXE9Z7XugxARSQx5WencesYAHrvkYCprgpz1wAeMe3cxoVB8BrCr1IMQEUks3+tdzBs/O5LvH1DCn19fwIWPfMzqLdUxP49mMYmIJKDWuZncf8FQ/vKDAcxctpkR/zuFN+auiuk5qiOD1Fnp/n0b9m9kIiIeMjPOO6iUV685gv2Kchn7xAyunzybrdV1MXn97cWCzCwmrxcPShAiIo3oUZzP81cexjXH9uKFmSs46a7YTIetqvN3sSBQghAR2aOMtADXndCHZ8ceRkaa8cOHPuIPr85nW+3e31xXXefvWhCgBCEi0mTDuhbx6jVHMurgUh56bwkn3DmFdxaubdZrbKmqY/K05XyyZCNZPq4FAVrNVUSkWfKy0vnjmQM4fVAnfvPCZ/z40U85ZWBHbh55IO13szqsc4635q9h8rTlvLtoHXVBx35tchhzZM8Wjr55zC/FMxpTVlbmpk2b5nUYIiI7qakPMv7dr7jnnS/JSgtwxTE9ueTw7jtNXV1bXs1vX5jLv+avoUNhNiMHduTUQZ0Y2KVV3AeozWy6c65sr4+PV4IwswnASGCtc65/ZFsb4BmgG/A1cK5zbtOeXksJQkT8bMn6Sm59ZT7/t2AtnVpl84sT+3DG4M68OGslv385vHTH9Sf05tIjepAWaLlZS35OEN8DKoDHGiSI24CNzrk/m9mvgCLn3I17ei0lCBFJBFMXb+CPr33OZyu30C4/i/UVNZR1LeK2swfSozi/xePxbYIAMLNuwCsNEsRC4Gjn3Coz6wj8xznXZ0+vowQhIokiFHK8POcbJnzwNacP6sTow7q1aK+hoX1NEC09SF3inFsFEEkS7Xe3o5mNAcYAlJaWtlB4IiL7JhAwTh/cmdMHd/Y6lH3m2zlWzrnxzrky51xZcXGx1+GIiKSclk4QayKXloj827wJxCIi0mJaOkG8BIyOfD8a+GcLn19ERJoobgnCzCYBU4E+ZrbCzC4F/gwcb2ZfAMdHHouIiA/FbZDaOTdqN08dF69ziohI7Ph2kFpERLylBCEiIlEpQYiISFQJsVifma0DlkYetgK2NHi64eNo37cD1u/D6Xc9X3P3ifZcY23Y9XEyt6nhNrWpefE2ZZ/mtqkp3+9Lm5rSnsb2a0p7dt3mh7+lxvaL9/tDV+fc3t9I5pxLqC9g/O4eR/semBbL8zV3n2jPNdaGVGrTLtvUJo/b1MTv97pNTWlPY/s1pT3NbVNL/Iz2tU0t/f7Q8CsRLzG93Mjj3X0fy/M1d59ozzXWhl0fJ3ObYtWepr6W2rR3v2st+XvX2H5Nac+u25KhTS39/rBDQlxi2hdmNs3tw2JVfqQ2JQa1yf+SrT0Q2zYlYg+iucZ7HUAcqE2JQW3yv2RrD8SwTUnfgxARkb2TCj0IERHZC0oQIiISlRKEiIhEldIJwsyONLNxZvawmX3odTyxYGYBM/uDmd1jZqP3fIT/mdnRZvZe5Gd1tNfxxIKZ5ZnZdDMb6XUssWBmB0R+Ps+Z2RVexxMLZnaGmT1kZv80sxO8jicWzKyHmT1iZs81Zf+ETRBmNsHM1prZ3F22jzCzhWb2pZn9qrHXcM6955wbC7wC/D2e8TZFLNoEnA50BuqAFfGKtali1CYHVADZeNymGLUH4EZgcnyibJ4Y/S19HvlbOhfwfNpojNr0onPuMuBHwHlxDLdJYtSmr5xzlzb5pLG6466lv4DvAUOBuQ22pQGLgR5AJjAbOBAYQDgJNPxq3+C4yUBhMrQJ+BVweeTY55KkTYHIcSXAk0nQnu8DPyT8xjMyGX5GkWNOAz4Ezk+WNkWO+yswNMna1KT3hrjVg4g359wUM+u2y+aDgS+dc18BmNnTwOnOuT8BUbvyZlYKbHHObY1nvE0RizaZ2QqgNvIwGMdwmyRWP6eITUBWXAJtohj9jI4B8gj/IVeZ2WvOuVB8I9+9WP2MnHMvAS+Z2avAU3EMeY9i9HMywkXNXnfOzYhzyHsU47+lJknYBLEbnYHlDR6vAA7ZwzGXAo/GLaJ919w2PQ/cY2ZHAlPiGdg+aFabzOws4ESgNXBvXCPbO81qj3PuJgAz+xGw3svk0Ijm/oyOBs4inMBfi2dg+6C5f0tXE+7ttTKzXs65cfEMbi819+fUFvgDMMTMfh1JJLuVbAnComxr9E5A59zNcYolVprVJufcNsJJz8+a26bnCSc+v2r27x2Ac25i7EOJmeb+jP4D/CdewcRIc9t0N3B3/MKJiea2aQMwtqkvnrCD1LuxAtivweMuwDcexRIrapP/JVt7QG1KFHFtU7IliE+B/c2su5llEh4IfMnjmPaV2uR/ydYeUJsSRXzb5PXI/D6M6E8CVvHtdM5LI9tPBhYRHtm/yes41abkalOytUdt8j5WP7dJi/WJiEhUyXaJSUREYkQJQkREolKCEBGRqJQgREQkKiUIERGJSglCRESiUoKQhGVmFS18vpjUDInUt9hiZjPNbIGZ3dGEY84wswNjcX6RplKCEIkws0bXJnPOHRbD073nnBsCDAFGmtnhe9j/DMKrv4q0mGRbrE9SnJn1BO4DioFtwGXOuQVmdirwW8Jr5m8ALnDOrTGzW4BOQDdgvZktAkoJr69fCtzlwou2YWYVzrn8yMqltwDrgf7AdOBC55wzs5OBv0WemwH0cM7tdtll51yVmc0ivConZnYZMCYS55fARcBgwrUWjjKz3wI/iBz+nXbu7f+bSDTqQUiyGQ9c7ZwbBvwCuD+y/X3g0Min9qeBXzY4ZhjhNfTPjzzuS3h58YOBm80sI8p5hgA/I/ypvgdwuJllAw8CJznnjiD85t0oMysC9ufbpdmfd84d5JwbBHxOeDmFDwmvr3ODc26wc25xI+0UiRn1ICRpmFk+cBjwbLjWC/BtgaEuwDNm1pHwp/MlDQ59yTlX1eDxq865GqDGzNYSrmS3a6nTT5xzKyLnnUW4B1IBfOWc2/7akwj3BqI50szmAH2APzvnVke29zezWwnXvsgH3mxmO0ViRglCkkkA2OycGxzluXuAvznnXmpwiWi7yl32rWnwfZDofyfR9om2Nv/uvOecG2lmvYH3zewF59wsYCJwhnNudqSg0NFRjm2snSIxo0tMkjRcuGzsEjM7B8IlI81sUOTpVsDKyPej4xTCAqBHg7KQeyx075xbBPwJuDGyqQBYFbmsdUGDXcsjz+2pnSIxowQhiSzXzFY0+LqO8JvqpWY2G5gHnB7Z9xbCl2TeIzyAHHORy1RXAm+Y2fvAGmBLEw4dB3zPzLoDvwM+Bt4inHC2exq4ITI1tie7b6dIzGi5b5EYMrN851xFpOD9fcAXzrk7vY5LZG+oByESW5dFBq3nEb6s9aC34YjsPfUgREQkKvUgREQkKiUIERGJSglCRESiUoIQEZGolCBERCQqJQgREYnq/wFfYAfGcsV3NAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner = Learner(dls, model, loss_func=ssd_loss).to_fp16()\n",
    "learner.freeze()\n",
    "lr_min, lr_steep = learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0017\n"
     ]
    }
   ],
   "source": [
    "lr = (lr_min+lr_steep)/2; print(\"lr:\",round(lr,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.574489</td>\n",
       "      <td>6.161962</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.015879</td>\n",
       "      <td>5.887607</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.400682</td>\n",
       "      <td>5.772642</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.044405</td>\n",
       "      <td>5.686826</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.821069</td>\n",
       "      <td>5.673601</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb:11.00 | lbl: 4.37\n",
      "bb:10.50 | lbl: 4.40\n",
      "bb:9.53 | lbl: 4.34\n",
      "bb:8.55 | lbl: 4.60\n",
      "bb:8.33 | lbl: 4.23\n",
      "bb:7.62 | lbl: 4.38\n",
      "bb:7.09 | lbl: 4.28\n",
      "bb:6.47 | lbl: 4.02\n",
      "bb:5.93 | lbl: 3.89\n",
      "bb:5.58 | lbl: 3.99\n",
      "bb:5.33 | lbl: 4.02\n",
      "bb:5.28 | lbl: 3.56\n",
      "bb:5.14 | lbl: 3.51\n",
      "bb:5.03 | lbl: 3.52\n",
      "bb:4.94 | lbl: 3.38\n",
      "bb:4.92 | lbl: 3.06\n",
      "bb:4.95 | lbl: 2.72\n",
      "bb:4.88 | lbl: 2.65\n",
      "bb:4.87 | lbl: 2.13\n",
      "bb:4.89 | lbl: 2.03\n",
      "bb:4.76 | lbl: 1.98\n",
      "bb:4.83 | lbl: 2.01\n",
      "bb:4.86 | lbl: 2.07\n",
      "bb:4.90 | lbl: 2.02\n",
      "bb:4.88 | lbl: 2.09\n",
      "bb:4.90 | lbl: 2.06\n",
      "bb:4.86 | lbl: 1.93\n",
      "bb:4.83 | lbl: 1.80\n",
      "bb:4.81 | lbl: 1.81\n",
      "bb:4.85 | lbl: 1.89\n",
      "bb:4.83 | lbl: 1.80\n",
      "bb:4.90 | lbl: 1.28\n",
      "bb:4.86 | lbl: 1.46\n",
      "bb:4.82 | lbl: 1.36\n",
      "bb:4.81 | lbl: 1.42\n",
      "bb:4.81 | lbl: 1.62\n",
      "bb:4.86 | lbl: 1.44\n",
      "bb:4.87 | lbl: 1.35\n",
      "bb:3.96 | lbl: 1.32\n",
      "bb:4.90 | lbl: 1.56\n",
      "bb:4.85 | lbl: 1.69\n",
      "bb:4.87 | lbl: 1.42\n",
      "bb:4.81 | lbl: 1.49\n",
      "bb:4.82 | lbl: 1.58\n",
      "bb:4.87 | lbl: 1.46\n",
      "bb:4.88 | lbl: 1.63\n",
      "bb:4.90 | lbl: 1.39\n",
      "bb:4.84 | lbl: 1.40\n",
      "bb:4.86 | lbl: 1.47\n",
      "bb:4.84 | lbl: 1.17\n",
      "bb:4.83 | lbl: 1.28\n",
      "bb:4.85 | lbl: 1.47\n",
      "bb:4.84 | lbl: 1.52\n",
      "bb:4.93 | lbl: 1.08\n",
      "bb:4.90 | lbl: 1.35\n",
      "bb:4.85 | lbl: 1.29\n",
      "bb:4.86 | lbl: 1.21\n",
      "bb:4.90 | lbl: 1.25\n",
      "bb:4.82 | lbl: 1.36\n",
      "bb:4.92 | lbl: 1.27\n",
      "bb:4.80 | lbl: 1.52\n",
      "bb:4.90 | lbl: 1.33\n",
      "bb:4.84 | lbl: 1.07\n",
      "bb:4.82 | lbl: 1.32\n",
      "bb:4.77 | lbl: 1.35\n",
      "bb:4.88 | lbl: 1.22\n",
      "bb:4.88 | lbl: 1.17\n",
      "bb:4.88 | lbl: 1.18\n",
      "bb:4.89 | lbl: 1.13\n",
      "bb:4.88 | lbl: 1.04\n",
      "bb:4.90 | lbl: 1.12\n",
      "bb:4.86 | lbl: 1.28\n",
      "bb:4.82 | lbl: 1.03\n",
      "bb:4.81 | lbl: 1.14\n",
      "bb:4.81 | lbl: 1.22\n",
      "bb:4.86 | lbl: 1.17\n",
      "bb:4.87 | lbl: 1.06\n",
      "bb:3.96 | lbl: 1.01\n",
      "bb:4.91 | lbl: 1.03\n",
      "bb:4.87 | lbl: 0.95\n",
      "bb:4.86 | lbl: 1.27\n",
      "bb:4.86 | lbl: 1.30\n",
      "bb:4.85 | lbl: 1.17\n",
      "bb:4.89 | lbl: 0.97\n",
      "bb:4.78 | lbl: 1.01\n",
      "bb:4.86 | lbl: 1.00\n",
      "bb:4.85 | lbl: 1.00\n",
      "bb:4.91 | lbl: 1.08\n",
      "bb:4.92 | lbl: 0.91\n",
      "bb:4.83 | lbl: 1.09\n",
      "bb:4.92 | lbl: 1.02\n",
      "bb:4.90 | lbl: 0.95\n",
      "bb:4.85 | lbl: 0.93\n",
      "bb:4.87 | lbl: 1.19\n",
      "bb:4.85 | lbl: 1.05\n",
      "bb:4.83 | lbl: 1.00\n",
      "bb:4.80 | lbl: 1.20\n",
      "bb:4.87 | lbl: 1.27\n",
      "bb:4.83 | lbl: 0.94\n",
      "bb:4.89 | lbl: 0.86\n",
      "bb:4.85 | lbl: 1.06\n",
      "bb:4.85 | lbl: 1.07\n",
      "bb:4.79 | lbl: 1.18\n",
      "bb:4.87 | lbl: 1.08\n",
      "bb:4.92 | lbl: 0.87\n",
      "bb:4.80 | lbl: 1.00\n",
      "bb:4.83 | lbl: 0.95\n",
      "bb:4.81 | lbl: 1.08\n",
      "bb:4.86 | lbl: 0.93\n",
      "bb:4.90 | lbl: 0.96\n",
      "bb:4.86 | lbl: 1.14\n",
      "bb:4.82 | lbl: 0.87\n",
      "bb:4.81 | lbl: 0.97\n",
      "bb:4.81 | lbl: 1.15\n",
      "bb:4.86 | lbl: 1.09\n",
      "bb:4.87 | lbl: 0.91\n",
      "bb:3.96 | lbl: 1.06\n",
      "bb:4.79 | lbl: 1.02\n",
      "bb:4.88 | lbl: 0.97\n",
      "bb:4.88 | lbl: 0.87\n",
      "bb:4.89 | lbl: 0.85\n",
      "bb:4.93 | lbl: 0.83\n",
      "bb:4.84 | lbl: 0.79\n",
      "bb:4.84 | lbl: 0.86\n",
      "bb:4.92 | lbl: 0.75\n",
      "bb:4.78 | lbl: 0.86\n",
      "bb:4.83 | lbl: 0.86\n",
      "bb:4.85 | lbl: 0.91\n",
      "bb:4.90 | lbl: 0.77\n",
      "bb:4.86 | lbl: 0.85\n",
      "bb:4.92 | lbl: 0.72\n",
      "bb:4.92 | lbl: 0.92\n",
      "bb:4.89 | lbl: 0.88\n",
      "bb:4.81 | lbl: 0.97\n",
      "bb:4.87 | lbl: 0.84\n",
      "bb:4.83 | lbl: 0.70\n",
      "bb:4.86 | lbl: 0.82\n",
      "bb:4.88 | lbl: 0.81\n",
      "bb:4.83 | lbl: 0.89\n",
      "bb:4.84 | lbl: 0.77\n",
      "bb:4.89 | lbl: 0.80\n",
      "bb:4.86 | lbl: 0.74\n",
      "bb:4.85 | lbl: 0.72\n",
      "bb:4.87 | lbl: 0.86\n",
      "bb:4.86 | lbl: 0.84\n",
      "bb:4.87 | lbl: 0.90\n",
      "bb:4.82 | lbl: 0.78\n",
      "bb:4.88 | lbl: 0.84\n",
      "bb:4.90 | lbl: 0.85\n",
      "bb:4.86 | lbl: 1.01\n",
      "bb:4.82 | lbl: 0.77\n",
      "bb:4.81 | lbl: 0.87\n",
      "bb:4.81 | lbl: 1.14\n",
      "bb:4.86 | lbl: 0.93\n",
      "bb:4.87 | lbl: 0.85\n",
      "bb:3.96 | lbl: 1.05\n",
      "bb:4.80 | lbl: 0.92\n",
      "bb:4.84 | lbl: 0.70\n",
      "bb:4.84 | lbl: 0.82\n",
      "bb:4.81 | lbl: 0.85\n",
      "bb:4.88 | lbl: 0.71\n",
      "bb:4.87 | lbl: 0.72\n",
      "bb:4.87 | lbl: 0.80\n",
      "bb:4.83 | lbl: 0.77\n",
      "bb:4.85 | lbl: 0.74\n",
      "bb:4.90 | lbl: 0.63\n",
      "bb:4.88 | lbl: 0.69\n",
      "bb:4.84 | lbl: 0.77\n",
      "bb:4.83 | lbl: 0.80\n",
      "bb:4.85 | lbl: 0.67\n",
      "bb:4.90 | lbl: 0.66\n",
      "bb:4.83 | lbl: 0.78\n",
      "bb:4.82 | lbl: 0.82\n",
      "bb:4.89 | lbl: 0.74\n",
      "bb:4.87 | lbl: 0.73\n",
      "bb:4.84 | lbl: 0.78\n",
      "bb:4.83 | lbl: 0.72\n",
      "bb:4.87 | lbl: 0.70\n",
      "bb:4.85 | lbl: 0.72\n",
      "bb:4.85 | lbl: 0.60\n",
      "bb:4.87 | lbl: 0.69\n",
      "bb:4.87 | lbl: 0.63\n",
      "bb:4.94 | lbl: 0.69\n",
      "bb:4.90 | lbl: 0.69\n",
      "bb:4.83 | lbl: 0.69\n",
      "bb:4.86 | lbl: 0.80\n",
      "bb:4.90 | lbl: 0.61\n",
      "bb:4.90 | lbl: 0.85\n",
      "bb:4.86 | lbl: 1.00\n",
      "bb:4.82 | lbl: 0.74\n",
      "bb:4.81 | lbl: 0.85\n",
      "bb:4.81 | lbl: 1.11\n",
      "bb:4.86 | lbl: 0.93\n",
      "bb:4.87 | lbl: 0.84\n",
      "bb:3.96 | lbl: 1.05\n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(5, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/s1.pth')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.save('s1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.export('models/20201214_pascal2007_jh.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stepping Through a Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get batch, acts\n",
    "head_reg4 = SSD_MultiHead(k, -4.)\n",
    "mod = CustMod(create_body(resnet34, pretrained=True), head_reg4)\n",
    "mod.cpu().eval()\n",
    "\n",
    "batch = next(iter(dls.cpu().valid))\n",
    "acts = mod(batch[0])\n",
    "batch_bbs, batch_lbls = batch[1], batch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get acts and targs for a single im\n",
    "bidx = 0\n",
    "act_bbs,act_lbls,bbs,lbls = list(zip(*acts,batch_bbs,batch_lbls))[bidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
